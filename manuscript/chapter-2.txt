# Object-Oriented Design Principles

This chapter describes principles related to object-oriented design. The following principles are discussed:

- Object-oriented programming concepts
- Programming paradigms
- Why is object-oriented programming hard?
- SOLID principles
- Clean microservice design (architecture) principle
- Vertical slice design (architecture) principle
- Class organization principle
- Package, class and function sizing principle
- Uniform naming principle
- Encapsulation principle
- Prefer composition over inheritance principle
- Tactical domain-driven design principle
- Use the design patterns principle
- Tell, don't ask principle
- Law of Demeter
- Avoid primitive type obsession principle
- Dependency injection principle
- Avoid duplication principle

We start the chapter by defining object-oriented programming (OOP) concepts and discussing different programming paradigms:
object-oriented, imperative, and functional. We also analyze why OOP can be hard to master even though the concepts and fundamental principles are not so difficult to grasp.

## Object-Oriented Programming Concepts

The following are the basic concepts related to OOP:

- Classes/Objects
    - Attributes and methods
    - Composition (= when attributes are other classes)
- Encapsulation
- Abstraction
- Inheritance
- Interfaces
    - Interface evolution
- Polymorphism
    - Dynamic dispatch (late binding)

Let's discuss each of the concepts next.

### Classes/Objects

A class is a user-defined data type that acts as the blueprint for individual objects (instances of the class). An object is created
using the class's *constructor* method, which sets the object's initial state. A class consists of *attributes* (or *properties*) and *methods*,
which can be either *class* or *instance* attributes/methods. Instance attributes define the
state of an object. Instance methods act on instance attributes, i.e., they are used to query and modify the state of an object.
Class attributes belong to the class, and class methods act on class attributes.

An object can represent either a concrete or abstract entity in the real world. For example, a circle and an employee object represent
real-world entities, while an object representing an open file (a file handle) is an abstract entity. Objects can also be hybrid, representing something concrete and abstract.

Attributes of an object can contain other objects to create object hierarchies. This is called *object composition*,
and is handled in more detail in the *prefer composition over inheritance principle* section.

In pure object-oriented languages like Java, you must always create a class where you can put functions. Even if you have only
class methods and no attributes, you must create a class in Java to host the class methods (static methods). In JavaScript, you don't
have to create classes for hosting functions; just put the functions into a single module or create a directory and put each function
in a separate module. Putting functions into classes has many benefits (e.g., dependency injection), which is why putting functions into classes is often a good idea.

### Encapsulation

Encapsulation makes changing the internal state of an object directly outside of the object impossible. The idea of encapsulation
is that the object's state is internal to the object and can be changed externally only by the object's public methods. Encapsulation contributes to better
security and avoidance of data corruption. More about that in the *encapsulation principle* section.

### Abstraction

Objects only reveal relevant internal mechanisms to other objects, hiding any unnecessary implementation code.
Callers of the object methods don't need to know the object's internal workings. They adhere only to the public API of the object.
This makes it possible to change the implementation details without affecting any external code.

### Inheritance

Inheritance allows classes to be arranged in a hierarchy representing *is-a* relationships. For example, the `Employee`
class might inherit from the `Person` class because an employee is also a person.
All the attributes and methods in the parent (super) class also appear in the child class (subclass) with the same names.
For example, class `Person` might define attributes `name` and `birthDate`.
These will also be available in the `Employee` class. Child class can add methods and attributes. Child class can also
override a method in the parent class. For example, the `Employee` might add attributes `employer` and `salary`. This technique allows
easy re-use of the same functionality and data definitions, mirroring real-world relationships intuitively.

C++ also supports multiple inheritance, where a child class can have multiple parent classes. The problem with multiple inheritance is that
the child class can inherit different versions of a method with the same name. By default, multiple inheritance should be avoided whenever
possible. Some languages, like Java, don't support multiple inheritance at all. Inheritance will cram additional functionality into a
child class, making the class large and possibly not having a single responsibility. A better way to add functionality to a class is to compose
the class of multiple other classes (the mixins). In that way, there is no need to worry about possible clashing of method names.

Multiple inheritance is always allowed for interfaces. More about interfaces in the next section.

### Interface

An interface specifies a contract that classes that implement the interface must obey. Interfaces are used to implement polymorphic behavior,
which will be described in the next section. An interface consists of one or more methods that classes must implement.
You cannot instantiate an interface. It is just a contract specification.

Below are two interfaces and two classes that implements the interfaces:

```java
public interface Drawable {
  void draw();
}


public interface Clickable {
  void click();
}


public class Window implement Drawable {
  public void draw() {
    System.out.println("Window drawn");
  }
}


public class Button implements Drawable, Clickable {
  public void draw() {
    System.out.println("Button drawn");
  }

  public void click() {
    System.out.println("Button clicked");
  }
}


final var button = new Button()
button.draw()
button.click()

// Output:
// Button drawn
// Button clicked
```

#### Interface evolution

After an interface has been defined and is used by the implementing classes, and you would like to add
method(s) to the interface, you might have to provide a default implementation in your interface because the classes that
currently implement your interface don't implement the methods you are about to add to the interface. This is
true in cases where the implementing classes are something you cannot or don't want to modify.

Let's imagine you have a `Message` interface with `getData` and `getLengthInBytes` methods, and you have classes
implementing the `Message` interface, but you cannot modify the classes.
You want to add `setQueuedAtInstant` and `getQueuedAtInstant` methods to the interface.
You can add the methods to the interface but must provide a default implementation, like raising an error
indicating the method is not implemented.

```java
import java.time.Instant;


public interface Message {
  byte[] getData();
  int getLengthInBytes();

  default void setQueuedAtInstant(final Instant instant) {
     throw new UnsupportedOperationException();
  }

  default Instant getQueuedAtInstant() {
    throw new UnsupportedOperationException();
  }
}
```

### Polymorphism

Polymorphism means that methods are polymorphic when the actual method to be called is decided during the runtime.
For this reason, polymorphism is also called *late binding* (to a particular method) or *dynamic dispatch*. Polymorphic behavior
is easily implemented using an interface variable. You can assign any object that implements the interface to the interface variable.
When you call a method on the interface variable, that actual method to be called is decided based on
what type of object is currently assigned to the interface variable. Below is an example of polymorphic behavior:

```java
Drawable drawable = new Button();
drawable.draw();

// Output:
// Button drawn

drawable = new Window();
drawable.draw();

// Output:
// Window drawn
```

Polymorphic behavior is also exhibited when you have a variable of the parent class type and assign a child class object
to the variable, like in the below example:

```java
public class IconButton extends Button {
  public void draw() {
    System.out.println("Button with icon drawn");
  }
}


var button = new Button();
button.draw();

// Output:
// Button drawn

button = IconButton();
button.draw();

// Output:
// Button with icon drawn
```

## Programming Paradigms

The most popular programming languages, including C++, Java and JavaScript, are multi-paradigm programming languages. Multi-paradigm languages
support the following programming paradigms:

- Imperative programming
- Object-oriented programming
- Functional programming

### Imperative Programming

Imperative programming is a programming paradigm that focuses on providing a sequence of explicit instructions or statements
for the computer to follow to solve a problem or achieve a desired outcome. The program consists of a series of commands
that modify the program state, typically using mutable variables and assignments. Imperative programming emphasizes
how to achieve a result step by step, specifying the control flow and state changes explicitly. Typical imperative programming constructs
are variable assignments, state mutations, match-case statements, if-statements, and different kinds of loops (for, while).
Below is a code sample using imperative programming in JavaScript:

```js
const numbers = [1, 2, 3, 4, 5];
const doubledEvenNumbers = [];

for (const number of numbers) {
  if (number % 2 == 0) {
    doubledEvenNumbers.push(number**2)
  }
}

console.log(doubledEvenNumbers)

// Output:
// [4, 16]
```

In the above example, although the `doubled_even_numbers` variable is declared as `const`, it is still a mutable list and
we mutate the list inside the `for` loop.

### Functional Programming

Functional programming is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids
changing state and mutable data. It emphasizes the use of immutable data and the composition of functions to solve problems.
In functional programming, functions are first-class citizens, meaning they can be assigned to variables, passed as arguments
to other functions, and returned as results. This enables the creation of higher-order functions and promotes modularity,
code re-usability, and concise expression of complex operations in a declarative way. Functional programming avoids side effects,
favoring [pure functions](https://en.wikipedia.org/wiki/Pure_function) that consistently produce the same output for a
given input without causing side effects, making programs easier to reason about and test.

Unlike in imperative programming, in functional programming, you don't tell the computer *how* to do something but declare
*what* you want, e.g., I want to filter even numbers from a sequence and calculate their squares.

{aside}
In mathematics and computer science, a [higher-order function](https://en.wikipedia.org/wiki/Higher-order_function) (HOF)
is a function that does at least one of the following:
    1. Takes one or more functions as arguments
    2. Returns a function as its result.
{/aside}

Below is functional code that uses `map` and `filter` functions:

```ts
const numbers = [1, 2, 3, 4, 5];
const is_even = (number: number) => number % 2 == 0;
const squared = (number: number) => number**2;

console.log(numbers.filter(is_even).map(squared));

// Output:
// [4, 16]
```

As you can see, the above code is much safer, shorter, and more straightforward than the earlier imperative code. There are no variable assignments or state modifications.
Both the `is_even` and `squared` are pure functions because they return the same output for the same input without
any side effects.

There is another way to implement the above code using a composition of functions. We can define reusable functions and
compose more specific ones from general-purpose ones. Below is an example of function composition using the
`compose` function from the [ramda](https://ramdajs.com/) library. The example also uses the `partial`
function from the same library to create
partially applied functions. For example, the `filterEven` function is a partially applied `filter` function where
the first parameter is bound to the `isEven` function. Similarly, the `mapSquared` function is a partially
applied `map` function where the first parameter is bound to the `squared` function. The `compose` function composes two
or more functions in the following way: `compose(f, g)(x)` is the same as `f(g(x))` and `compose(f, g, h)(x)` is same as `f(g(h(x)))`
and so on. You can compose as many functions as you need/want.

```ts
import { compose, filter, map, partial } from "ramda";


const numbers = [1, 2, 3, 4, 5];
const isEven = (number: number) => number % 2 == 0;
const squared = (number: number) => number**2;
const filterEven = partial(filter, [isEven]);
const mapSquared = partial(map, [squared]);
const doubledEven = compose(mapSquared, filterEven);
console.log(doubledEven(numbers));

// Output:
// [4, 16]
```

In the above example, all the following functions can be made re-usable and put into a library:

- `isEven`
- `squared`
- `filterEven`
- `mapSquared`

Modern code should favor functional programming over imperative programming when possible. As compared to functional programming,
imperative programming comes with the following disadvantages:

1. *Mutable state*: Imperative programming relies heavily on mutable state, where variables can be modified throughout the program's execution. This can lead to subtle bugs and make the program harder to reason about, as the state can change unpredictably. In functional programming, immutability is emphasized, reducing the complexity of state management and making programs more reliable.
2. *Side effects*: Imperative programming often involves side effects, where functions or operations modify the state or interact with the external world. Side effects make the code harder to test, reason about, and debug. On the other hand, functional programming encourages pure functions with no side effects, making the code more modular, reusable, and testable.
3. *Concurrency and parallelism*: Imperative programming can be challenging to parallelize and reason about in concurrent scenarios. Since mutable state can be modified by multiple threads or processes, race conditions and synchronization issues can occur. Functional programming, with its emphasis on immutability and pure functions, simplifies concurrency and parallelism by eliminating shared mutable state.
4. *Lack of referential transparency*: Imperative programming tends to rely on assignments and statements that modify variables in place. This can lead to code that is difficult to reason about due to implicit dependencies and hidden interactions between different parts of the code. In functional programming, [referential transparency](https://en.wikipedia.org/wiki/Referential_transparency) is a key principle where expressions can be replaced with their values without changing the program's behavior. This property allows for easier understanding, debugging, and optimization.

Pure imperative programming also quickly leads to code duplication, lack of modularity, and abstraction issues. These are issues
that can be solved using object-oriented programming.

## Multi-Paradigm Programming Principle

> ***You should not use a single programming paradigm only.***

To best utilize both object-oriented and functional programming (FP) when developing software, you can
leverage the strengths of each paradigm in different parts of your codebase. Use domain-driven design (DDD) and object-oriented design to design
the application: interfaces and classes. Implement classes by encapsulating related behavior and (possibly mutable, but aim for immutable) state in the classes.
Apply OOP principles like *SOLID principles* and  *design patterns*. These principles and patterns make code modular and
easily extensible without accidentally breaking existing code. Use FP as much as possible when implementing class and instance methods.
Embrace functional composition by creating pure functions that take immutable data as input and always produce the same output for the same input without side effects.
Use higher-order functions to compose functions and build complex operations from simpler ones. For example, utilize higher-order functions in OOP by passing functions as arguments to methods
or using them as callbacks. This allows for greater flexibility and modularity, enabling functional-style operations within an OOP framework.
Also, remember to use functional programming libraries, either the standard or 3rd party libraries. Consider using functional techniques for error handling,
such as *Either* or *Maybe/Optional* types. This helps you manage errors without exceptions, promoting more predictable and robust code. This is
because function signatures don't tell if they can raise an error. You must remember to consult the documentation and check if a function can raise an error.

Aim for immutability within your codebase, regardless of the paradigm. Immutable data reduces complexity, avoids shared mutable state,
and facilitates reasoning about your code. Favor creating new objects or data structures instead of modifying existing ones.

## Why is Object-Oriented Programming Hard?

The basic concepts of OOP are not complex to understand, so why is it hard to master OOP?
Below are listed things that can make OOP hard:

- You cannot rush into coding. You must have patience and perform object-oriented design (OOD) first
- You cannot get the OOD right on the first try. You need to have discipline and time reserved for refactoring.
- The difference between object composition and inheritance is not correctly understood, and inheritance is used in place of object composition, making the OOD flawed
- SOLID principles are not understood or followed
    - It can be challenging to create optimal-sized classes and functions with a single responsibility
        - For example, you might have a single-responsibility class, but the class is too big. You must realize that you must split the class into smaller classes the original class is composed of. Each of these smaller classes has a single responsibility on a lower level of abstraction compared to the original class
    - Understanding and following the open-closed principle can be challenging
      - The idea of the open-closed principle is to avoid modifying existing code and thus avoid breaking any existing working code. For example, If you have a collection class and need a thread-safe collection class, don't modify the existing one, e.g., by adding a constructor flag to tell if a collection should be thread-safe. Instead, create a totally new class for thread-safe collections.
    - Liskov's substitution principle is not as simple as it looks
      - For example, suppose you have a base class `Circle` with a `draw` method. If you derive a `FilledCircle` class from the `Circle` class, you must implement the `draw` function so that it first calls the base class method. In some cases, it is possible to override the base class method with the derived class method
    - Interface segregation is usually left undone if it is not immediately needed. This might hinder the extensibility of the codebase in the future
    - In many texts, the dependency inversion principle is explained in complicated terms. The dependency inversion principle generally means programming against interfaces instead of concrete class types.
- You don't understand the value of dependency injection and are not using it
  - Dependency injection is a requirement for effectively utilizing some other principles, like the open-closed principle
  - Dependency injection makes unit testing a breeze because you can create mock implementations and inject them into the tested code
- You don't know/understand design patterns and don't know when and how to use them
  - Familiarize yourself with the design patterns
  - Some design patterns are more useful than others. You use some patterns basically in every codebase, and some patterns you rarely use
  - Many design patterns help make code more modular and extensible and help avoid modifying existing code. Modifying existing code is always a risk. You can introduce bugs in already working code. These bugs are sometimes very subtle and hard to discover.
  - Learning the design patterns takes time. It can take years to master them, and mastery is only achieved by repeatedly using them in real-life codebases.

Mastering OOD and OOP is a life-long process. You are never 100% ready. The best way to become better in OOD and OOP, as in any other thing
in your life, is practicing. I have been practicing OOD and OOP for 29 years and am still improving and learning something new regularly.
Start a non-trivial (hobby/work) project and try to make the code 100% clean. Whenever you think you are ready
with it, leave the project for some time and later come back to the project, and you might be surprised to notice that there are several things
still needing improvement!

## SOLID Principles

All five [SOLID principles](https://en.wikipedia.org/wiki/SOLID) are covered in this section. The *dependency inversion principle* is generalized
as a *program against interfaces principle*. The five SOLID principles are the following:

- Single responsibility principle
- Open-closed principle
- Liskov's substitution principle
- Interface segregation principle
- Dependency inversion principle (Generalization: program against interfaces principle)

### Single Responsibility Principle

> ***Classes should have one responsibility: representing a thing or providing a single functionality.***
> ***Functions should do one thing only.***

Single responsibility should be at a particular abstraction level. A class or function can become too large if the abstraction level is too high.
Then, split the class or function into multiple classes or functions on a lower
level of abstraction. The single responsibility principle is akin to the [separation of concerns](https://en.wikipedia.org/wiki/Separation_of_concerns) principle.
In the *separation of concerns* principle, you divide a software component into distinct "sections". A section can be any size, e.g., a subdomain (package),
module, class, or function.

Suppose you need to implement configuration reading and parsing for your software component. Reading and parsing are two different
concerns and should be implemented in separate "sections", which in practice means implementing them in different class hierarchies: a `ConfigReader` interface
with various implementation classes, like `FileSystemConfigReader`, `DatabaseConfigReader`, `RestApiConfigReader`, and a `ConfigParser` interface with various implementation
classes like `JsonConfigParser`, `YamlConfigParser`, `TomlConfigParser`, `XmlConfigParser`, etc.

Single responsibility helps to achieve *high cohesion*, which
is the target of good design (another target is *low coupling*, which we will discuss later). If your class or function has multiple distinct responsibilities (and reasons for change),
then the class or function does not have high cohesion. Cohesion, in a class, for example, means the level that class methods belong together (i.e., change for the same reason).
If you have a class that performs user authentication and configuration parsing, you have a class with two distinct responsibilities at the same abstraction level. That class is against the *single responsibility principle*,
and has lower cohesion because it has two reasons to change. One great sign of a class possibly having multiple responsibilities is that it can be hard to figure out a good name for the class, or if you could put an *and* word in the class name, like `UserAuthenticatorAndConfigParser`.
*High cohesion* and *low coupling* are both part of the [GRASP](https://en.wikipedia.org/wiki/GRASP_(object-oriented_design)) principles.

Another great example of the separation of concerns principle is the *clean microservice design (or architecture) principle* where
you separate the microservice's business logic from the microservice's input and output. In this way, it is easy to make the microservice
support various inputs and outputs without modifying the business logic "section". The clean microservice design (or architecture) principle
is discussed later in this chapter.

Let's get back to the single responsibility principle. Each class should have a single dedicated purpose. A class can represent a single thing, like
a bank account (`Account` class) or an employee (`Employee` class), or provide a single functionality
like parsing a configuration file (`ConfigFileParser` class) or calculating tax (`TaxCalculator` class).

We should not create a class representing a bank account and an employee. It is simply wrong.
Of course, an employee can *have* a bank account. But that is a different thing. It is called object composition.
In object composition, an `Employee` class object contains an `Account` class object. The `Employee` class still represents one thing:
An employee (who can have a bank account). Object composition is covered in more detail later in this chapter.

At the function level, each function should perform a single task. The function name should describe what task the function
performs, meaning each function name should contain a verb. The function name should not contain the word *and*
because it can mean that the function is doing more than one thing or you haven't named the function on a correct abstraction level.
You should not name a function according to the steps it performs (e.g., `doThisAndThatAndThenSomeThirdThing`) but
instead, use wording on a higher level of abstraction.

When a class represents something, it can contain multiple methods. For example, an `Account` class can have
methods like `deposit` and `withdraw`. It is still a single responsibility if these methods are simple enough
and if there are not too many methods in the class.

Below is a real-life Java code example where the *and* word is used in the function name:

```java
void deletePageAndAllReferences(Page page) {
  deletePage(page);
  registry.deleteReference(page.name);
  configKeys.deleteKey(page.name.makeKey());
}
```

In the above example, the function does two things: delete a page and remove all the references to that page.
But if we look at the code inside the function, we can realize that it is also doing a third thing: deleting a page key from configuration keys.
So should the function be named `deletePageAndAllReferencesAndConfigKey`? It does not sound reasonable.
The problem with the function name is that it is at the same level of abstraction as the function statements.
The function name should be at a higher level of abstraction than the statements inside the function.

How should we then name the function? I cannot say for sure because I don't know the context of the function.
We could name the function just `delete`. This would tell
the function caller that a page will be deleted. The caller does not need to know all the actions
related to deleting a page. The caller just wants a page to be deleted. The function implementation should fulfill that
request and do the needed housekeeping tasks, like removing all the references to the page being deleted and so on.

Let's consider another example with [React Hooks](https://react.dev/reference/react/hooks). React Hooks has a function named `useEffect`, which can be used to enqueue
functions to be run after component rendering. The `useEffect` function can be used to run some code
after the initial render (after the component mount), after every render, or conditionally. This is quite a
responsibility for a single function. Also, the function's name does not reveal its purpose; it sounds abstract. The word *effect*
comes from the fact that this function is used to enqueue other functions with side effects to be run. The term [side effect](https://en.wikipedia.org/wiki/Side_effect_(computer_science))
might be familiar to functional programmers. It indicates that a function is not pure because it causes side effects.

Below is an example of a React functional component:

{format: jsx, type: code}
![MyComponent.jsx](resources/chapter2/code/MyComponent.jsx)

In the above example, the `useEffect` call makes calls to functions `startFetchData` and `subscribeToDataUpdates`
to happen after the initial render because of the supplied empty array for dependencies
(the second parameter to the `useEffect` function). The cleanup function returned from the function supplied to `useEffect`
will be called before the effect will be rerun or when the component is unmounted and in this case, only on unmount
because the effect will only run once after the initial render.

Let's imagine how we could improve the `useEffect` function. We could split the rather abstract-sounding `useEffect` method into multiple methods on a lower level
of abstraction. The functionality related to mounting and
unmounting could be separated into two different functions: `afterMount` and `beforeUnmount`. Then, we could change the above example
to the following piece of code:

```jsx
export default function MyComponent() {
  function startFetchData() {
    // ...
  }

  function subscribeToDataUpdate() {
    // ...
  }

  function unsubscribeFromDataUpdate() {
    // ...
  }

  afterMount(startFetchData, subscribeToDataUpdates);
  beforeUnmount(unsubscribeFromDataUpdates)

  // JSX to render
  return ...;
}
```

The above example is cleaner and much easier for a reader to understand than the original example. There are no
multiple levels of nested functions. You don't have to return a function to be executed on component unmount, and you don't
have to supply an array of dependencies.

Let's have another example of a React functional component:

```jsx
import { useEffect, useState } from "react";

export default function ButtonClickCounter() {
  const [clickCount, setClickCount] = useState(0);

  useEffect(() => {
    function updateClickCountInDocumentTitle() {
      document.title = `Click count: ${clickCount}`;
    }

    updateClickCountInDocumentTitle();
  });
}
```

In the above example, the effect is called after every render (because no dependencies array is supplied
for the `useEffect` function). Nothing in the above code clearly states what will be executed and when. We
still use the same `useEffect` function, but now it behaves differently than in the previous example. It
seems like the `useEffect` function is doing multiple things. How to solve this? Let's think hypothetically again.
We could extract functionality from the `useEffect` function and introduce yet another new function called `afterEveryRender` that can be called when we want something to happen after every render:

```jsx
export default function ButtonClickCounter() {
  const [clickCount, setClickCount] = useState(0);

  afterEveryRender(function updateClickCountInDocumentTitle() {
    document.title = `Click count: ${clickCount}`;
  });
}
```

The intentions of the above React functional component are pretty clear: It will update the click count in the
document title after every render.

Let's optimize our example so that the click count update happens only if the click count has changed:

```jsx
import { useEffect, useState } from "react";

export default function ButtonClickCounter() {
  const [clickCount, setClickCount] = useState(0);

  useEffect(() => {
    function updateClickCountInDocumentTitle() {
      document.title = `Click count: ${clickCount}`;
    }

    updateClickCountInDocumentTitle();
  }, [clickCount]);
}
```

Notice how `clickCount` is now added to the dependencies array of the `useEffect` function. This means
the effect is not executed after every render but only when the click count is changed.

Let's imagine how we could improve the above example. We could once again extract functionality from the `useEffect` function and introduce a new function that handles dependencies:
`afterEveryRenderIfChanged`. Our hypothetical example would now look like this:

```jsx
export default function ButtonClickCounter() {
  const [clickCount, setClickCount] = useState(0);

  afterEveryRenderIfChanged(
    [clickCount],
    function updateClickCountInDocumentTitle() {
      document.title = `Click count: ${clickCount}`;
  });
}
```

Making functions do a single thing at an appropriate level of abstraction also helped make the code more readable.
Regarding the original examples, a reader must look at the end of the `useEffect` function call to figure out in what
circumstances the effect function will be called. Understanding and remembering the difference between
a missing and empty dependencies array is cognitively challenging.

> ***Good code is such that it does not make the code reader think. At best, the code should read like beautifully written prose.***

In the above example, we can read like prose: *after every render if changed click count, update click count in document title*.

One idea behind the single responsibility principle is that it enables software development using the *open-closed principle*
described in the next section. When you follow the single responsibility principle and need
to add functionality, you add it to a new class, which means you don't need to modify an existing
class. You should avoid modifying existing code but extend it by adding new classes, each with a single responsibility.
Modifying existing code always poses a risk of breaking something that works.

### Open-Closed Principle

> ***Software code should be open for extension and closed for modification. Functionality in existing classes should not be modified, but new classes that implement a new or existing interface or extend an existing class should be introduced.***

Any time you find yourself modifying some method in an existing class, you should consider if
this principle could be followed and if the modification could be avoided. Every time you modify an existing class, you can
introduce a bug in the working code. The idea of this principle is to leave the working code untouched so it does not get accidentally broken.
When applying the *open-closed principle*, you create a kind of plugin architecture where new functionality is introduced as plugins (new
implementation classes) that are plugged into existing code using, e.g., factories and dependency injection.

The *open-closed principle* is called *protected variations* in the GRASP principles. The protected variation principle protects existing
classes from variations in other classes. For example, if you have a `ConfigReader` class that needs to parse the configuration, but the configuration format can vary. The `ConfigReader` class is protected from variations by introducing a `ConfigParser` interface for which various implementations can be provided. The `ConfigReader` depends only on the `ConfigParser` interface and does not need to know what
particular parsing implementation is actually used. There could be a `JsonConfigParser` class for parsing the configuration in JSON format, and later, a `YamlConfigParser` class could be introduced to parse the configuration in YAML format.
The `JsonConfigParser` class is also protected from variations because possible variations in configuration parsing can be introduced in new classes instead of modifying
an existing class.

Let's have an example where this principle is *not* followed. We have the following existing and working Java code:

```java
public interface Shape {
}


public class RectangleShape implements Shape {
  private int width;
  private int height;

  public RectangleShape(final int width, final int height) {
    this.width = width;
    this.height = height;
  }

  public int getWidth() {
    return width;
  }

  public int getHeight() {
    return height;
  }

  public void setWidth(final int newWidth) {
    width = newWidth;
  }

  public void setHeight(final int newHeight) {
    height = newHeight;
  }
}
```

Suppose we get an assignment to introduce support for square shapes. Let's try to modify the existing
`RectangleShape` class, because a square is also a rectangle:

```java
class RectangleShape(Shape):
    public class RectangleShape implements Shape {
      private int width;
      private int height;

      // Rectangle constructor
      public RectangleShape(final int width, final int height)  {
        this.width = width;
        this.height = height;
      }

      // Square constructor
      public RectangleShape(final int sideLength) {
        this.width = sideLength;
        this.height = sideLength;
      }

      public int getWidth() {
          return width;
      }

      public int getHeight() {
          return height;
      }

      public void setWidth(final int newWidth) {
        if (height == width) {
          //noinspection SuspiciousNameCombination
          height = newWidth;
        }

        width = newWidth;
      }

      public void setHeight(final int newHeight) {
        if (height == width) {
          //noinspection SuspiciousNameCombination
          width = newHeight;
        }

        height = newHeight;
      }
    }
```

We needed to add a factory method for creating squares and modify two methods in the class. Everything works okay when we run tests.
But we have introduced a subtle bug in the code: If we create a rectangle
with an equal height and width, the rectangle becomes a square, which is probably not what is wanted. This is
a bug that can be hard to find in unit tests. This example showed that modifying an existing class can be problematic.
We modified an existing class and accidentally broke it.

A better solution to introduce support for square shapes is to use the *open-closed principle* and create a new class
that implements the `Shape` protocol. Then, we don't have to modify any existing class, and there is no risk of accidentally
breaking something in the existing code. Below is the new `SquareShape` class:

```java
public class SquareShape implements Shape {
  private int sideLength;

  public SquareShape(final int sideLength) {
    this.sideLength = sideLength;
  }

  public int getSideLength() {
    return sideLength;
  }

  public void setSideLength(final int newSideLength) {
    sideLength = newSideLength;
  }
}
```

An existing class can be safely modified by adding a new method in the following cases:

1) The added method is a pure function, i.e., it always returns the same value for the same arguments and does not have side effects, e.g., it does not modify the object's state.
2) The added method is read-only and tread-safe, i.e., it does not modify the object's state and accesses the object's state in a thread-safe manner in the case of multithreaded code. An example of a read-only method in the `Shape` class would be a method that calculates a shape's area.
3) Class is immutable, i.e., the added method (or any other method) cannot modify the object's state

There are a couple of cases where the modification of existing code is needed. One example is factories. When you
introduce a new class, you need to modify the related factory to be able to create an instance of that new class.
For example, if we had a `ShapeFactory` class, we would need to modify it to support the creation of `SquareShape` objects.
Fortunately, this modification is simple: Just adding a new case branch. The probability of introducing a bug is very low.
Factories are discussed later in this chapter.

Another case is adding a new enum constant. You typically need to modify existing code to handle the new enum constant.
If you forget to add the handling of the new enum constant somewhere in the existing code, typically, a bug will arise. For this reason,
You should always safeguard switch-case statements with a *default* case that throws an exception and safeguard if/else if structures with an else branch that throws an exception.
You can also enable your static code analysis tool to report an issue if a switch statement's *default* case or
an else branch is missing from an if/else if structure. Also, some static code analysis tools can report an issue if you miss handling
an enum constant in a match-case statement.

Here is an example of safeguarding an if/else if structure in Java:

```java
public enum FilterType {
  INCLUDE,
  EXCLUDE
}


public interface Filter {
  boolean isFilteredOut(...);
}


public class FilterImpl implements Filter {
  private final FilterType filterType;

  public FilterImpl(final FilterType filterType, ...) {
    this.filterType = filterType;
    // ...
  }

  public boolean isFilteredOut(...) {
    if (filterType == FilterType.INCLUDE) {
      // ...
    } else if (filterType == FilterType.EXCLUDE) {
      // ..
    } else {
      // Safeguarding
      throw new IllegalArgumentException("Invalid filter type");
    }
  }
}
```

In TypeScript, safeguarding might be needed for union types also:

```ts
type FilterType = 'include' | 'exclude';

if (filterType === 'include') {
  // ...
} else if (filterType === 'exclude') {
  // ...
} else {
  // Safeguarding
  throw new Error("Invalid filter type");
}
```

In the future, if a new literal is added to the `FilterType` type and you forget to update the if-statement, you
get an exception thrown instead of silently passing through the if-statement without any action.

We can notice from the above examples that if/else if structures could be avoided
with a better object-oriented design. For instance, we could create a `Filter` protocol and two separate classes,
`IncludeFilter` and `ExcludeFilter`. The classes implement the `Filter` protocol. Using object-oriented design allows us
to eliminate the `FilterType` enum and the if/else if structure.
This is known as the *replace conditionals with polymorphism* refactoring technique. Refactoring is discussed more
in the next chapter. Below is the above example refactored to be more object-oriented:

```python
public interface Filter {
  boolean isFilteredOut(...);
}


public class IncludeFilter implements Filter {

  // ...

  public boolean isFilteredOut(...) {
    // ...
  }
}


public class ExcludeFilter implements Filter {

  // ...

  public boolean isFilteredOut(...) {
    // ...
  }
}
```

### Liskov's Substitution Principle

> ***Objects of a superclass should be replaceable with objects of its subclasses without breaking the application. I.e.,***
> ***objects of subclasses behave the same way as the objects of the superclass.***

Following *Liskov's substitution principle* guarantees semantic interoperability of types in a type hierarchy.

Let's have an example with a Java `RectangleShape` class and a derived `SquareShape` class:

```java
public interface Shape {
  void draw();
}


public class RectangleShape implements Shape {
  private int width;
  private int height;

  public RectangleShape(final int width, final int height) {
    this.width = width;
    this.height = height;
  }

  public void draw() {
    // ...
  }

  public int getWidth() {
    return this.width;
  }

  public int getHeight() {
    return this.height;
  }

  public void setWidth(final int newWidth) {
    width = newWidth;
  }

  public void setHeight(final int newHeight) {
    height = newHeight;
  }
}


public class SquareShape extends RectangleShape {
  public SquareShape(final int sideLength) {
    super(sideLength, sideLength);
  }

  public void setWidth(final int newWidth) {
    super.setWidth(newWidth);
    //noinspection SuspiciousNameCombination
    super.setHeight(newWidth);
  }

  public void setHeight(final int newHeight) {
    //noinspection SuspiciousNameCombination
    super.setWidth(newHeight);
    super.setHeight(newHeight);
  }
}
```

The above example does not follow Liskov's substitution principle because you cannot set a square's width and height separately.
This means that a square is not a rectangle from an object-oriented point of view. Of course, mathematically, a square is a rectangle. But when
considering the above public API of the `RectangleShape` class, we can conclude that a square is not a rectangle because
a square cannot fully implement the API of the `RectangleShape` class.
We cannot substitute a square object for a rectangle object. What we need to do is to implement the `SquareShape` class without
deriving from the `RectangleShape` class:

```java
public class SquareShape implements Shape {
  private int sideLength;

  public SquareShape(final int sideLength) {
    this.sideLength = sideLength;
  }

  public void draw() {
    // ...
  }

  public int getSideLength() {
    return this.sideLength;
  }

  public void setSideLength(final int newSideLength) {
    sideLength = newSideLength;
  }
}
```

Let's have another example where we have the following two Java classes:

```java
public class Dog {
  public void bark() {
    // ...
  }

  public void walk() {
    // ...
  }

  public void eat() {
    // ...
  }

  // ...
}


public class RoboticDog extends Dog {
  public void bark() {
    // Use super class method
    // get_sound()
  }

  public void walk() {
    // Use super class method
    // get_speed()
  }

  public void eat() {
    // Robotic dog cannot eat
    throw new UnsupportedOperationException();
  }
}
```

The above example does not follow *Liskov's substitution principle*, because a `RoboticDog` object cannot be used
in place of a `Dog` object. The `RoboticDog` object throws an exception if you call the `eat` method. There are two
solutions to the problem:

1) Abstract away
2) Composition over inheritance

Let's abstract the `eat` method to something common to both a dog and a robotic dog. We could change the
`eat` method to a `recharge` method:

```java
public class Dog {
  public void bark() {
    // ...
  }

  public void walk() {
    // ...
  }

  public void recharge() {
    // Eat
  }

  // ...
}


public class RoboticDog extends Dog {
  public void bark() {
    // Use super class method
    // get_sound()
  }

  public void walk() {
    // Use super class method
    // get_speed()
  }

  public void recharge() {
    // Charge the robot
  }
}
```

The other solution is to use composition over inheritance:

```java
public class RoboticDog {
  private final Dog dog;

  public RoboticDog(final Dog dog) {
      this.dog = dog;
  }

  public void bark() {
    // Use dog.get_sound()
  }

  public void walk() {
    // Use dog.get_speed()
  }
}
```

Liskov's substitution principle requires the following:

- A subclass must implement the superclass API and retain (or, in some cases, replace) the functionality of the superclass.
- A superclass should not have protected attributes because it allows subclasses to modify the state of the superclass, which can lead to incorrect behavior in the superclass.

Below is a Java example where a subclass extends the behavior of a superclass in the `do_something` method. The functionality of the superclass is retained in the subclass
making a subclass object substitutable for a superclass object.

```java
public class SuperClass {
  // ...

  public void doSomething() {
    // ...
  }
}

public class SubClass extends SuperClass {
  // ...

  public void doSomething() {
    super.doSomething();

    // Some additional behaviour...
  }
}
```

Let's have a concrete example of using the above strategy. We have the following `CircleShape` class defined:

```java
public interface Shape {
  void draw();
}


public class CircleShape implements Shape {
  public void draw() {
    // draw the circle stroke
  }
}
```

Next, we introduce a class for filled circles:

```java
public class FilledCircleShape extends CircleShape {
  public void draw() {
     super.draw(); // draws the circle stroke
     // Fill the circle
  }
}
```

The `FilledCircleShape` class fulfills the requirements of Liskov's substitution principle. We can use an instance of the
`FilledCircleShape` class everywhere where an instance of the `CircleShape` class is wanted. The `FilledCircleShape` class
does all that the `CircleShape` class does, plus adds some behavior (= fills the circle).

You can also completely replace the superclass functionality in a subclass:

{title: "ReverseArrayList.java"}
```java
public class ReverseArrayList<T> extends ArrayList<T>
{
  @Override
  public Iterator<T> iterator() {
    return new ReverseListIterator<>(this);
  }
}
```

The above subclass implements the superclass API and retains its behavior: The `iterator` method still returns an iterator.
It just returns a different iterator compared to the superclass.

### Interface Segregation and Multiple Inheritance Principle

> ***No class should depend on other classes' methods it does not use.***

When following the *interface segregation principle*, you split larger interfaces into smaller interfaces so that no one should depend on something it does not use.
Let's have an example where we have the following classes:

```java
public interface InterfaceA {
  void method1();
  void method2();
  void method3();
  void method4();
  void method5();
}


public class ClassB {
  private final InterfaceA someAttribute;

  // Depends on InterfaceA but
  // uses only the following methods:
  // method1, method2, method3
}


public class ClassC {
  private final InterfaceA someAttribute;

  // Depends on InterfaceA and
  // uses all methods from the ProtocolA
}
```

The `ClassB` is depending on `method4` and `method5` even if it does not use them. We need to apply the *interface segregation principle* and segregate a smaller interface from the `InterfaceA`:

```java
public interface InterfaceA1 {
  void method1();
  void method2();
  void method3();
}


public interface InterfaceA extends InterfaceA1 {
  void method4();
  void method5();
}


public class ClassB() {
  private final InterfaceA1 someAttribute;

  // Depends on InterfaceA1
  // and uses all methods of it
}


public class ClassC() {
  private final InterfaceA someAttribute;

  // Depends on InterfaceA
  // and uses all methods of it
}
```

*Interface segregation principle* is a way to reduce coupling in your software component. A software component's design
is considered the most optimal when it has *low coupling* between classes and *high cohesion* in classes. In the above example, the `ClassB`
only depends on the three methods provided by the `ProtocolA1`, not all the five methods provided by the `ProtocolA`.

Next, we will have examples of an extreme case of the *interface segregation principle*: Segregating larger interfaces to microinterfaces with a single capability/behavior and constructing larger interfaces by
inheriting multiple microinterfaces. Let's have a Java example with several automobile classes:

```java
public interface Automobile {
  void drive(final Location start, final Location destination);
  void carryCargo(final double volumeInCubicMeters, final double weightInKgs);
}


public class PassengerCar implements Automobile {
  // Implement drive and carryCargo
}


public class Van implements Automobile {
  // Implement drive and carryCargo
}


public class Truck implements Automobile {
  // Implement drive and carryCargo
}


public interface ExcavatingAutomobile extends Automobile {
  void excavate(...);
}


public class Excavator implements ExcavatingAutomobile {
  // Implement drive, carryCargo and excavate
}
```

Notice how the `Automobile` interface has two methods declared. This can limit our software if we
later want to introduce other vehicles that could be just driven but unable to carry cargo. We should
segregate two microinterfaces from the `Automobile` protocol in an early phase. A microinterface defines a single capability
or behavior. After segregation, we will have the following two microinterfaces:

```java
public interface Drivable {
  void drive(final Location start, final Location destination);
}


public interface CargoCarrying {
  void carryCargo(final double volumeInCubicMeters, final double weightInKgs);
}
```

Now that we have two interfaces, we can use these protocols separately in our codebase. For example, we can have
a list of drivable objects or a list of objects that can carry cargo. We still want to have an interface
for automobiles, though. We can use *interface multiple inheritance* to redefine the `Automobile` protocol to extend
the two microinterfaces:

```java
public interface Automobile extends Drivable, CargoCarrying {
}
```

If we look at the `ExcavatingAutomobile` interface, we can notice that it extends the `Automobile` interface and
adds excavating behavior. Once again, we have a problem if we want an excavating machine that is not
auto-mobile. The excavating behavior should be segregated into its own microinterface:

```java
public interface Excavating {
  void excavate(...);
}
```

We can once again use the interface multiple inheritance to redefine the `ExcavatingAutomobile` protocol as follows:

```java
public interface ExcavatingAutomobile
                   extends Excavating, Automobile {
}
```

The `ExcavatingAutomobile` interface now extends three microinterfaces: `Excavating`, `Drivable`,
and `CargoCarrying`. Where-ever you need an excavating, drivable, or cargo-carrying object in your codebase,
you can use an instance of the `Excavator` class there.

Let's have another example with a generic collection interface using TypeScript. We should be able to
traverse a collection and also be able to compare two collections for equality. First, we define a generic `Iterator`
interface for iterators. It has two methods, as described below:

```ts
interface MyIterator<T> {
  hasNextElement(): boolean;
  getNextElement(): T;
}
```

Next, we can define the collection interface:

```ts
interface Collection<T> {
  createIterator(): MyIterator<T>;
  equals(anotherCollection: Collection<T>): boolean;
}
```

`Collection` is an interface with two unrelated methods. Let's segregate those methods
into two microinterfaces: `Iterable` and `Equatable`. The `Iterable` interface is for objects that you can iterate over.
It has one method for creating new iterators. The `Equatable` interface's `equals` method is more generic than
the `equals` method in the above `Collection` interface. You can equate an `Equatable[T]` object with
another object of type `T`:

```ts
interface MyIterable<T> {
  createIterator(): MyIterator<T>;
}


interface Equatable<T> {
  equals(anotherObject: T): boolean;
}
```

We can use interface multiple inheritance to redefine the `Collection` interface as follows:

```ts
interface Collection<T> extends MyIterable<T>,
                                Equatable<Collection<T>> {
}
```

We can implement the `equals` method by iterating elements in two collections and checking if the elements are equal:

```ts
abstract class AbstractCollection<T> implements Collection<T> {
  abstract createIterator(): MyIterator<T>;

  equals(anotherCollection: Collection<T>): boolean {
    const iterator = this.createIterator();
    const anotherIterator = anotherCollection.createIterator();
    let collectionsAreEqual =
      this.areEqual(iterator, anotherIterator);

    if (anotherIterator.hasNextElement()) {
      collectionsAreEqual = false;
    }

    return collectionsAreEqual;
  }

  private areEqual(
    iterator: MyIterator<T>,
    anotherIterator: MyIterator<T>
  ): boolean {
    while (iterator.hasNextElement()) {
      if (anotherIterator.hasNextElement()) {
        if (iterator.getNextElement() !==
            anotherIterator.getNextElement()) {
         return false;
        }
      } else {
        return false;
      }
    }

    return true;
  }
}
```

Collections can also be compared. Let's introduce support for such collections. First, we define a generic `Comparable` interface for comparing an object with another object:

```ts
type ComparisonResult = 'isLessThan' | 'areEqual' | 'isGreaterThan' | 'unspecified';

interface Comparable<T> {
  compareTo(anotherObject: T): ComparisonResult;
}
```

Now, we can introduce a comparable collection protocol that allows comparing two collections
of the same type:

```ts
interface ComparableCollection<T>
            extends Comparable<Collection<T>>, Collection<T> {
}
```

Let's define a generic sorting algorithm for collections whose elements are comparable:

```ts
function sort<T, U extends Comparable<T>, V extends Collection<U>>(
  collection: V
): V {
  // ...
}
```

Let's create two interfaces, `Inserting` and `InsertingIterable` for classes whose instances elements can be inserted into:

```ts
interface Inserting<T> {
  insert(element: T): void;
}


interface InsertingIterable<T> extends Inserting<T>,
                                       MyIterable<T> {
}
```

Let's redefine the `Collection` interface to extend the `InsertingIterable` interface because a collection is iterable,
and you can insert elements into a collection.

```ts
interface Collection<T> extends InsertingIterable<T> {
}
```

Next, we introduce two generic algorithms for collections: `map` and `filter`. We can realize that those algorithms work
with more abstract objects than collections. We benefit from interface segregation because instead of
the `Collection<T>` interface, we can use the `MyIterable<T>` and
`InsertingIterable<T>` interfaces to create generic `map` and `filter` algorithms. Later it is possible to introduce some additional non-collection iterable
objects that can utilize the algorithms as well. Below is the implementation of the `map` and `filter` functions:

```ts
function map<T, U>(
  source: MyIterable<T>,
  mapped: (sourceElement: T) => U,
  destination: InsertingIterable<U>
): InsertingIterable<U> {
  const sourceIterator = source.createIterator();

  while(sourceIterator.hasNextElement()) {
    const sourceElement = sourceIterator.getNextElement();
    destination.insert(mapped(sourceElement));
  }

  return destination;
}


function filter<T>(
  source: MyIterable<T>,
  isIncluded: (sourceElement: T) => boolean,
  destination: InsertingIterable<T>
): InsertingIterable<T> {
  const sourceIterator = source.createIterator();

  while (sourceIterator.hasNextElement()) {
    const sourceElement = sourceIterator.getNextElement();

    if (isIncluded(sourceElement)) {
      destination.insert(sourceElement);
    }
  }

  return destination;
}
```

Let's define the following concrete collection classes:

```ts
class List<T> implements Collection<T> {
  constructor(...args: T[]) {
    // ...
  }

  // ...
}

class Stack<T> implements Collection<T> {
  // ...
}

class MySet<T> implements Collection<T> {
  // ...
}
```

Now, we can use the `map` and `filter` algorithms with the above-defined collection classes:

```ts
const numbers = new List<number>(1, 2, 3, 3, 3, 50, 60);
const isLessThan10 = (nbr: number) => nbr < 10;

const uniqueLessThan10Numbers =
  filter(numbers, isLessThan10, new MySet());

const doubled = (nbr: number) => 2 * nbr;
const stackOfDoubledNumbers = map(numbers, doubled, new Stack());
```

Let's create an asynchronous version of the `map` algorithm:

```python
interface MaybeCloseable {
  tryClose(): Promise<void>;
}


interface MaybeInserting<T> {
  tryInsert(value: T): Promise<void>;
}


interface MaybeCloseableInserting<T>
            extends MaybeCloseable, MaybeInserting<T> {
}


class MapError extends Error {
  // ...
}


async function tryMap<T, U>(
  source: MyIterable<T>,
  mapped: (sourceElement: T) => U,
  destination: MaybeCloseableInserting<U>
): Promise<void> {
  const sourceIterator = source.createIterator();

  try {
    while (sourceIterator.hasNextElement()) {
      const sourceElement = sourceIterator.getNextElement();
      await destination.tryInsert(mapped(sourceElement));
    }

    await destination.tryClose();
  } catch (error: any) {
    throw new MapError(error.message);
  }
}
```

Let's create a `FileLineInserter` class that implements the `MaybeCloseableInserting` interface:

```python
const fs = require('fs');

class FileLineInserter<T extends { toString(): string }>
        implements MaybeCloseableInserting<T> {
  private writeStream: FS.WriteStream;

  constructor(private readonly filePathName: string) {
    this.writeStream =
      fs.createWriteStream(this.filePathName, { flags: 'a' });
  }

  async tryInsert(value: T): Promise<void> {
    try {
      const writePromise = new Promise((resolve, reject) => {
        const line = value.toString() + '\n';

        this.writeStream.write(line, (error: any) => {
          if (error) {
            reject(error);
          } else {
            resolve(undefined);
          }
        });
      });

      await writePromise;
    } catch (error: any) {
      throw new Error(error.message);
    }
  }

  tryClose(): Promise<void> {
    this.writeStream.close();
    return Promise.resolve();
  }
}
```

Let's use the above-defined `try_map` algorithm and the `FileLineInserter` class to write doubled numbers (one number per line) to
a file named *file.txt*:

```ts
const numbers = new List<number>(1, 2, 3, 2, 1, 50, 60);
const doubled = (nbr: number) => 2 * nbr;

try {
  await tryMap(numbers, doubled, new FileLineInserter('file.txt'));
} catch(error: any) { // error will be always MapError type.
  console.log(error.message);
}
```

Python's standard library utilizes interface segregation and multiple interface inheritance in an exemplary
way. For example, the Python standard library defines the below listed abstract base classes (or interfaces) that implement a single
method only. I.e., they are microinterfaces.

| Abstract base class |  Method        |
| --------------------|----------------|
| `Container`         | `__contains__` |
| `Hashable`          | `__hash__`     |
| `Iterable`          | `__iter__`     |
| `Sized`             | `__len__`      |
| `Callable`          | `__call__`     |
| `Awaitable`         | `__await__`    |
| `AsyncIterable`     | `__aiter__`    |


Python standard library also contains the below abstract base classes that inherit from multiple (micro)interfaces:

| Abstract base class |  Inherits from                    |
|---------------------|-----------------------------------|
| `Collection`        | `Sized`, `Iterable`, `Container`  |
| `Sequence`          | `Collection`, `Reversible`        |


### Program Against Interfaces Principle (Generalized Dependency Inversion Principle)

> ***Do not write programs where internal dependencies are concrete object typesinstead, program against interfaces.***
> ***Exceptions to this rule are data classes with no behavior (not counting simple getters/setters) and utility classes***.

An interface is used to define an abstract base type. Various implementations that implement the interface can be introduced.
When you want to change the behavior of a program, you create a new class that implements an interface
and then use an instance of that class. In this way, you can practice the *open-closed principle*.
You can think of this principle as a prerequisite for using the *open-closed principle* effectively.

You should always program against an interface when the implementation can vary. On the other hand, you don't have to program against
an interface when the implementation is fixed. This is usually the case with utility classes. For example, you can
have a method for parsing an integer from a string. That is a method where implementation is fixed, and the method can be put
as a static method in a final utility class:

```java
// Utility class is declared final
// You should not be able to extend the utility class,
// because the method implementation are not expected to change
public final class ParseUtils {
  private ParseUtils() {
    // Utility class with static methods only
    // should have a private constructor
    // You should not be able to make instances of
    // the utility class
  }

  static int parseInt(final String string) {
    // ...
  }

  // Possible other methods ...
}
```

The above method implementation is not expected to change in the future. But if we have
a class for performing application configuration parsing, that functionality *can* change, and the *program
against interfaces principle* should be applied. We should create a `ConfigParser` interface and then provide one or more
implementations in various implementation classes, like `XyzFormatConfigParser`, `JsonConfigParser`, or `YamlConfigParser`.

The *program against interfaces principle* was presented by the *Gang of Four* in their book *Design Patterns* and
can be seen as a generalization of the *dependency inversion principle* from the SOLID principles:

> The *dependency inversion principle* is a methodology for loosely coupling software classes. When following the principle,
> the conventional dependency relationships from high-level classes to low-level classes are reversed, thus making the high-level
> classes independent of the low-level implementation details.

The *dependency inversion principle* states:

1) High-level classes should not import anything from low-level classes
2) Abstractions (= interfaces) should not depend on concrete implementations (classes)
3) Concrete implementations (classes) should depend on abstractions (= interfaces)

![Dependency Inversion Principle](resources/chapter2/images/dep_inv_principle.png)

*Dependency inversion principle* is the primary way to reduce coupling in a software component's code (the other way being the
*interface segregation principle*). When you use the principle, your classes are not coupled to any concrete implementation
but to an interface promising its implementors to offer certain functionality. For example, if your software component needs
a collection to store and retrieve items and occasionally get the item count, you should define an interface for the wanted functionality:

```java
public interface Collection<T> {
  void add(final T item);
  void remove(final T item);
  long size();
}
```

Being coupled to the above `Collection` interface is much weaker and less coupling than being coupled to a concrete implementation
like a stack or linked list.

An interface is always an abstract type and cannot be instantiated. Below is an example of an interface:

```java
public interface Shape {
  void draw();
  double calculateArea();
}
```

The name of an interface describes something abstract, which you cannot create an object of.
In the above example, `Shape` is something abstract. You cannot create an instance of `Shape` and then
draw it or calculate its area because you don't know what shape it is. But when a class implements an
interface, a concrete object of the class representing the interface can be created. Below is an example of three different classes
that implement the `Shape` interface:

```java
public class CircleShape implements Shape {
  private final int radius;

  public CircleShape(final int radius) {
    this.radius = radius;
  }

  public void draw() {
    // ...
  }

  public double calculateArea() {
    return Math.PI * radius * radius;
  }
}


public class RectangleShape implements Shape {
  private final int width;
  private final int height;

  public RectangleShape(final int width, final int height) {
    this.width = width;
    this.height = height;
  }

  public void draw() {
    // ...
  }

  public double calculateArea() {
    return width * height;
  }
}


public class SquareShape extends RectangleShape {
  public SquareShape(final int sideLength) {
   super(sideLength, sideLength);
  }
}
```

We should program against the `Shape` interface when using shapes in code. In the below example, we make
a high-level class `Canvas` dependent on the `Shape` interface, not on any of the low-level classes (`CircleShape`,
`RectangleShape` or `SquareShape`). Now, the high-level `Canvas` class and all the low-level shape classes depend on abstraction only,
the `Shape` interface. We can also notice that the high-level class `Canvas` does not import anything from the
low-level classes. Also, the abstraction `Shape` does not depend on concrete implementations (classes).

```java
public class Canvas {
  private final List<Shape> shapes = new ArrayList<>(10);

  public void add(final Shape shape) {
    shapes.add(shape);
  }

  public void drawShapes() {
    for(final var shape : shapes) {
      shape.draw();
    }
  }
}
```

A `Canvas` object can contain any shape and draw any shape. It can handle any of
the currently defined concrete shapes and any new ones defined in the future.

If you did not program against interfaces and did not use the dependency inversion principle, your `Canvas` class would
look like the following:

```java
public class Circle {
  public void draw() {
    // ...
  }
}


public class Rectangle {
  public void draw() {
    // ...
  }
}


public class Square {
  public void draw() {
    // ...
  }
}


public class Canvas {
  private final List<Circle> circles = new ArrayList<>(10);
  private final List<Rectangle> rectangles = new ArrayList<>(10);
  private final List<Square> squares = new ArrayList<>(10);

  public void addCircle(final Circle circle) {
    circles.add(circle);
  }

  public void addRectangle(final Rectangle rectangle) {
    rectangles.add(rectangle);
  }

  public void addSquare(final Square square) {
    squares.add(square);
  }

  public void drawShapes() {
    for(final var circle : circles) {
      circle.draw();
    }

    for(final var rectangle : rectangles) {
      rectangle.draw();
    }

    for(final var square : squares) {
      square.draw();
    }
  }
}
```

The above high-level `Canvas` class is coupled with all the low-level classes (`Circle`, `Rectangle`, and `Square`).
The type annotations in the `Canvas` class must be modified if a new shape type is needed. If something changes in the public API
of any low-level class, the `Canvas` class needs to be modified accordingly. In the above example, we implicitly specify
the interface for the `draw` method: it does not take arguments and returns nothing. Relying on implicit interfaces is not
a good solution, especially in non-trivial applications. It is better to program against interfaces and make interfaces explicit.

Let's have another example. If you have read books or articles about object-oriented design, you may have encountered
something similar as is presented in the below example:

```java
public class Dog {
  public void walk() {
    // ...
  }

  public void bark() {
    // ...
  }
}


public class Fish {
  public void swim() {
    // ...
  }
}


public class Bird {
  public void fly() {
    // ...
  }

  public void sing() {
    // ...
  }
}
```

Three concrete implementations are defined above, but no interface is defined. Let's say we are making
a game that has different animals. The first thing to do when coding the game is to remember to program
against interfaces and thus introduce an `Animal` interface that we can use as an abstract base type. Let's try to create
the `Animal` interface based on the above concrete implementations:

```python
public interface Animal {
  void walk();
  void bark();
  void swim();
  void fly();
  void sing();
}


public class Dog implements Animal {
  public void walk() {
    // ...
  }

  public void bark() {
    // ...
  }

  public void swim() {
    throw new UnsupportedOperationException();
  }

  public void fly() {
    throw new UnsupportedOperationException();
  }

  public void sing() {
    throw new UnsupportedOperationException();
  }
}


// Fish class ...
// Bird class ...
```

The above approach is wrong. We declare that the `Dog` class implements the `Animal` interface, but
it does not do that. It implements only methods `walk` and `bark` while other methods throw an exception. We should be
able to supply any concrete animal implementation where an animal is required. But it is impossible because
if we have a `Dog` object, we cannot safely call `swim`, `fly`, or `sing` methods because they will always throw an exception.

The problem is that we defined the concrete classes before defining the interface. That approach is wrong.
We should specify the interface first and then the concrete implementations. What we did above was the other way around.

When defining an interface, we should remember that we are defining an abstract base type, so we must think in abstract terms.
We must consider what we want the animals to do in the game. If we look
at the methods `walk`, `fly`, and `swim`, they are all concrete actions. But what is the abstract action common to these
three concrete actions? It is *move*. Walking, flying, and swimming are all ways
of moving. Similarly, if we look at the `bark` and `sing` methods, they are also concrete actions. What is the abstract action
common to these two concrete actions? It is *make sound*. And barking and
singing are both ways to make a sound. When we use these abstract actions, our `Animal` interface becomes the following:

```java
public interface Animal {
  void move();
  void makeSound();
}
```

We can now redefine the animal classes to implement the new `Animal` interface:

```java
public class Dog implements Animal {
  public void move() {
    // walk
  }

  public void makeSound() {
    // bark
  }
}


public class Fish implements Animal {
  public void move() {
    // swim
  }

  public void makeSound() {
    // Intentionally no operation
    // (Fishes typically don't make sounds)
  }
}


public class Bird implements Animal {
  public void move() {
    // fly
  }

  public void makeSound() {
    // sing
  }
}
```

Now, we have the correct object-oriented design and can program against the `Animal` interface. We can call the `move` method
when we want an animal to move and the `make_sound` method when we want an animal to make a sound.

After realizing that some birds don't fly at all, we can easily enhance our design. We can introduce two different implementations:

```java
public abstract class AbstractBird implements Animal {
  public abstract void move();

  public void makeSound() {
    // sing
  }
}

public class FlyingBird extends AbstractBird {
  public void move() {
    // fly
  }
}

public class NonFlyingBird extends AbstractBird {
  public void move() {
    // walk
  }
}
```

We might also later realize that not all birds sing but make different sounds. Ducks quack, for example.
Instead of using inheritance as was done above, an even better alternative is to use *object composition*.
We compose the `Bird` class of behavioral classes for moving and making sounds. This is called the *strategy pattern*,
and is discussed later in this chapter. We can give different moving and sound-making strategies for bird objects upon construction.

```java
public interface Mover {
  void move();
}

public interface SoundMaker {
  void makeSound();
}

public class Bird implements Animal {
  private final Mover mover;
  private final SoundMaker soundMaker;

  public Bird(
    final Mover mover,
    final SoundMaker soundMaker
  ) {
    this.mover = mover;
    this.soundMaker = soundMaker;
  }

  public void move() {
    mover.move();
  }

  public void makeSound() {
    soundMaker.makeSound();
  }
}
```

I don't advocate adding a design pattern name to code entity names, but for demonstration purposes, we could make an exception here, and I can show
how the code would look when making the *strategy pattern* explicit:

```java
public interface MovingStrategy {
  void move();
}


public interface SoundMakingStrategy {
  void makeSound();
}


public class Bird implements Animal {
  private final MovingStrategy movingStrategy;
  private final SoundMakingStrategy soundMakingStrategy;

  public Bird(
    final MovingStrategy movingStrategy,
    final SoundMakingStrategy soundMakingStrategy
  ) {
    this.movingStrategy = movingStrategy;
    this.soundMakingStrategy = soundMakingStrategy;
  }

  public void move() {
    movingStrategy.move();
  }

  public void makeSound() {
    soundMakingStrategy.makeSound();
  }
}
```

As you can see above, adding the design pattern name made many names longer without adding any significant value.
We should try to keep names as short as possible to enhance readability.
Now, we can create birds with various behaviors for moving and making sounds. We can use the *factory pattern* to
create different birds. The *factory pattern* is described in more detail later in this chapter. Let's introduce
three different moving and sound-making behaviors and a factory to make three kinds of birds: goldfinches, ostriches,
and domestic ducks.

```java
public class Flyer implements Mover {
  public void move() {
    // fly
  }
}

public class Runner implements Mover {
  public void move() {
    // run
  }
}

public class Walker implements Mover {
  public void move() {
    // walk
  }
}

public class GoldfinchSoundMaker implements SoundMaker {
  public void makeSound() {
    // Sing goldfinch specific songs
  }
}

public class OstrichSoundMaker implements SoundMaker {
  public void makeSound() {
    // Make ostrich specific sounds like whistles,
    // hoots, hisses, growls, and deep booming growls
    // that sound like the roar of a lion
  }
}

public class Quacker implements SoundMaker {
  public void makeSound() {
    // quack
  }
}

public enum BirdType {
  GOLDFINCH,
  OSTRICH,
  DOMESTIC_DUCK
}

public class BirdFactory {
  public Bird createBird(final BirdType birdType) {
    return switch(birdType) {
      case GOLDFINCH ->
        new Bird(new Flyer(),
                 new GoldfinchSoundMaker());

      case OSTRICH ->
        new Bird(new Runner(),
                 new OstrichSoundMaker());

      case DOMESTIC_DUCK ->
        new Bird(new Walker(),
                 new Quacker());

      default ->
        throw new IllegalArgumentException("Unsupported type");
    };
  }
}
```

## Clean Microservice Design Principle

> ***The clean microservice design promotes object-oriented design with the separation of concerns achieved***
> ***by dividing software into layers using the dependency inversion principle (programming against interfaces).***

Clean microservice design focuses on creating a microservice core (the model, business logic) that is devoid of technological concerns, pushing those to an outer input/output interface adaptation layer
that includes, e.g., the persistence mechanism (an output interface adapter) and controller (an input interface adapter), which can be considered as technological details that
have nothing to do with the microservice core. The benefit of this approach is that you can modify technological details without affecting the microservice core. Microservice's input comes from its clients and
output is anything external the microservice needs to access to fulfill requests from the input.

*Robert C. Martin a.k.a. Uncle Bob* uses the term *clean architecture* in his book *Clean Architecture* for this same principle. I do not use
the term *architecture* because I have reserved that term to designate the design of something larger (i.e., a software system) than a single service. Clean microservice design focuses on designing a single (micro)service conducting OOD in a particular fashion.

Clean microservice design is a relatively simple concept. If you have used the single responsibility principle, divided a microservice into layers, and been programming against interfaces (using the dependency inversion
principle), you may have applied the clean microservice design without knowing it. The clean microservice design principle also employs the *adapter pattern* from design patterns discussed later in this chapter. The adapter pattern is used in input and output interface adapters. We can create separate adapter classes for various input sources and output destinations. Many resources (books, websites, etc.) can explain the clean architecture in rather complex terms.

{aside}
If you are interested, there are similar concepts to *clean architecture* called [hexagonal architecture](https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)) and *onion architecture*.
They have the same basic idea of separating technology-related code from the business logic code, making it easy to change technological aspects of the
software without modifications to the business logic part. They can use different terms, and in hexagonal architecture, you
have co-centric hexagons instead of circles like in clean architecture, but the basic idea in all of them is the same.
{/aside}

Clean microservice design comes with the following benefits for the service:

- Not tied to any single framework
- Not tied to any single API technology like REST or GraphQL
- Unit testable
- Not tied to a specific client (works with web, desktop, console, and mobile clients)
- Not tied to a specific database or other storage technology
- Not dependent on any specific external service implementation

A clean API microservice design consists of the following layers:

- Input and output interface adapters (e.g., controllers, repositories, etc.)
- Use cases (i.e., the features the microservice exposes outside)
- (Business) Entities

Use cases and entities together form the *core* or *model* of the service, also called the *business logic*.
The outermost layer of the use case layer usually contains application service classes that implement the use cases. For example, one method
in a service class implements one use case. The use case layer can contain other layers of software needed to implement the
use cases. The service classes serve as a facade to those other layers. The service classes (i.e., the facade) are meant to be used by the *input
interface adapters*, i.e., the *controllers*. A controller is a common term used to describe an input interface adapter.
The controller should delegate to application service classes. It coordinates and controls the activity but should not do much work itself.
*Controller* is a pattern from GRASP principles. Similarly, a repository
is a common term used to describe an output interface adapter that stores information, usually in persistent storage.

![Clean Microservice Design](resources/chapter2/images/clean_arch.png)

The direction of dependencies in the above diagrams is shown with arrows. We can see that the microservice's clients depend
on the input interface adapter or *controller* we create. The controller depends on the use cases. The use case layer depends on (business) entities.
The purpose of the use case layer is to orchestrate operations on the (business) entities. In the above figure,
the parts of software that tend to change most often are located at the outer layers (e.g., controller technology like REST, GraphQL, and database)
The most stable part of the software is located at the center (entities).

Let's have an example of an entity: a bank account.
We know it is something that doesn't change often. It has a couple of key attributes: owner, account number, interest rate, and balance (and probably some other attributes),
but what a bank account is or does has remained the same for tens of years. But we cannot say the same for API technologies or database technologies.
Those are things that change at a much faster pace compared to bank accounts.
Because of the direction of dependencies,
changes in the outer layers do not affect the inner layers. The clean microservice design allows for easy API technology
and database change, e.g., from REST to gRPC or SQL to NoSQL database. All these changes can be made
without affecting the business logic (use case and entities layers).

Put entity-related business rules into entity classes. A `BankAccount` entity class should have
a method for withdrawing money from the account. That method should enforce a business rule: Withdrawal is possible only if the account has enough funds.
Don't put the withdrawal functionality into a service class and use `BankAccount`'s `get_balance` and `set_balance` accessors to perform the withdrawal
procedure in the service class. That would be against the *tell, don't ask principle* discussed later in this chapter.
Also, don't allow service classes to access sub-entities (and their methods) a `BankAccount` possibly contains.
That would be against DDD principles and the *law of demeter* (discussed later in this chapter).
DDD states that you should access an aggregate (`BankAccount`)  by its root only, not directly accessing any sub-entities.

Services orchestrate operations on one or more entities, e.g., a `BacklogItemService` can
have a `setSprint` method that will fetch a `Sprint` entity and pass it to the `BacklogItem` entity's `setSprint` method, which verifies
if the sprint for the backlog item can be set (only non-closed sprint can be set, i.e., current or future, not past sprints;
a new sprint for a closed backlog item cannot be set. The closed backlog item has to remain in the sprint where it was closed.)

Let's assume that the `BacklogItem` entity class is large and the `setSprint` would contain a lot of validation code,
making it even larger. In that case, you should extract a new class for backlog item sprint validation business rules,
and the `BacklogItem` class should be composed of that new behavioral class: `BacklogItemSprintValidator`. In the `BacklogItem` class's `setSprint` method,
the validation can be done with the following call: `sprintValidator.validate(newSprint, this)`.

### Real-Life Example

Let's have a real-life example of creating an API microservice called *order-service*, which handles orders in an
e-commerce software system. First, we define a REST API controller using Java and Spring Boot:

{title: "RestOrderController.java"}
```java
@RestController
@RequestMapping("/orders")
public class RestOrderController {
  @Autowired
  private OrderService orderService;

  @PostMapping
  @ResponseStatus(HttpStatus.CREATED)
  public final Order createOrder(
    @RequestBody final OrderArg orderArg
  ) {
    return orderService.createOrder(orderArg);
  }

  // Other API methods...
}
```

The API offered by the microservice depends on the controller, as seen in the earlier diagram. The API is currently a REST API, but
we could create and use a GraphQL controller. Then, our API, which depends on the controller, is a GraphQL API.
You can create a controller for any client-server technology, like gRPC or WebSocket. You can even create a controller
for standard input (stdin) or command line interface (CLI). A CLI controller reads command(s) from the command line arguments supplied to the microservice.
Remember that you can have multiple controllers active in the same microservice. Your microservice could be used by frontend clients using a REST controller,
or it could be used on the command line using its CLI controller.

Below is a partial implementation of a GraphQL controller with Java and Spring Boot:

{title: "GraphQlOrderController.java"}
```java
@Controller
public class GraphQlOrderController {
  @Autowired
  private OrderService orderService;

  @MutationMapping
  public final Order createOrder(
    @Argument final OrderArg orderArg
  ) {
    return orderService.createOrder(orderArg);
  }

  // Other API methods...
}
```

The `RestOrderController` and `GraphQlOrderController` classes depend on the `OrderService` interface, which is
part of the use case layer. Notice that the controllers do not rely on a concrete implementation of the use
cases but depend on an interface according to the *dependency inversion principle*. Below is the definition for
the `OrderService` protocol:

{title: "OrderService.java"}
```java
public interface OrderService {
  Order createOrder(OrderArg orderArg);
  Order getOrderById(Long id);
  Iterable<Order> getOrderByUserAccountId(Long userAccountId);
  void updateOrder(Long id, OrderArg orderArg);
  void deleteOrderById(Long id);
}
```

The below `OrderServiceImpl` class implements the `OrderService` protocol:

{title: "OrderServiceImpl.java"}
```java
@Service
public class OrderServiceImpl implements OrderService {
  private static final String ORDER = "Order";

  @Autowired
  private OrderRepository orderRepository;

  @Override
  public final Order createOrder(
    final OrderArg orderArg
  ) {
    final var order = Order.from(orderArg);
    return orderRepository.save(order);
  }

  @Override
  public final Order getOrderById(final Long id) {
    return orderRepository.findById(id)
             .orElseThrow(() ->
               new EntityNotFoundError(ORDER, id));
  }

  // Rest of the methods...
}
```

The `OrderServiceImpl` class has a dependency on an order repository. This dependency is also inverted. The `OrderServiceImpl` class depends only on the `OrderRepository` interface. The order repository is used to orchestrate the persistence of order entities.
Note that there is no direct dependency on a database. The term *repository* is abstract. It only means a place where data (entities) are stored. So the
repository can be implemented by a relational database, NoSQL database, file system, in-memory cache, message queue, or another microservice, to name a few.

Below is the `OrderRepository` protocol:

{title: "OrderRepository.java"}
```java
public interface OrderRepository {
  Order save(Order order);
  Order findById(Long id);
  // ...
}
```

The `OrderRepository` interface depends only on the `Order` entity class. You can introduce an *output interface adapter* class
that implements the `OrderRepository` interface. An output interface adapter adapts a particular concrete output destination (e.g., a database) to the `OrderRepository` interface.
Entity classes do not depend on anything except other entities to create hierarchical entities (aggregates). For example, the `Order`
entity consists of `OrderItem` entities. For example, you can define `SqlOrderRepository` *output interface adapter* class for an SQL database.
Changing the database to MongoDB can be done by creating a new `MongoDbOrderRepository` output interface adapter class that implements the `OrderRepository` interface.

![Clean Microservice Design for Order Service](resources/chapter2/images/04-05.png)

When implementing a clean microservice design, everything is wired together using configuration and dependency injection.
For example, an instance implementing the `OrderRepository` interface is created according to configuration and injected into an `OrderServiceImpl` instance by the Spring framework.
In the case of Spring, the dependency injector is configured using a configuration file and annotations. The configuration file
can be used to configure what database is used. Additionally, the Spring dependency injector creates an instance of the `OrderServiceImpl` class
and injects it where an `OrderService` object is wanted.

The dependency injector is the only place in a microservice that contains references to concrete implementations. In many
frameworks, the dependency injector is not a visible component, but its usage is configured using a configuration file
and annotations. For example, in Spring, the `@Autowired` annotation tells the dependency injector to
inject a concrete implementation into the annotated class field or constructor parameter. The _dependency injection principle_ is
discussed more in a later section of this chapter. The dependency inversion principle and dependency injection principle
usually go hand in hand. Dependency injection is used for wiring interface dependencies so that those become dependencies on concrete implementations, as seen in the figure below.

![Fig 3.4 Dependency Injection](resources/chapter2/images/di.png)

Let's add a feature where the shopping cart is emptied when an order is created:

{title: "ShoppingCartEmptyingOrderService.java"}
```java
@Service
public class ShoppingCartEmptyingOrderService implements OrderService {
  @Autowired
  private OrderRepository orderRepository;

  @Autowired
  private ShoppingCartService shoppingCartService;

  @Override
  public final Order createOrder(
    final OrderArg orderArg
  ) {
    final var order = Order.from(orderArg);
    final var savedOrder = orderRepository.save(order);
    shoppingCartService.emptyCart(order.userAccountId);
    return savedOrder;
  }
}
```

As you can see from the above code, the `ShoppingCartEmptyingOrderService` class does not depend on any concrete implementation of the
shopping cart service. We can create an *output interface adapter* class that is a concrete implementation of the `ShoppingCartService` interface.
For example, that interface adapter class connects to a particular external shopping cart service via a REST API. Once again,
the dependency injector will inject a concrete `ShoppingCartService` implementation to an instance of the `ShoppingCartEmptyingOrderService` class.

Note that the above `create_order` method is not production quality because it lacks a transaction.

Now we have seen examples of the following benefits of clean microservice design:

- Not tied to any single API technology like REST or GraphQL
- Not tied to a specific client (works with web, desktop, console, and mobile clients)
- Not tied to a specific database
- Not dependent on any specific external service implementation

The final benefit of clean microservice design:

- Not tied to any single framework

This is not always straightforward, and in our case, if we want to change our framework from Spring Boot to, e.g., Jakarta EE or Quarkus, we would have to make changes in places other than the application class and the controller only. This is because we are
using Spring-specific dependency injection and Spring-specific repository implementation. Being unable to replace the framework easily is the main drawback of
large frameworks like Spring, JakartaEE, Django, or Nest.js. Most of the time, you would be better off with small single-purpose libraries (remember the *microlibraries* from the first chapter)
instead of using a massive framework. Switching from one micro library to another is less effort than trying to change a big framework.

In my other book [Clean Code Principles And Patterns: Python Edition](https://leanpub.com/cleancodeprinciplesandpatternspythonedition), I give you an example where we easily change a *FastAPI*-based microservice
to a *Flask*-based microservice. In that example, we can change the used web framework by introducing two new small modules (application and controller modules). We do not touch any existing modules.
Thus, we can be confident that we do not break any existing functionality. We successfully apply the *open-closed principle* to our software.

It should be noted that the clean microservice design principle applies to other microservices with input or output, not just API microservices. We will have an example of this later in this chapter.
One additional benefit of the clean microservice design that has not been mentioned yet is that you can write component tests that test the software component's business logic (or the model) using fake input and output adapters instead of the real ones. Let's take a data exporter microservice as an example. It reads data from an input source (e.g., Apache Kafka) and transforms it in various ways before writing to an output destination (e.g., Apache Pulsar). We can test the transformation business logic using a fake input and output adapter injected into the software component. Running the tests will be fast because there is no need to spin up an instance of Kafka and Pulsar. Later, we can augment the component tests with some integration tests that test the integration to real input and output. We will talk more about component and integration tests in a later chapter.

## Vertical Slice Design Principle

*Vertical slice design* is also known as *vertical slice architecture*. Vertical slice design divides individual features into separate vertical slices.
In the source code repository, this means a separate directory for each vertical slice (feature).
You can also group these single feature directories under a domain directory. This makes navigating the code-base a breeze and finding a particular feature easy.
The main benefit of vertical slice design is that you can follow the open-closed principle when adding new features. There is no need to modify existing code and no risk of breaking existing functionality.
You can implement a vertical slice (a feature) as you wish, which is a clear benefit when different features have divergent requirements.
So, a vertical slice can contain a single class or multiple classes that form a layered design. Vertical slice design does not enforce any specific way.
However, using some design principles for a vertical slice implementation is good practice. I suggest to use the *clean microservice design*.
You can use vertical slice design and clean microservice design principles together. They are not mutually exclusive principles.

If your microservice is a small API, e.g., just containing a handful of simple CRUD operations, you don't necessarily get much benefit from vertical slicing.
If you are not using the vertical slice design, adding a new CRUD operation requires changes to existing classes. These changes include adding new methods to mostly immutable or stateless classes,
which can be considered extensions instead of modifications and are according to the open-closed principle. Adding a method
to an immutable or stateless class rarely breaks existing functionality in
existing methods. This is why I haven't used vertical slicing in the examples in this book.

For example, suppose you have an API
providing CRUD operations on a resource and want to use vertical slicing. In that case, you implement each CRUD operation separately
in different service/controller/repository classes. Here is an example of the source code directory layout for the *order-service* using
vertical slice design:

```
order-service
 src
     order
         common
            dtos
               InputOrder.py
               OutputOrder.py
            entities
                Order.py
         create
            CreateOrderRepository.py
            CreateOrderService.py
            CreateOrderServiceImpl.py
            RestCreateOrderController.py
            SqlCreateOrderRepository.py
         get
            GetOrderRepository.py
            GetOrderService.py
            GetOrderServiceImpl.py
            RestGetOrderController.py
            SqlGetOrderRepository.py
         update
            UpdateOrderRepository.py
            UpdateOrderService.py
            UpdateOrderServiceImpl.py
            RestUpdateOrderController.py
            SqlUpdateOrderRepository.py
         delete
             DeleteOrderRepository.py
             DeleteOrderService.py
             DeleteOrderServiceImpl.py
             RestDeleteOrderController.py
             SqlDeleteOrderRepository.py
```

## Class Organization Principle

A class should be organized in the following manner:

- Attributes first, methods after them
- Method order: constructor first, then public, then protected, and private last
- Order attributes and public methods by importance or logic, and if there is no logic or importance difference, order alphabetically
- Define public getters/properties/setters after other public methods
- Order private methods in the same order they are used in the public methods

An example of the *logic* is a `Rectangle` class with `width` and `height` attributes. You should give the `width` (x-axis length) before
`height` (y-axis length) because coordinates are given `x` first and then `y`.

Let's have an example with a `Circle` class.
It has the following attributes:

- `origin` (vital because you cannot draw a circle without knowing its origin)
- `radius` (vital because you cannot draw a circle without knowing its radius)
- `strokeColor` (this is a must attribute even though a default value could be used)
- `fillColor` (this is an optional attribute; a default value of `None` could be used)

Attributes `origin` and `radius` should be given in that order because you need to know the *origin* before you can start
drawing the circle.

The `Circle` class has the following methods:

- draw (most used method, should be the first)
- calculateArea (calculateXXX methods should be in alphabetical order because there is no logic or importance difference between methods)
- calculatePerimeter
- getters (in the same order as respective attributes)
- setters (in the same order as respective attributes)

Our `Circle` class written in TypeScript would like the following:

```ts
import Point from 'Point';


class Circle {
  constructor(
    private origin: Point,
    private radius: number,
    private strokeColor: string,
    private fillColor: string | null = null
  ) {
  }

  draw(): void {
    // ...
  }

  calculateArea(): number {
    // ...
  }

  calculatePerimeter(): number {
    // ..
  }


  getOrigin(): Point {
    return this.origin;
  }

  getRadius(): number {
    return this.radius;
  }

  getStrokeColor(): string {
    return this.strokeColor;
  }

  getFillColor(): string | null {
    return this.fillColor;
  }

  setOrigin(origin: Point): void {
    this.origin = origin;
  }

  setRadius(radius: number): void {
    this.radius = radius;
  }

  setStrokeColor(strokeColor: string): void {
    this.strokeColor = strokeColor;
  }

  setFillColor(fillColor: string | null): void {
    this.fillColor = fillColor;
  }
}
```

## Package/Directory, Class and Function Sizing Principle

> ***Use the maximum number of items (5-9) that can be stored in the short-term memory as the maximum size for a package/directory, class, or function.***

A package (or directory) should have a maximum of 5-9 modules. This allows you to find a specific module (file) in the package quickly.
If you have a package with many modules, it can be hard to find a specific module because they are listed in alphabetical order, and
you cannot apply any logical order to them. I usually create packages that may only contain 2 or 3 modules. For example, I could have
a *config* directory that has a *Config.java* module, and under the *config* directory, I could have a *parser* subdirectory that has the
following modules: *ConfigParser.java*, *JsonConfigParser.java* and *YamlConfigParser.java*.

A class should have a maximum of 5-9 attributes and 5-9 methods. If your class has more than 5-9 attributes, extract attributes to a new class. Let's say you have the following class:

```java
public class User {
  private String id;
  private String firstName;
  private String lastName;
  private String streetAddress;
  private String zipCode;
  private String city;
  private String country;
  private String phoneNumber;
  private String emailAddress;
  private Gender gender;
  private String username;
  private String password;
}
```

The above class can be refactored to use *value objects* to reduce the number of attributes:

```python
public class Name {
  private String firstName;
  private String lastName;
}


public class Address {
  private String streetAddress;
  private String zipCode;
  private String city;
  private String country;
}


public class ContactInfo {
  private String phoneNumber;
  private String emailAddress;
}


public class Credentials {
  private String username;
  private String password;
}

public class User {
  private String id;
  private Name name;
  private Address address;
  private ContactInfo contactInfo;
  private Gender gender;
  private Credentials credentials;
}
```

If you have too many methods, use the *extract class* refactoring technique explained
in the next chapter. As a rule of thumb, consider refactoring the class smaller if your class has more than 100-150 lines of code (not counting the import statements).
Here is an example. If you have a software component with 10,000 lines of code, you should have a new class for at least every approx. 200 lines of code,
meaning that the total number of classes in the software component should be at least 50, in practice, even more.

A function should have a maximum of 5-9 statements. If you have a longer function, extract a function or functions that the original function calls.
If you have a public method that calls several private methods, keep the number of those private methods small, preferably only one or two.
This is because if you write a unit test for the public method, testing becomes more complex the more private methods also need to be tested indirectly.
More about this topic also in the coming *testing principles* chapter.

A function should have a maximum of 5-9 parameters. You should prefer limiting the maximum number of parameters closer to 5 instead of 9.
You can reduce the number of parameters by using the *introduce parameter object* refactoring technique explained in the next chapter.

## Uniform Naming Principle

> ***Use a uniform way to name interfaces, classes, and functions.***.

This section presents conventions for uniformly naming interfaces, classes, and functions.

### Naming Interfaces and Classes

> ***Classes represent a thing or an actor. They should be named consistently so the class name ends with a noun. An interface represents an abstract thing, actor, or capability. Interfaces representing a thing or an actor should be named like classes but using an abstract noun. Interfaces representing a capability should be named according to the capability.***

When an interface represents an abstract thing, name it according to that abstract thing. For example, if you have a drawing application with
various geometrical objects, name the geometrical object interface `Shape`. It is a simple abstract noun.
Names should always be the shortest, most descriptive ones. There is no reason to name the geometrical object interface
as `GeometricalObject` or `GeometricalShape`, if we can use simply `Shape`.

When an interface represents an abstract actor, name it according to that abstract actor.
The name of an interface should be derived from the functionality it provides. For example, suppose there is a `parseConfig` method
in the interface. In that case, the interface should be named `ConfigParser`, and if an interface has a `validateObject` method,
the interface should be named `ObjectValidator`. Don't use mismatching name combinations like a `ConfigReader` interface with
a `parseConfig` method or an `ObjectValidator` interface with a `validateData` method.

When an interface represents a capability, name it according to that capability. Capability is something that
a concrete class is capable of doing. For example, a class could be sortable, iterable, comparable, equitable,
etc. Name the respective interfaces according to the capability: `Sortable`, `Iterable`, `Comparable`, and `Equitable`.
The name of an interface representing a capability usually ends with *able* or *ing*.

Don't name interfaces starting with the *I* prefix (or any other prefix or postfix). Instead, use an *Impl* postfix for
class names to distinguish a class from an interface, but only when needed. For example, if you have an interface named
`ConfigParser` and you have a concrete class implementing the interface and parsing configuration in JSON format,
name the class `JsonConfigParser`, not `JsonConfigParserImpl`, because the `Impl` prefix is not needed to distinguish between
the interface and implementing class. Remember that you should be programming against
interfaces, and if every interface has its name prefixed with an *I*, it just adds unnecessary noise to the code.

Some examples of class names representing a thing are: `Account`, `Order`, `RectangleShape`, and `CircleShape`. In a class
inheritance hierarchy, the names of classes usually refine the interface name or the base class name. For example,
if there is an `InputMessage` interface, then there can be different concrete implementations (= classes) of the `InputMessage` interface.
They can represent an input message from different sources, like `KafkaInputMessage` and `HttpInputMessage`.
And there could be different subclasses for different data formats:  `AvroBinaryKafkaInputMessage` or `JsonHttpInputMessage`.

The interface or base class name should be retained in the class or subclass name. Class names should follow the pattern:
`<class-purpose>` + `<interface-name>` or `<sub-class-purpose>` + `<super-class-name>`, e.g.,
`Kafka` + `InputMessage` = `KafkaInputMessage` and `AvroBinary` + `KafkaInputMessage` = `AvroBinaryKafkaInputMessage`.
Name abstract classes with the prefix `Abstract`. Java follows the above-described naming convention. For example, there exists an
`Executor` interface. The `ThreadPoolExecutor` class implements the `Executor` interface and `ScheduledThreadPoolExecutor`
class extends the `ThreadPoolExecutor` class.

If an interface or class name is over 20-30 characters long, consider abbreviating one or more words in the name.
The reason for this is to keep the code readable. Very long names are harder to read and slow a developer down. (Remember that
code is more often read than written).

Only use abbreviations that are commonly used and understandable for other developers. If a word does not have a good
abbreviation, don't abbreviate. For example, in the class name `AvroBinaryKafkaInputMessage`, we can only abbreviate
the `Message` to `Msg`. There are no well-established abbreviations for other words in the class name. Abbreviating `Binary` to `Bin`
is questionable because `Bin` could also mean a *bin*. Don't abbreviate a word if you benefit only one or two characters.
For example, there is no reason to abbreviate `Account` to `Accnt`.

Instead of abbreviating, you can shorten a name by dropping one or more words from it, provided readers can still easily understand it.
For example, if you have classes `InternalMessage`, `InternalMessageSchema` and
`InternalMessageField`, you could shorten the last two class names to `InternalSchema` and `InternalField`.
This is because these two classes are mainly used in conjunction with the `InternalMessage` class: An `InternalMessage` object has
a schema and one or more fields. You can also use nested classes: `InternalMessage.Schema` and `InternalMessage.Field`.
The problem with nested classes is that they can make the module too large.

If you have related classes and one or more class names require shortening, you should shorten all related class names
to keep the naming uniform. For example, if you have two classes, `ConfigurationParser` and `JsonConfigurationParser`, you
should shorten the names of both classes, not only the one longer than 19 characters. The new class names would be `ConfigParser` and `JsonConfigParser`.

If an interface or class name is less than 20 characters long, there is usually no need to shorten it.

Don't add a design pattern name to a class name if it does not bring any real benefit. For example, suppose we have
a `DataStore` interface, a `DataStoreImpl` class, and a class wrapping
a `DataStore` instance using the *proxy pattern* to add caching functionality to the wrapped data store. We should not name the
caching class `CachingProxyDataStore` or `CachingDataStoreProxy`. The word *proxy* does not add significant value,
so the class should be named simply `CachingDataStore`. That name clearly tells it is a question about a data store
with caching functionality. A seasoned developer notices from the `CachingDataStore` name that the class uses the *proxy pattern*. And if not,
looking at the class implementation will finally reveal it.

### Naming Functions

> ***Functions should do one thing, and the name of a function should describe what the function does. The function name usually contains a verb that indicates what the function does. The function name often starts with a verb, but exceptions exist. If a function returns a value, try to name the function so that the function name describes what it returns.***

The general rule is to name a function so that the purpose of the function is clear. A good function name should not
make you think. If a function name is *20 or more characters long*, consider abbreviating one or more words in the name.
The reason for this is to keep the code readable. Very long names are harder to read and slow a developer down. (Remember that
code is more often read than written). Only use abbreviations that are widely used and understandable for other developers.
If a word does not have a good abbreviation, don't abbreviate.

Below is an example of a protocol containing two methods named with simple verbs only. It is not necessary to name the methods as
`startThread` and `stopThread` because the methods are already part of the `Thread` interface, and it is self-evident what the `start` method
starts and what the `stop` method ends. You don't need to repeat the class name in the method name.

```java
public interface Thread {
  void start();
  void stop();
}
```

Let's have another Java example:

```java
grpcChannel.shutdown().awaitTermination(30, TimeUnit.SECONDS);
```

The above example has two issues with the `shutdown` function. Most people probably assume that calling the `shutdown` function will shut down the channel
and return after the channel is shut down without any return value. But now the `shutdown` function is returning something. It is not necessarily self-evident what it returns. But we can notice that the `shutdown` function does not wait for the channel termination.

It would be better to rename the `shutdown` function as `requestShutdown` because it better describes what the function does. Also, we should
name the `awaitTermination` to `awaitShutdown` because we should not use two different terms _shutdown_ and _termination_
to denote a single thing.

```java
final var shutdownPromise = grpcChannel.requestShutdown();
shutdownPromise.awaitShutdown(30, TimeUnit.SECONDS);
```

Let's have an example in JavaScript:

```js
fetch(url).then(response => response.json()).then(...);
```

In the above example, we have the following issue: the `fetch` function does not properly describe what it does.
According to the documentation, it fetches a resource. But it does not return a resource. It returns a response object.
Whenever possible, the function name should indicate what the function returns. The `fetch` performs an action on a resource and does not always return a resource.
The action is specified by giving an HTTP verb as a parameter to the function (GET is the default HTTP verb). The most common
actions are `GET`, `POST`, `PUT` and `DELETE`. If you issue a `PUT` request for a REST API, you don't usually get the resource back.
The same is, of course, valid for a `DELETE` request. You cannot get the resource back because it was just deleted.

We could name the function `performActionOnResource,` but that is a pretty long name and does not communicate the return value type.
We should name the `fetch` function
`makeHttpRequest` (or `sendHttpRequest`) to indicate that it is making an HTTP request. The new function name also
communicates that it returns an HTTP response. Another possibility is introducing an actor class with static methods for different HTTP
methods, for example: `HttpClient.makeGetRequest(url)`.

In the above example, the `json` function name is missing a verb. It should contain the verb _parse_
because that is what it is doing. The function name should also tell what it parses: the response body. We should also add a _try_
prefix to indicate that the function can throw (more about the _try_ prefix and error handling in general in the next chapter).
Below is the example with renamed functions:

```js
makeHttpRequest(url).then(response =>
  response.tryParseBodyJson()).then(...);
```

Many languages offer streams that can be written to, like the standard output stream. Streams are
usually buffered, and the actual writing to the stream does not happen immediately. For example, the below
statement does not necessarily write to the standard output stream immediately. It buffers the text to be written later
when the buffer is flushed to the stream. This can happen when the buffer is full, when some
time has elapsed since the last flush or when the stream is closed.

```js
stdOutStream.write(...);
```
</div>

The above statement is misleading and could be corrected by renaming the function to describe what it actually does:

```js
stdOutStream.writeOnFlush(...);
```

The above function name immediately tells a developer that writing happens only on flush, and the developer can consult the function documentation to determine when the flushing happens.

You can introduce a convenience method to perform a write with an immediate flush:

```js
// Instead of this:
stdOutStream.writeOnFlush(...);
stdOutStream.flush();

// User can do this:
stdOutStream.writeWithFlush(...);
```

Many times function's action is associated with a target, for example:

```java
public interface ConfigParser {
  Configuration tryParseConfig(...);
}
```

When a function's action has a target, it is useful to name the function using the following pattern: `<action-verb>` +
`<action-target>`, for example, `parse` + `config` = `parseConfig`.

We can drop the action target from the function name if the function's first parameter describes the action target. It is not wrong to keep the action target in the function name, though. But if it can be dropped, it usually
makes the function call statements read better. In the below example, the word "config" appears repeated: `tryParseConfig(configJson)`,
which makes the function call statement read a bit clumsy.

```java
final var configuration = configParser.tryParseConfig(configJson);
```

We can drop the action target from the function name:

```java
public interface ConfigParser {
  Configuration tryParse(final String configJson);
}
```

As shown below, this change makes the code read better, presuming we use a descriptive variable name. And we should,
of course, always use a descriptive variable name.

```java
final var configuration = configParser.tryParse(configJson);
```

Here is another example:

```java
public class Vector<T> {
  void pushBack(final T value); // OK
  void pushBackValue(final T value); // Not ideal,
                                     // word "value" repeated
}
```

```java
public class KafkaAdminClient {
  void create(final String topic);
}
```

The above function name should be used only when a topic is the only thing a Kafka admin client can create.
We cannot call the above function in the following way:

```java
kafkaAdminClient.create("xyz");
```

We need to introduce a properly named variable:

```java
final var topic = "xyz";
kafkaAdminClient.create(topic);
```

In languages where you can use named function parameters, the following is possible:

```
// Python
kafkaAdminClient.create(topic = "xyz");

// Swift
kafkaAdminClient.create(topic: "xyz");
```

#### Preposition in Function Name

> ***Use a preposition in a function name when needed to clarify the function's purpose.***

You don't need to add a preposition to a function name if the preposition can be assumed (i.e., the preposition is implicit).
In many cases, only one preposition can be assumed. If you have a function named `wait`, the preposition `for` can be assumed,
and if you have a function named `subscribe`, the preposition `to` can be assumed. We don't need to use function names `waitFor` and `subscribeTo`.

Suppose a function is named `laugh(person: Person)`. Now we have to add a preposition because none can be assumed.
We should name the function either `laughWith(person: Person)` or `laughAt(person: Person)`.

The following sections present examples of better naming some existing functions in programming languages.

#### Example 1: Renaming JavaScript Array Methods

Adding elements to a JavaScript array is done with the `push` method. Where does it push the elements? The method name
does not say anything. There are three possibilities:

1) At the beginning
2) Somewhere in the middle
3) At the end

Most definitely, it is not the second one, but it still leaves two possibilities. Most people correctly guess that it
pushes elements to the end. To make it 100% clear where the elements are pushed, this function should be named `pushBack`.
Then it does not make anybody think where the elements are pushed. Remember that a good function name does not make you think.

Popping an element from an array is done with the `pop` method. But where does it pop from? If you read the method description,
it tells that the element is popped at the back. To make it 100% clear, this method should be named `popBack`.

The `Array` class also contains methods `shift` and `unshift`. They are like `push` and `pop` but operate at the beginning of
an array. Those method names are extremely non-descriptive and should be named `popFront` and `pushFront`.

There are several methods in the JavaScript `Array` class for finding elements in an array. Here is the list of those methods:

- `find` (finds the first element where the given predicate is true)
- `findIndex` (find the index of the first element where the given predicate is true)
- `includes` (returns true or false based on if the given element is found in the array)
- `indexOf` (returns the first index where the given element is found)
- `lastIndexOf` (returns the last index where the given element is found)

Here are the suggested new names for the above functions:

- `find` ==> `findFirstThat`
- `findIndex` ==> `findFirstIndexThat`
- `includes` ==> `include`
- `indexOf` ==> `findFirstIndexOf`
- `lastIndexOf` ==> `findLastIndexOf`

Below are examples of these new function names in use:

```js
const numbers = [1, 2, 3, 4, 5, 5];
const isEven = nbr => (nbr % 2) === 0;
const firstEvenNumber = numbers.findFirstThat(isEven);
const firstEvenNumberIndex = numbers.findFirstIndexThat(isEven);
const numbersIncludeFour = numbers.include(4);
const firstIndexOfFive = numbers.findFirstIndexOf(5);
const lastIndexOfFive = numbers.findLastIndexOf(5);
```

#### Naming Method Pairs

Methods in a class can come in pairs. A typical example is a pair of getter and setter methods. When you define
a method pair in a class, name the methods logically. The methods in a method pair often do two opposite things, like
getting or setting a value. If you are unsure how to name one of the methods, try to find an antonym for a word. For example, if you have a method whose name starts with "create" and
are unsure how to name the method for the opposite action, try a Google search: "create antonym".

Here is a non-comprehensive list of some method names that come in pairs:

- get/set (getters and setters)
  - Name a boolean getter with the same name as the respective field, e.g., `boolean isDone()`
  - Name a boolean setter with `set` + boolean field name, e.g., `void setIsDone(boolean isDone)`
- get/put (especially when accessing a collection)
- read/write
- add/remove
- store/retrieve
- open/close
- load/save
- initialize/destroy
- create/destroy
- insert/delete
- start/stop
- pause/resume
- start/finish
- increase/decrease
- increment/decrement
- construct/destruct
- encrypt/decrypt
- encode/decode
- obtain/relinquish
- acquire/release
- reserve/release
- startup/shutdown
- login/logout
- begin/end
- launch/terminate
- publish/subscribe
- join/detach
- &lt;something&gt;/un&lt;something&gt;, e.g. assign/unassign, install/uninstall, subscribe/unsubscribe, follow/unfollow
- &lt;something&gt;/de&lt;something&gt;, e.g. serialize/deserialize, allocate/deallocate
- &lt;something&gt;/dis&lt;something&gt;, e.g. connect/disconnect

The `apt` tool in Debian/Ubuntu-based Linux has an `install` command to install a package, but the
command for uninstalling a package is `remove`. It should be `uninstall`. The Kubernetes package manager Helm has this correct.
It has an `install` command to install a Helm release and an `uninstall` command to uninstall it.

#### Naming Boolean Functions (Predicates)

> ***The naming of boolean functions (predicates) should be such that when reading the function call statement,***
> ***it reads as a boolean statement that can be true or false.***

In this section, we consider naming functions that are predicates and return a boolean value. Here I don't mean functions that
return true or false based on the success of the executed action, but cases where the function call is used
to evaluate a statement as true or false. The naming of boolean functions should be such that when
reading the function call statement, it makes a statement that can be true or false. Below are some Java examples:

```java
public class Response {
  public boolean hasError() {
    // ...
  }
}


public class String {
  public boolean isEmpty() {
    //...
  }

  public boolean startsWith(final String anotherString) {
    //...
  }

  public boolean endsWith(final String anotherString) {
    // ...
  }

  public boolean contains(final String anotherString) {
    // ...
  }
}


// Here we have a statement: response has error? true or false?
if (response.hasError()) {
  // ...
}


// Here we have a statement: line is empty? true or false?
final String line = fileReader.readLine();
if (line.isEmpty()) {
  // ...
}


// Here we have statement: line starts with a space character?
// true or false?
if (line.startsWith(" ")) {
    // ...
}


// Here we have statement: line ends with a semicolon?
// true or false?
if (line.endsWith(";")) {
    // ...
}


public class Thread {
  public boolean shouldTerminate() {
    // ...
  }

  public boolean isPaused() {
    // ...
  }

  public boolean canResumeExecution() {
    // ...
  }

  public void run() {
    // ...

    // Here we have statement: [this] should terminate?
    // true or false?
    if (shouldTerminate()) {
      return;
    }

    // Here we have statement: [this] is paused and
    // [this] can resume execution? true or false?
    if (isPaused() && canResumeExecution()) {
      // ...
    }

    // ...
  }
}
```

A boolean returning function is correctly named when you call the function in code and can read that function call statement
in plain English. Below is an example of incorrect and correct naming:

```java
public class Thread {
  public boolean stopped() { // Incorrect naming
    // ...
  }

  public boolean isStopped() { // Correct naming
    // ...
  }
}


if (thread.stopped()) {
  // Here we have: if thread stopped
  // This is not a statement with a true or false answer
  // It is a second conditional form,
  // asking what would happen if thread stopped.
  // ...
}


// Here we have statement: if thread is stopped
// true or false?
if (thread.isStopped()) {
  // ...
}
```

From the above examples, we can notice that many names of boolean-returning functions start with either
_is_ or _has_ and follows the below pattern:

- is + &lt;adjective&gt;, e.g. isOpen, isRunning or isPaused
- has + &lt;noun&gt;

Also, these two forms can be relatively common:

- should + &lt;verb&gt;
- can + &lt;verb&gt;

But as we saw with the `startsWith`, `endsWith`, and `contains` functions, a boolean returning function name can start
with any verb in third-person singular form (i.e., ending with an _s_). If you have a collection class, its boolean method names
should have a verb in the plural form, for example: `numbers.include(...)` instead of `numbers.includes(...)`. Name your collection variables
always in plural form (e.g., `numbers` instead of `numberList`). We will discuss the uniform naming principles for variables in the next
chapter.

Do not include the _does_ word in a function name, like _doesStartWith_, _doesEndWith_, or _doesContain_.
Adding the _does_ word doesn't add any real value to the name, and such function names are awkward to read when used in code, for example:

```java
final String line = textFileReader.readLine();

// "If line does start with" sound awkward
if (!line.doesStartWith(" ")) {
  // ...
}
```

When you want to use the past tense in a function name, use a _did_ prefix in the function name, for example:

```java
public class DatabaseOperation {
  public void execute() {
    // ...
  }

  // Method name not OK. This is a second conditional form
  // if (dbOperation.startedTransaction())...
  public boolean startedTransaction() {
    // ...
  }

  // Method name OK, no confusion possible
  public boolean didStartTransaction() {
    // ...
  }
}
```

#### Naming Builder Methods

A builder class is used to create builder objects that build a new object of a particular type. If you wanted to
construct a URL, a _UrlBuilder_ class could be used for that purpose. Builder class methods add properties to the
built object. For this reason, it is recommended to name builder class methods starting with the verb _add_. The method that
finally builds the wanted object should be named simply _build_ or _build + &lt;build-target&gt;_, for example, _buildUrl_.
I prefer the longer form to remind the reader what is being built.
Below is a Java example of naming the methods in a builder class:

```java
public class UrlBuilder {
  public UrlBuilder() {
    // ...
  }

  public UrlBuilder addScheme(final String scheme) {
   // ...
   return this;
  }

  public UrlBuilder addHost(final String host) {
    // ...
    return this;
  }

  public UrlBuilder addPort(final int port) {
    // ...
    return this;
  }

  public UrlBuilder addPath(final String path) {
    // ...
    return this;
  }

  public UrlBuilder addQuery(final String query) {
    // ...
    return this;
  }

  public Url buildUrl() {
    // ...
  }
};


final var url = new UrlBuilder()
  .addScheme("https://")
  .addHost("google.com")
  .buildUrl();
```

#### Naming Methods with Implicit Verbs

Factory method names usually start with the verb _create_. Factory methods can be named so that the _create_ verb is implicit, for example in Java:

```java
Optional.of(final T value)
Optional.empty() // Not optimal, 'empty' can be confused as a verb
Either.withLeft(final L value)
Either.withRight(final R value)
SalesItem.from(final SalesItemArg salesItemArg)
```

The explicit versions of the above method names would be:

```java
Optional.createOf(final T value)
Optional.createEmpty()
Either.createWithLeft(final L value)
Either.createWithRight(final L value)
SalesItem.createFrom(final SalesItemArg salesItemArg)
```

Similarly, conversion methods can be named so that the _convert_ verb is implicit. Conversion methods without a verb
usually start with the _to_ preposition, for example:

```java
value.toString();
object.toJson();
```

The explicitly named versions of the above methods would be:

```java
value.convertToString();
object.convertToJson();
```

Java has some factory methods that could be shortened:

```java
final var value = Integer.parseInt(string);
final var value = Long.parseLong(string);
```

Shorter method names would be:

```java
final var value = Integer.from(intString);
final var value = Long.from(longString);
```

You can access a collection element in some languages using the method `at(index)`.
Here the implicit verb is `get`. I recommend using method names with implicit verbs sparingly and only in circumstances where
the implicit verb is self-evident and does not force a developer to think.

#### Naming Property Getter Functions

Property getter functions are usually named `get` + `<property-name>`.
It is also possible to name a property getter that does not have a respective setter using just the property name. This is acceptable in cases where the property name cannot be confused with a verb.
Below is a Java example of property getters:

```java
final var list = new MyList();

list.size(); // OK
list.length(); // OK
list.empty(); // NOT OK, empty can be a verb.
list.isEmpty(); // OK
```

#### Naming Lifecycle Methods

Lifecycle methods are called on certain occasions only. Lifecycle method names should answer the question:
When or "on what occasion" will this method be called? Examples of good names for lifecycle methods are: `onInit`, `onError`,
`onSuccess`, `afterMount`, `beforeUnmount`. In React, there are lifecycle methods in class components called `componentDidMount`,
`componentDidUpdate` and `componentWillUnmount`. There is no reason to repeat the class name in the lifecycle method names. Better
names would have been: `afterMount`, `afterUpdate`, and `beforeUnmount`.

#### Naming Generic Type Parameters

Generic type parameters are usually named with a single character only. If there is one generic type parameter, a `T` is often used, e.g.,
`List<T>`. If there are multiple generic type parameters, the letters following T in the alphabet are used, e.g., `T` and `U`.
If the generic type parameter has a special meaning, use the first letter from that meaning; for example, in `Map<K, V>`, the `K` means
key and the `V` means value, or in `AbstractAction<S>`, the `S` means state. The problem with single-letter generic type parameters
can be lousy readability. For example, in the `AbstractAction<S>`, can we assume everybody understands what the `S` means? It is often better
to name generic type parameters with the convention `T<purpose>`, e.g., `TKey`, `TValue`, or `TState`. The initial `T` is needed to distinguish
generic type parameters from similar class names, like `Key`, `Value`, or `State`.

#### Naming Function Parameters

Naming rules for function parameters are mostly the same as for variables. _Uniform naming principle_ for variables
is described in the next chapter in more detail.

There are some exceptions, like naming object parameters. When a function parameter is an object, the name of the object class can be left out from
the parameter name when the parameter name and the function name implicitly describe the class of the parameter. This exception is acceptable because the function parameter type
can always be easily checked by looking at the function signature.
And this should be easily done with a glance because a function should be short (a maximum of 5-7 statements).
Below is a TypeScript example of naming object type parameters:

```ts
// Word 'Location' repeated, not optimal, but allowed
drive(startLocation: Location, destinationLocation: Location): void

// Better way
// When we think about 'drive' and 'start' or 'destination',
// we can assume that 'start' and 'destination' mean locations
drive(start: Location, destination: Location): void
```

Some programming languages like Swift allow adding so-called _external names_ to function parameters. Using external names
can make a function call statement read better, as shown below:

```swift
func drive(from start: Location, to destination: Location) {
  // ...
}

func send(
  message: String,
  from sender: Person,
  to recipient: Person
) {
  // ...
}


let startLocation = new Location(...);
let destLocation = new Location(...);
drive(from: startLocation, to: destLocation);

let message = "Some message";
let person = new Person(...);
let anotherPerson = new Person(...);
send(message, from: person, to: anotherPerson);
```

Always make the function call expression such that it has maximum readability: e.g., `copy(source, target)` not `copy(target, source)`
or `write(line, file)` not `write(file, line)` or `decode(inputMessage, internalMessage)` and `encode(internalField, outputMessage)`. The examples contain implicit articles and prepositions. You can
easily imagine the missing articles and prepositions, e.g., *copy from a source to a target*, *write a line to a file* or *encode an internal field to an output message*.

How would you name a UI function that closes a collapsible panel after a timeout if the panel is open?
Inside the collapsible panel component, we could specify

```ts
function closeAfterTimeout(closeTimeoutInMs: number, isOpen: boolean): void {
  // ...
}
```

The above is not the best, because `close` and `timeout` are repeated twice. Let's modify the function definition by dropping
one `close` and one `timeout` to avoid repetition:

```ts
function closeAfter(timeoutInMs: number, isOpen: boolean): void {
  // ...
}
```

We could improve the function name a bit more by specifying what the `isOpen` parameter is used for using an `if` word:

```ts
function closeAfterIf(timeoutInMs: number, isOpen: boolean): void {
  // ...
}
```

Now we read the function definition in plain English: *close [this] after timeout in milliseconds if [this] is open*.
And the `[this]` of course means the current collapsible panel object, so we could read:
*close [the panel] after timeout in milliseconds if [the panel] is open*.

We could write the above function definition in a very readable manner in Swift:

```swift
func close(after timeoutInMs: Int, if isOpen: Bool): void {
  // ...
}
```

## Encapsulation Principle

> ***A class should encapsulate its state so that access to the state happens only via public methods.***

Encapsulation is achieved by declaring class attributes private. You can create getter and setter methods if you need
the state to be modifiable outside the class. However, encapsulation is best ensured if you don't need to create getter
and setter methods for the class attributes. Do not automatically implement or generate getter and setter methods for every class.
Only create those accessor methods if needed, like when the class represents a modifiable data structure. An automatically generated getter can break
the encapsulation of a class if the getter returns modifiable internal state, like a list.
Only generate setter methods for attributes that need to be modified outside the class. If you have a class with many getters,
you might be guilty of *feature envy* code smell, where other objects query your object for its internal state and perform operations
based on that state. You should follow the *tell, don't ask principle* (discussed later in this chapter) by removing the getters from your class and implementing the operation in your class.

### Immutable Objects

The best way to ensure the encapsulation of an object's state is to make the object immutable. This means that once the object
is created, its state cannot be modified afterward. Immutability ensures you cannot accidentally or intentionally modify the object's state.
Modifying the object's state outside the object can be a source of bugs.

When creating an immutable object, you give the needed parameters for the object in the constructor, and after that, those properties
cannot be modified (You don't create any setters for the class). If you need to modify an immutable object, the only way is to create a new object with different values given in the constructor.
The drawback of this approach is that a performance penalty is introduced when
creating new objects as compared to modifying existing objects' attributes only. But in many cases, this penalty is negligible
compared to the benefits of immutability. For example, strings are immutable in Python. Once you create a string, you cannot modify it.
You can only create new strings.

Immutability also requires that getters and other methods returning a value may not return a modifiable attribute, like a list.
If you return a list from a method, that list could be modified by adding or removing elements without
the "owning" object being aware of that.

### Don't Leak Modifiable Internal State Outside an Object Principle

Beware when you return values from methods. It is possible that a method accidentally returns some internal
state of the object that can be modified later by the method caller. Returning modifiable state from a method breaks the encapsulation.

You can safely return an object's internal state when it has a primitive or so-called value type. Those include
bool, int, and float. You can also safely return an immutable object, like a string. But you cannot safely return a mutable collection, for example.

There are two ways to protect against leaking internal state outside an object:

1) Return a copy of the modifiable internal state
2) Return an unmodifiable version of the modifiable internal state

Regarding the first approach, when a copy is returned, the caller can use it as they like.
Changes made to the copied object don't affect the original object. I am primarily talking about making a shallow copy.
In many cases, a shallow copy is enough. For example, a list of primitive values, immutable strings, or immutable objects does
not require a deep copy of the list. But you should make a deep copy when needed.

The copying approach can cause a performance penalty, but in many cases, that penalty is insignificant.
In JavaScript, you can easily create a copy of an array:

```js
const values = [1, 2, 3, 4, 5];
const copyOfValues = [...values];
```

The second approach requires you to create an unmodifiable version of a modifiable object and return
that unmodifiable object. Some languages offer an easy way to create unmodifiable versions of certain objects.
In Java, you can create an unmodifiable version of a `List`, `Map`, or `Set` using `Collections.unmodifiableList`,
`Collections.unmodifiableMap`, or `Collections.unmodifiableSet` factory method, respectively.

You can also create an unmodifiable version of a class by yourself. Below is an example in Java:

```java
public interface MyList<T> {
  void addToEnd(T item);
  Optional<T> getItem(int index);
}

public class UnmodifiableMyList<T> implements MyList<T> {
  private final MyList<T> list;

  public UnmodifiableMyList(final MyList<T> list) {
    this.list = list;
  }

  public void addToEnd(final T item) {
    throw new UnsupportedOperationException(...);
  }

  public Optional<T> getItem(final int index) {
    return list.getItem(index);
  }
}
```

In the above example, the unmodifiable list class takes another list (a modifiable list) as a constructor argument. It
only implements the `MyList` interface methods that don't attempt to modify the wrapped list. In this case, it implements only the
`getItem` method that delegates to the respective method in the `MyList` class. The `UnmodifiableMyList` class methods that attempt to modify
the wrapped list should throw an error. The `UnmodifiableMyList` class utilizes the _proxy pattern_ by wrapping an object of the `MyList` class
and partially allowing access to the `MyList` class methods.

In C++, you can return an unmodifiable version by declaring the return type as _const_, for example:

<div class="sourceCodeWithoutLabel">

```cpp
std::shared_ptr<const std::vector<std::string>>
getStringValues() const;
```

Now callers of the `getStringValues` method cannot modify the returned vector of strings because it is declared
const.

Unmodifiable and immutable objects are slightly different. No one can modify an immutable object, but when you return an
unmodifiable object from a class method, that object can still be modified by the owning class, and modifications are visible to
everyone that has received an unmodifiable version of the object. If this is something undesirable, you should use
a copy instead.

### Don't Assign From a Method Parameter to a Modifiable Attribute

If a class receives modifiable objects as constructor or method arguments, it is typically best practice not to
assign those arguments to the internal state directly. If they are assigned directly, the class can,
on purpose or accidentally modify those argument objects, which is probably not what the constructor or method caller
expects.

There are two ways to handle this situation:

1) Store a copy of the modifiable argument object to the class's internal state
2) Store an unmodifiable version of the modifiable argument object to the class's internal state

Below is a Java example of the second approach:

```java
public class MyClass {
  private final List<Integer> values;

  public MyClass(final List<Integer> values) {
    this.values = Collections.unmodifiableList(values);
  }
}
```

## Prefer Composition Over Inheritance Principle

> ***In object-oriented design, like in real life, objects are constructed by constructing larger objects from smaller objects.***
> ***This is called object composition. Prefer object composition over inheritance.***

This principle is presented in the *Design Patterns* book by the *Gang of Four*. An example of composition is a car object composed of an engine and transmission object (to name a few).
Objects are rarely "composed" by deriving from another object, i.e., using inheritance. But first, let's try to specify
classes that implement the below Java `Car` interface using inheritance and see where it leads us:

```java
public interface Car {
  void drive(
    Location start,
    Location destination
 );
}


public class CombustionEngineCar implements Car {
  public void drive(
    final Location start,
    final Location destination
  ) {
    // ...
  }
}


public class ElectricEngineCar implements Car {
  public void drive(
    final Location start,
    final Location destination
  ) {
    // ...
  }
}


public class ManualTransmissionCombustionEngineCar
         extends CombustionEngineCar {
  public void drive(
    final Location start,
    final Location destination
  ) {
    // ...
  }
}


public class AutomaticTransmissionCombustionEngineCar
         extends CombustionEngineCar {
  public void drive(
    final Location start,
    final Location destination
  ) {
    // ...
  }
}
```

If we wanted to add other components to a car, like a two or four-wheel drive, the number of classes
needed would increase by three. If we wanted to add a design property (sedan, hatchback, wagon, or SUV) to a car,
the number of needed classes would explode, and the class names would become ridiculously long, like `HatchbackFourWheelDriveAutomaticTransmissionCombustionEngineCar`.
We can notice that inheritance is not the correct way to build more complex classes here.

Class inheritance creates an *is-a* relationship between a superclass and its subclasses. Object composition creates a *has-a*
relationship. We can claim that `ManualTransmissionCombustionEngineCar` *is a* kind of `CombustionEngineCar`, so basically, we
are not doing anything wrong here, one might think. But when designing classes, you should first determine if object composition
could be used: is there a *has-a* relationship? Can you declare a class as an attribute of another class?
If the answer is yes, then composition should be used instead of inheritance.

All the above things related to a car are actually properties of a car. A car *has an* engine.
A car *has a* transmission. It *has a* two or four-wheel drive and design. We can turn the inheritance-based solution into a composition-based solution:

```java
public interface Drivable {
  void drive(
    Location start,
    Location destination
  );
}

public interface Engine {
  // Methods like start, stop ...
}

public class CombustionEngine implements Engine {
  // Methods like start, stop ...
}

public class ElectricEngine implements Engine {
  // Methods like start, stop ...
}

public interface Transmission {
  // Methods like changeGear ...
}

public class AutomaticTransmission implements Transmission {
  // Methods like changeGear ...
}

public class ManualTransmission implements Transmission {
  // Methods like changeGear ...
}

// Define DriveType here...
// Define Design here...

public class Car implements Drivable {
  private final Engine engine;
  private final Transmission transmission;
  private final DriveType driveType;
  private final Design design;

  public Car(
    final Engine engine,
    final Transmission transmission,
    final DriveType driveType,
    final Design design
  ) {
    this.engine = engine;
    this.transmission = transmission;
    this.driveType = driveType;
    this.design = design;
  }

  public void drive(
    final Location start,
    final Location destination
  ) {
    // To implement functionality, delegate to
    // component classes, for example:

    // engine.start();
    // transmission.shiftGear(...);
    // ...
    // engine.stop();
  }
}
```

Let's have a more realistic example in TypeScript with different chart types. At first, this sounds
like a case where inheritance could be used: We have some abstract base charts that different concrete charts extend:

```ts
interface Chart {
  renderView(): JSX.Element;
  updateData(...): void;
}


abstract class AbstractChart implements Chart {
  abstract renderView(): JSX.Element;
  abstract updateData(...): void;

  // Implement some common functionality
  // shared by all chart types
}


abstract class XAxisChart extends AbstractChart {
  abstract renderView(): JSX.Element;

  updateData(...): void {
    // This is common for all x-axis charts,
    // like ColumnChart, LineChart and AreaChart
  }
}


class ColumnChart extends XAxisChart {
  renderView(): JSX.Element {
    // ...

    return (
      <XYZChart
        type="column"
        data={data}
        options={options}...
      />;
    );
  }
}


// LineChart class definition here...
// AreaChart class definition here...


abstract class NonAxisChart extends AbstractChart {
  abstract renderView(): JSX.Element;

  updateData(...): void {
    // This is common for all non-x-axis charts,
    // like PieChart and DonutChart
  }
}


class PieChart extends NonAxisChart {
  renderView(): JSX.Element {
    // ...

    return (
      <XYZChart
        type="pie"
        data={data}
        options={options}...
      />;
    );
  }
}


class DonutChart extends PieChart {
  renderView(): JSX.Element {
    // ...

    return (
      <XYZChart
        type="donut"
        data={data}
        options={options}...
      />;
    );
  }
}
```

The above class hierarchy looks manageable: there should not be too many subclasses that need to be defined. We can, of course, think of new chart types, like a geographical map or data table
for which we could add subclasses. One problem with a deep class hierarchy arises when you need to change or
correct something related to a particular chart type. Let's say you want to change or correct some behavior
related to a pie chart. You will first check the `PieChart` class if the behavior is defined there. If
you can't find what you are looking for, you need to navigate to the base class of the `PieChart` class (`NonAxisChart`) and look there. And
you might need to continue this navigation until you reach the base class where the behavior you want to
change or correct is located. Of course, if you are incredibly familiar with the codebase, you might be able to locate the
correct subclass on the first try. But in general, this is not a straightforward task.

Using class inheritance can
introduce class hierarchies where some classes have significantly more methods than other classes.
For example, in the chart inheritance chain, the `AbstractChart` class probably has significantly more methods than
classes at the end of the inheritance chain. This class size difference creates an imbalance between classes making it hard to reason about
what functionality each class provides.

Even if the above class hierarchy might look okay at first sight, currently, there lies one problem. We have
hardcoded what kind of chart view we are rendering. We are using the _XYZ_ chart library and rendering `XYZChart`
views. Let's say we would like to introduce another chart library called _ABC_. We want to use both chart libraries
in parallel so that the open-source version of our data visualization application uses the _XYZ_ chart library, which is open
source. The paid version of our application uses the commercial _ABC_ chart library. When using class inheritance,
we must create new classes for each concrete chart type for the _ABC_ chart library.
So, we would have two classes for each concrete chart type, like here for the pie chart:

```ts
class XYZPieChart extends XyzNonAxisChart {
  renderView(): JSX.Element {
    // ...

    return (
      <XYZChart
        type="pie"
        data={data}
        options={options}...
      />;
    );
  }
}


class ABCPieChart extends AbcNonAxisChart {
  renderView(): JSX.Element {
    // ...

    return (
      <ABCPieChart
        dataSeries={dataSeries}
        chartOptions={chartOptions}...
      />;
    );
  }
}
```

Implementing the above functionality using composition instead of inheritance has several benefits:

- It is more apparent what behavior each class contains
- There is no significant size imbalance between classes, where some classes are huge and others relatively small
- You can split chart behaviors into classes as you find fit, and is in accordance with the _single responsibility principle_

In the below example, we have split some chart behavior into two types of classes: chart view renderers and chart data factories:

```ts
interface Chart {
  renderView(): JSX.Element;
  updateData(...): void;
}


interface ChartViewRenderer {
  renderView(data: ChartData, options: ChartOptions): JSX.Element;
}


interface ChartDataFactory {
  createData(...): ChartData
}


// ChartData...
// ChartOptions...


class ChartImpl implements Chart {
  private data: ChartData;
  private options: ChartOptions;

  constructor(
    private readonly viewRenderer: ChartViewRenderer,
    private readonly dataFactory: ChartDataFactory
  ) {
    // ...
  }

  renderView(): JSX.Element {
    return this.viewRenderer.renderView(this.data, this.options);
  }

  updateData(...): void {
    this.data = this.dataFactory.createData(...);
  }
}


class XYZPieChartViewRenderer implements ChartViewRenderer {
  renderView(data: ChartData, options: ChartOptions): JSX.Element {
    // ...

    return (
      <XYZPieChart
        data={dataInXyzChartLibFormat}
        options={optionsInXyzChartLibFormat}...
      />;
    );
  }
}


class ABCPieChartViewRenderer implements ChartViewRenderer {
   renderView(data: ChartData, options: ChartOptions): JSX.Element {
     // ...

     return (
       <ABCPieChart
         dataSeries={dataInAbcChartLibFormat}
         chartOptions={optionsInAbcChartLibFormat}...
       />;
     );
   }
}


// ABCColumnChartViewRenderer...
// XYZColumnChartViewRenderer...


type ChartType = 'column' | 'pie';

interface ChartFactory {
  createChart(chartType: ChartType): Chart;
}


class ABCChartFactory implements ChartFactory {
  createChart(chartType: ChartType): Chart {
    switch(chartType) {
      case 'column':
        return new ChartImpl(new ABCColumnChartViewRenderer(),
                             new XAxisChartDataFactory());
      case 'pie':
        return new ChartImpl(new ABCPieChartViewRenderer(),
                             new NonAxisChartDataFactory());

      default:
        throw new Error('Invalid chart type');
    }
  }
}


class XYZChartFactory implements ChartFactory {
  createChart(chartType: ChartType): Chart {
    switch(chartType) {
      case 'column':
        return new ChartImpl(new XYZColumnChartViewRenderer(),
                             new XAxisChartDataFactory());
      case 'pie':
        return new ChartImpl(new XYZPieChartViewRenderer(),
                             new NonAxisChartDataFactory());

      default:
        throw new Error('Invalid chart type');
    }
  }
}
```

The `XYZPieChartViewRenderer` and `ABCPieChartViewRenderer` classes use the _adapter pattern_ as they convert
the supplied data and options to an implementation (ABC or XYZ chart library) specific interface.

We can easily add more functionality by composing the `ChartImpl` class of more classes. There could be, for example, a title
formatter, tooltip formatter class, y/x-axis label formatter, and event handler classes.

```ts
class ChartImpl implements Chart {
  private data: ChartData;
  private options: ChartOptions;

  constructor(
    private readonly viewRenderer: ChartViewRenderer,
    private readonly dataFactory: ChartDataFactory,
    private readonly titleFormatter: ChartTitleFormatter,
    private readonly tooltipFormatter: ChartTooltipFormatter,
    private readonly xAxisLabelFormatter: ChartXAxisLabelFormatter,
    private readonly eventHandler: ChartEventHandler
  ) {
    // ...
  }

  renderView(): JSX.Element {
    return this.viewRenderer.renderView(this.data, this.options);
  }

  updateData(...): void {
    this.data = this.dataFactory.createData(...);
  }
}


class ABCChartFactory implements ChartFactory {
  createChart(chartType: ChartType): Chart {
    switch(chartType) {
      case 'column':
        return new ChartImpl(new ABCColumnChartViewRenderer(),
                             new XAxisChartDataFactory(),
                             new ChartTitleFormatterImpl(),
                             new XAxisChartTooltipFormatter(),
                             new ChartXAxisLabelFormatterImpl(),
                             new ColumnChartEventHandler());

     case 'pie':
       return new ChartImpl(new ABCColumnChartViewRenderer(),
                            new NonAxisChartDataFactory(),
                            new ChartTitleFormatterImpl(),
                            new NonAxisChartTooltipFormatter(),
                            new NullXAxisLabelFormatter(),
                            new NonAxisChartEventHandler());

      default:
        throw new Error('Invalid chart type');
    }
  }
}
```

## Tactical Domain-Driven Design Principle

> ***In Tactical DDD you define your domain models in more details. Tactical DDD is applied within a single bounded context.***

We continue here where we left with strategical DDD in the last chapter. Strategic DDD was about dividing a software system to subdomains and bounded contexts (microservices).
Tactical DDD is about implementing a single bounded context.
Tactical DDD means that the structure of a bounded context and the names appearing in the code (interface, class, function, and variable names)
should match the domain's vocabulary and the ubiquitous language. For example, names like *Account*, *withdraw*, *deposit*,
*make_payment* should be used in a *payment-service* bounded context.

### Tactical DDD Concepts

Tactical domain-driven design recognizes multiple concepts:

- Entities
- Value Objects
- Aggregates
- Aggregate Roots
- Factories
- Repositories
- Services
- Events

#### Entities

An entity is a domain object that has an identity. Usually, this is indicated by the entity class having some *id* attribute. Examples of entities are an *employee* and a *bank account*. An employee object has an employee id, and a bank account has a number that identifies the bank account. Entities can contain methods that operate on the attributes
of the entity. For example, a bank account entity can have methods *withdraw* and *deposit* that operate on the *balance*
attribute of the entity.

#### Value Objects

Value objects are domain objects that don't have an identity. Examples of value objects are an address or a price object.
The price object can have two attributes: *amount* and *currency*, but it does not have an identity. Similarly an address
object can have the following attributes: *street address*, *postal code*, *city* and *country*. Value objects can and many times
should have behavior in them. For example a *price* value object can have a validation rule for accepted currencies. You can
also put behavior, like converting a price object to another price object with different currency, into the `Price` value object class.
So, value objects are not just holders for a set of primitive values.

#### Aggregates

Aggregates are entities composed of other entities and value objects. For example, an *order* entity can have one or more *order item* entities.
Regarding object-oriented design, this is the same as object composition. Each aggregate has a root (entity). The figure below shows a `SalesItem` aggregate. A `SalesItem` entity is an aggregate and aggregate root. It can contain one or more images of the sales item, and it consists of a `Price` value object, which has two attributes: price and currency.

![Aggregate Example](resources/chapter2/images/aggregate.png)

#### Aggregate Roots

Aggregate roots are domain objects that don't have any parent objects. An *order* entity is an aggregate root when it does
not have a parent entity. But an *order item* entity is not an aggregate root when it belongs to an *order*. Aggregate roots
serve as facade objects. Operations should be performed on the aggregate root objects, not directly accessing the
objects behind the facade (e.g., not directly accessing the individual order items, but performing operations on order objects). For example, if you have an aggregate car object containing wheels, you don't operate the wheels outside of the car object. The car
object provides a facade like a *turn* method, and the car object internally operates the wheels, making the car object
an aggregate root. More about the *facade pattern* in a later section of this chapter.

Let's have an example of aggregate roots in a microservice architecture. Suppose we have a bank account, an aggregate root containing transaction entities. The bank account and transaction entities can be handled in different microservices (*account-service*
and *account-transaction-service*), but only the *account-service* can  directly access and modify the transaction entities using
the *account-transaction-service*. Our bounded context is the *account-service*. The role and benefit of an aggregate root are the following:

- The aggregate root protects against invariant violation. For example, no other service should directly remove or add transactions using the *account-transaction-service*. That would break the invariant that the sum of transactions should be the same as the balance of the account maintained by the *account-service*.
- The aggregate root simplifies (database/distributed) transactions. Your microservice can access the *account-service* and let it manage the distributed transactions between the *account-service* and *account-transaction-service*. It's not something that your microservice needs to do.

You can easily split an aggregate root into more entities. For example, the bank account aggregate root
could contain balance and transaction entities. The balance entity could be handled by a separate *account-balance-service*.
Still, all bank account operations must be made to the *bank-account-service*, which will orchestrate, e.g., *withdraw* and
*deposit* operations using the *account-balance-service* and *account-transaction-service*. We can even split the *account-service*
to two separate microservices: *account-service* for account CRUD operations (excluding updates related to balance) and
*account-money-transfer-service* that will handle *withdraw* and *deposit* operations using the two lower-level microservices:
*account-balance-service* and *account-transaction-service*. In the previous chapter, we had an example of the latter case when
we discussed distributed transactions.

#### Actors

Actors perform commands. End-users are actors, but also services can be actors.
For example, in a data exporter microservice, there can be an input message consumer service that has a command
to consume a message from a data source.

#### Factories

In domain-driven design, the creation of domain objects can be separated from the object classes to factories. Factories are
objects that are dedicated to creating objects of a particular type. Domain object factories can be created using the *factory pattern* which is described in a later section of this chapter.

#### Repositories

A repository is an object with methods for persisting domain objects and retrieving them from a data store (e.g., a database).
Typically, there is one repository for each aggregate root, e.g., an *order repository* for order entities.

#### Services

Services can be divided into *domain* and *application* services. Application services are used to implement business use cases. External clients connect to the application services via input interface adapters.
Domain services contain functionality that is not directly part of any specific object. A domain service is a class that does not represent a
concept in the problem domain. It is also called *pure fabrication* according to [GRASP](https://en.wikipedia.org/wiki/GRASP_(object-oriented_design)) principles.
Services orchestrate operations on aggregate roots. For example, an `OrderService` orchestrates operations on order entities.
An application service typically uses a related repository to perform persistence-related operations. A service can also be seen as an actor with specific command(s).
For example, in a data exporter microservice, there can be an input message consumer service that has a command
to consume a message from a data source.

Domain services usually should not contain access to a repository (or other output interface) or otherwise be side-effectful. Aim for
a side-effect-free, functional, and immutable domain model (domain services and objects) and put side effects on the outer application service layer. The application service
layer can have several variations. A single application service (or service class method) implements a use case or a feature. In the simplest form, an application service is a *transaction script* when no domain services are involved. This is usually the case for simple CRUD-based APIs where the application service class performs simple CRUD operations like creating a new sales item. Let's have an example of a transaction script with a backlog item service. The service has an update backlog item use case (or feature) where the application service method first fetches the sprint the backlog item is assigned from a repository and then calls the backlog item factory to create a new backlog item with the specific
sprint object also given as a parameter in addition to the updated backlog item DTO. The factory should validate if the sprint is valid (a current or a future sprint, not a past one).
The factory can be implemented in various ways, using one of the *factory patterns*, e.g., a separate factory class or a factory method in the entity class.
Factory can create different variants of backlog item entities if needed. For example, the factory can create various objects based on the backlog item type, like a `TeamBacklogItem` or `ProductBacklogItem` object.
After the backlog item is created using the factory, it can be persisted using a repository's update method. In this simple example, there is no need for domain services. In more complex cases, the model usually has domain services to which application services delegate for more complex operations.

#### Events

Events are operations on entities and form the business use cases. Services usually handle events. For example, there could be the following events related to order entities: create, update, and cancel an order. These
events can be implemented by having an `OrderService` with the following methods: `create_order`, `update_order`, and
`cancel_order`.

#### Design-Level Event Storming

*Design-level event storming* is a lightweight method (a workshop), a team can use to discover DDD-related concepts in a bounded context.
The event storming process typically follows the below steps:

1) Figure out *domain events* (events are usually written in past tense)
2) Figure out *commands* that caused the *domain events*
3) Add *actors*/*services* that execute the *commands*
4) Figure out related *entities*

In event storming workshop, the different DDD concepts like events, commands, actors, and entities are represented with sticky notes in different colors.
These sticky notes are put on a wall, and related sticky notes are grouped together, like the actor, the command, and entity/entities for a specific
domain event. If you are interested in details of the event storming process, there is a book named *Introducing EventStorming* by *Alberto Brandolini*.

### Tactical DDD Example 1: Data Exporter Microservice

Let's have a DDD example with a microservice for exporting data. Data exporting will be our top-level
domain. The development team should participate in the DDD and
object-oriented design (OOD) process. An expert-level software developer,
e.g., the team tech lead, could do the DDD and OOD alone, but it is not how it should be done. Other team members,
especially the junior ones, should be involved to learn and develop their skills further.

The DDD process is started by first defining the big picture (top-level domain) based on requirements from the product management and the architecture team:

> Data exporter handles data that consists of messages that contain multiple fields. Data exporting should happen from
> an input system to an output system. During the export, various transformations to the data can be made, and
> the data formats in the input and output systems can differ.

Let's start the event-storming process by figuring out the domain events:

1) A message is consumed from the input system
2) The input message is decoded into an internal representation (i.e., an internal message)
3) The internal message is transformed
4) The transformed message is encoded to the wanted output format
5) The transformed message is produced in the output system
6) Configuration is read and parsed

From the above events, we can figure out four subdomains:

- Input (Events 1, 2 and 6)
- Internal Message (Events 2 and 3)
- Transform (Events 3 and 6)
- Output (Events 4, 5 and 6)

![Data Exporter Subdomains](resources/chapter2/images/data_exporter_subdomains.png)

Let's take the first domain event, "Messages are consumed from the input system," and figure out what caused the
event and who was the actor. Because no end-user is involved, we can conclude that the event was caused
by an "input message consumer" *service* executing a "consume message" *command*. This operation creates an "input message" *entity*.
The picture below shows how this would look with sticky notes on the wall.

![Event Storming](resources/chapter2/images/event_storming.png)

When continuing the event storming process further for the *Input* domain, we can figure out that it consists of the following
additional DDD concepts:

- Commands
  - Read input configuration
  - Parse input configuration
  - Consume input message
  - Decode input message
- Actors/Services
  - Input configuration reader
  - Input configuration parser
  - Input message consumer
  - Input message decoder
- Entities
  - Input message
- Value Objects
  - Input configuration

The event-storming process that resulted in the above list of DDD concepts is actually [object-oriented analysis](https://en.wikipedia.org/wiki/Object-oriented_analysis_and_design#Object-oriented_analysis) (OOA).
We got an initial set of objects that our use case needs when implemented. We got all of them only by looking at the domain events that consist of a verb and an object. We just have to figure out the actor that causes the domain event to happen. Many times, it can also be directly inferred from the domain event.

The actors/services are often singleton objects.
Entities and value objects are objects. Commands are the main methods in the actor/service classes. The OOA phase should result
in an initial [class diagram](https://en.wikipedia.org/wiki/Class_diagram) showing the main classes and their relationships
with other classes.

Below is the list of sub-domains, interfaces, and classes in the *Input* domain:

- Input message
    - Contains the message consumed from the input data source
    - `InputMessage` is a protocol that can have several concrete implementations, like `KafkaInputMessage` representing
      an input message consumed from a Kafka data source
- Input message consumer
    - Consumes messages from the input data source and creates `InputMessage` instances
    - `InputMessageConsumer` is a protocol that can have several concrete implementations, like `KafkaInputMessageConsumer` for consuming messages from a Kafka data source
- Input Message decoder
    - Decodes input messages into internal messages
    - `InputMessageDecoder` is a protocol that can have several concrete implementations, like `AvroBinaryInputMessageDecoder`,
      which decodes input messages encoded in Avro binary format. (If you provide multiple implementations for the `InputMessageDecoder` protocol, you must also create a factory class that can create different kinds of input message decoders).
- Input configuration
    - Input configuration reader
        - Reads the domain's configuration
        - `InputConfigReader` is a protocol that can have several concrete implementations, like
          `LocalFileSystemInputConfigReader` or `HttpRemoteInputConfigReader`
    - Input configuration parser
        - Parses the read configuration to produce an `InputConfig` instance
        - `InputConfigParser` is a protocol that can have several concrete implementations, like `JsonInputConfigParser` or `YamlInputConfigParser`
    - `InputConfig` instance contains parsed configuration for the domain, like the input data source type, host, port, and input data format.

![Input Subdomain](resources/chapter2/images/04-02.png)

Next, we should perform [object-oriented design](https://en.wikipedia.org/wiki/Object-oriented_analysis_and_design#Object-oriented_design) (OOD) and design objects in a more detailed way, using various design principles and patterns.
As shown in the below class diagram, we have applied the *dependency inversion / program against interfaces principle* to the result of the earlier OOA phase:

![Input Subdomain Class Diagram](resources/chapter2/images/input_domain.svg)

When applying the event storming process to the *Internal Message* domain, we can figure out that it consists of the following DDD concepts:

- Entities
    - Internal message
    - Internal field
- Aggregate
    - Internal message (consists of fields)
- Aggregate root
    - Internal message

Below is the list of sub-domains, interfaces, and classes in the *Internal Message* domain:

- Internal Message
  - Internal message consists of one or more internal fields
  - `InternalMessage` is an interface for a class that provides an internal representation of an input message
- Internal Field
  - `InternalField` is an interface for classes representing a single field of an internal message

When applying the event storming process to the *Transform* domain, we can figure out that it consists of the following DDD concepts:

- Commands
    - Read transformer configuration
    - Parse transformer configuration
    - Transform message
    - Transform field
- Actors/Services
    - Transformer configuration reader
    - Transformer configuration parser
    - Message transformer
    - Field transformer
- Value objects
    - Transformer configuration

Below is the list of sub-domains, interfaces, and classes in the *Transform* domain:

- Field transformer
    - `FieldTransformers` is a collection of `FieldTransformer` objects
    -  A Field transformer transforms the value of an internal field into the value of an output message field
    - `FieldTransformer` is a protocol that can have several concrete implementations, like
      `FilterFieldTransformer`, `CopyFieldTransformer`, `TypeConversionFieldTransformer` and `ExpressionTransformer`
- Message Transformer
    - `MessageTransformer` takes an internal message and transforms it using field transformers
- Transformer configuration
    - Transformer configuration reader
        - Reads the domain's configuration
        - `TransformerConfigReader` is a protocol that can have several concrete implementations,
          like `LocalFileSystemTransformerConfigReader`
    - Transformer configuration parser
        - Parses read configuration to produce a `TransformerConfig` instance
        - `TransformerConfigParser` is a protocol that can have several concrete implementations,
          like `JsonTransformerConfigParser`
    - `TransformerConfig` instance contains parsed configuration for the *Transformer* domain

![Transform Subdomain](resources/chapter2/images/transformer_subdomain.png)

Below is the class diagram for the Transform subdomain. I have left the configuration part out of the diagram because
it is pretty much the same as the configuration part in the Input domain.

![Transform Subdomain Class Diagram](resources/chapter2/images/transform_domain.svg)

When applying the event storming process to the *Output* domain, we can figure out that it consists of the following DDD concepts:

- Commands
    - Read output configuration
    - Parse output configuration
    - Encode output message
    - Produce output message
- Actors/Services
    - Output configuration reader
    - Output configuration parser
    - Output message encoder
    - Output message producer
- Entities
    - Output message
- Value objects
    - Output configuration

Below is the list of sub-domains, interfaces, and classes in the *Output* domain:

- Output Message encoder
    - Encodes transformed message to an output message with a specific data format
    - `OutputMessageEncoder` is a protocol that can have several concrete implementations, like `CsvOutputMessageEncoder`,
      `JsonOutputMessageEncoder`, `AvroBinaryOutputMessageEncoder`
- Output message
    - `OutputMessage` is a container for an output byte sequence
- Output message producer
    - Produces output messages to the output destination
    - `OutputMessageProducer` is a protocol that can have several concrete implementations, like `KafkaOutputMessageProducer`
- Output configuration
    - Output configuration reader
        - Reads the domain's configuration
        - `OutputConfigReader` is a protocol that can have several concrete implementations,
          like `LocalFileSystemOutputConfigReader`
    - Output configuration parser
        - Parse the read configuration to an `OutputConfig` instance
        - `OutputConfigParser` is a protocol that can have several concrete implementations, like `JsonOutputConfigParser`
    - `OutputConfig` instance contains parsed configuration for the domain, like output destination type, host, port, and the output data format

![Output Subdomain](resources/chapter2/images/output_subdomain.png)

Below is the class diagram for the Output subdomain. I have left the configuration part out of the diagram because
it is pretty much the same as the configuration part in the Input domain.

![Output Subdomain Class Diagram](resources/chapter2/images/output_domain.svg)

The above design also follows the *clean microservice design* principle. Note that this principle applies to all kinds of microservices with input or output, not just APIs. From the above design, we can discover the following interface adapters that
are not part of the business logic of the microservice:

- `InputMessageConsumer` interface implementations
- `InputMessageDecoder` interface implementations
- `OutputMessageEncoder` interface implementations
- `OutputMessageProducer` interface implementations
- `InputConfigReader` interface implementations
- `InputConfigParser` interface implementations
- `TransformerConfigReader` interface implementations
- `TransformerConfigParser` interface implementations
- `OutputConfigReader` interface implementations
- `OutputConfigParser` interface implementations

We should be able to modify the implementations mentioned above or add a new implementation without modifying other parts of the code (the core or business logic). This means that we can easily adapt our microservice
to consume data from different data sources in different data formats and output the transformed data to different data sources
in various data formats. Additionally, the configuration of our microservice can be read from various sources in different formats. For example, if we now read some configuration from a local file in JSON format, in the future, we
could introduce new classes for reading the configuration from an API using some other data format.

After defining the interfaces between the above-defined subdomains, the four subdomains can be developed very much in parallel.
This can speed up the microservice development significantly. The code of each subdomain should be put into separate source
code folders. We will discuss source code organization more in the next chapter.

Based on the above design, the following data processing pipeline can be implemented (C++):

```cpp
void DataExporterApp::run()
{
  while(m_isRunning)
  {
    const auto inputMessage =
      m_inputMessageConsumer.consumeInputMessage();

    const auto internalMessage =
      m_inputMessageDecoder.decodeToInternalMessage(inputMessage);

    const auto transformedMessage =
      m_messageTransformer.transform(*internalMessage);

    const auto outputMessage =
      m_outputMessageEncoder.encode(transformedMessage);

    m_outputMessageProducer.produce(outputMessage);
  }
}
```

And the `MessageTransformer::transform` method can be implemented in the following way:

```cpp
std::unique_ptr<InternalMessage> MessageTransformer::transform(
  const InternalMessage& internalMessage
)
{
  const auto transformedMessage =
    std::make_unique<InternalMessageImpl>();

  std::ranges::for_each(m_fieldTransformers,
                        [&internalMessage, &transformedMessage]
                        (const auto& fieldTransformer) {
    fieldTransformer.transform(internalMessage,
                               transformedMessage);
  });

  return transformedMessage;
}
```

### Tactical DDD Example 2: Anomaly Detection Microservice

Let's have another DDD example with an anomaly detection microservice. The purpose of the microservice is to detect anomalies
in measurement data. This concise description of the microservice's purpose reveals the two subdomains of the microservice:

- Anomaly
- Measurement

Let's first analyze the *Measurement* subdomain in more detail and define domain events for it:

- Measurement data source definitions are loaded
- Measurement data source definitions are parsed
- Measurement definitions are loaded
- Measurement definitions are parsed
- Measurement data is fetched from data sources
- Measurement data is scaled (for further AI processing)

Let's continue using the event storming and define additional DDD concepts:

- Commands
    - Load measurement data source definitions
    - Parse measurement data source definitions
    - Load measurement definitions
    - Parse measurement definitions
    - Fetch measurement data from data sources
    - Scale measurement data
-Actors/Services
    - Measurement data source definitions loader
    - Measurement data source definitions parser
    - Measurement definitions loader
    - Measurement definitions parser
    - Measurement data fetcher
    - Measurement data scaler
- Entities
    - Measurement data source
    - Measurement data
    - Measurement
- Aggregates
    - Measurement
        - Measurement data source
        - Measurement query
        - Measurement data
- Aggregate root
    - Measurement
- Value Objects
    - Measurement query

Let's define domain events for the *Anomaly* subdomain:

- Anomaly detection configuration is parsed
- Anomaly detection configuration is created
- Anomaly detection rule is parsed
- Anomaly detection rule is created
- Anomalies are detected in a measurement according to the anomaly detection rule using a trained anomaly model
- Anomaly detection is triggered at regular intervals
- Anomaly model is trained for a measurement
- Anomaly model is created
- Anomaly model training is triggered at regular intervals
- A detected anomaly (i.e., an anomaly indicator) is created
- A detected anomaly (i.e., an anomaly indicator) is serialized to a wanted format, e.g., JSON
- The detected anomaly (i.e., an anomaly indicator) is published to a specific destination using a specific protocol

Let's continue with the event storming and define additional DDD concepts:

- Commands
    - Parse anomaly detection configuration
    - Create anomaly detection configuration
    - Parse anomaly detection rule definition
    - Create anomaly detection rule
    - Detect anomalies in a measurement according to the anomaly detection rule using a trained anomaly model
    - Trigger anomaly detection at regular intervals
    - Train anomaly model for a measurement using a specific AI technique, like self-organizing maps (SOM)
    - Create an anomaly model
    - Trigger anomaly model training at regular intervals
    - Create anomaly indicator
    - Serialize anomaly indicator
    - Publish anomaly indicator
- Actors/Services
    - Anomaly detection configuration parser
    - Anomaly detection rule parser
    - Anomaly detector
    - Anomaly detection engine
    - Anomaly model trainer (e.g. SOM)
    - Anomaly training engine
    - Anomaly indicator serializer (e.g. JSON)
    - Anomaly indicator publisher (e.g., REST or Kafka)
- Factories
    - Anomaly detection configuration factory
    - Anomaly detection rule factory
    - Anomaly model factory
    - Anomaly indicator factory
- Entities
    - Anomaly detection rule
    - Anomaly model
    - Anomaly indicator

The two domains, anomaly and measurement, can be developed in parallel. The anomaly domain interfaces with the measurement domain
to fetch data for a particular measurement from a particular data source. The development effort of both the
anomaly and measurement domains can be further split to achieve even more development parallelization. For example,
one developer could work with anomaly detection, another with anomaly model training, and the third with anomaly indicators.

If you want to know more about DDD, I suggest you to read *Implementing Domain-Driven Design* by *Vaughn Vernon*.

## Design Patterns

The following sections present 25 design patterns, most of which are made famous by the *Gang of Four* and their book [Design Patterns](https://en.wikipedia.org/wiki/Design_Patterns).
Design patterns are divided into creational, structural, and behavioral patterns.

### Design Patterns for Creating Objects

This section describes design patterns for creating objects. The following design patterns will be presented:

- Factory pattern
- Abstract factory pattern
- Static factory method pattern
- Builder pattern
- Singleton pattern
- Prototype pattern
- Object pool pattern

#### Factory Pattern

> ***Factory pattern allows deferring what kind of object will be created to the point of calling the *create*-method of the factory***.

A factory allows a dynamic way of creating objects instead of a static way by directly calling a concrete class constructor. A factory typically consists of precisely one or multiple methods for creating objects of a particular base type. This base type is usually an interface type. The factory decides what concrete type of object will be created. A factory
separates the logic of creating objects from the objects themselves, which is in accordance with the *single responsibility principle*.

Below is an example `ConfigParserFactory` class written in Java that has a single `create` method for creating different kinds of
`ConfigParser` objects. In the case of a single create method, the method usually contains a switch-case statement or
an if/else-if structure. Factories are the only place where extensive switch-case statements or if/else-if structures
are allowed in object-oriented programming. If you have a lengthy switch-case statement or long if/else-if structure somewhere
else in code, that is typically a sign of a non-object-oriented design.

```java
public interface ConfigParser {
  // ...
}


public class JsonConfigParser implements ConfigParser {
  // ...
}


public class YamlConfigParser implements ConfigParser {
  // ...
}


public enum ConfigFormat {
  JSON,
  YAML
}


public final class ConfigParserFactory {
  public static ConfigParser createConfigParser(
    final ConfigFormat configFormat
  ) {
    return switch(configFormat) {
      case JSON -> new JsonConfigParser();
      case YAML -> new YamlConfigParser();
      default ->
        throw new IllegalArgumentException(
          "Unsupported config format"
        );
    };
  }
}
```

Below is an example of a factory with multiple *create* methods:

```java
public final class ShapeFactory {
  public static Shape createCircleShape(final int radius) {
    return new CircleShape(radius);
  }

  public static Shape createRectangleShape(
    final int width,
    final int height
  ) {
    return new RectangleShape(width, height);
  }

  public static Shape createSquareShape(final int sideLength) {
    return new SquareShape(sideLength);
  }
}
```

#### Abstract Factory Pattern

> ***In the abstract factory pattern, there is an abstract factory (interface) and one or more concrete factories (classes that implement the factory interface).***

The abstract factory pattern extends the earlier described *factory pattern*. Usually, the abstract factory pattern should be
used instead of the plain factory pattern. Below is a Java example of an abstract `ConfigParserFactory` with one concrete implementation:

```java
public interface ConfigParserFactory {
  ConfigParser createConfigParser(ConfigFormat configFormat);
}

public class ConfigParserFactoryImpl implements
               ConfigParserFactory {
   public final ConfigParser createConfigParser(
     final ConfigFormat configFormat
   ) {
     return switch(configFormat) {
       case JSON -> new JsonConfigParser();
       case YAML -> new YamlConfigParser();
       default ->
         throw new IllegalArgumentException(
           "Unsupported config format"
         );
    };
  }
}
```

You should follow the *program against interfaces principle* and use the abstract `ConfigParserFactory` in your code instead of
a concrete factory. Then, using the *dependency injection principle*, you can inject the wanted factory
implementation, like `ConfigParserFactoryImpl`.

When unit testing code, you should create mock objects instead of real ones with a
factory. The abstract factory pattern comes to your help because you can inject a mock instance of the `ConfigParserFactory`
in the tested code. Then you can expect the mocked `createConfigParser` method to be called and return a mock instance
of the `ConfigParser` interface. And then, you can expect the `parse` method to be called on the `ConfigParser` mock and return
a mocked configuration. Below is an example unit test that uses JUnit5 and [JMockit](https://jmockit.github.io/index.html) library.
We test the `initialize` method in an `Application` class containing a `ConfigParserFactory` field. The `Application` class
uses the `ConfigParserFactory` instance to create a `ConfigParser` to parse the application configuration. In the below test, we
inject a `ConfigParserFactory` mock to an `Application` instance using the `@Injectable` annotation
from JMockit. Unit testing and mocking are better described later in the _testing principles_ chapter.

<div class="sourceCodeWithoutLabel">

```java
public class Application {
  private ConfigParserFactory configParserFactory;
  private Config config;

  public Application(final ConfigParserFactory configParserFactory) {
    this.configParserFactory = configParserFactory;
  }

  public void initialize() {
    // ...

    final var configParser = configParserFactory.createConfigParser(...);
    config = configParser.parse(...);

    // ...
  }

  public Config getConfig() {
    return config;
  }
}

public class ApplicationTests {
  @Tested
  Application application;

  @Injectable
  ConfigParserFactory configParserFactoryMock;

  @Mocked
  ConfigParser configParserMock;

  @Mocked
  Config configMock;

  @Test
  public void testInitialize() {
    // GIVEN
    new Expectations() {{
      configParserFactoryMock.createConfigParser(...);
      result = configParserMock;

      configParserMock.parse(...);
      result = configMock;
    }};

    // WHEN
    application.initialize();

    // THEN
    assertEquals(application.getConfig(), configMock);
  }
}
```

#### Static Factory Method Pattern

> ***In the static factory method pattern, objects are created using one or more static factory methods in a class, and the class constructor is made private.***

If you want to validate the parameters supplied to a constructor,
the constructor may throw an error. You cannot return an error value from a constructor. Creating constructors that cannot
throw an error is recommended because it is relatively easy
to forget to catch errors thrown in a constructor if nothing in the constructor signature tells it can throw an error.
See the next chapter for a discussion about the *error/exception handling principle*.

Below is a TypeScript example of a constructor that can throw:

```ts
class Url {
  constructor(
    scheme: string,
    port: number,
    host: string,
    path: string,
    query: string
  ) {
    // Validate the arguments and throw if invalid
  }
}
```

You can use the static factory method pattern to overcome the problem of throwing an error in a constructor.
You can make a factory method to return an optional value (if you don't need to return an error cause) or
make the factory method throw an error. You should add a *try* prefix to the factory method name
to signify that it can raise an error. Then, the function signature (function name) communicates to readers
that the function may raise an error.

Below is an example class with two factory methods and a private constructor:

{title: "Url.ts"}
```
class Url {
  private constructor(
    scheme: string,
    port: number,
    host: string,
    path: string,
    query: string
  ) {
    // ...
  }

  static createUrl(
    scheme: string,
    port: number,
    host: string,
    path: string,
    query: string
 ): Url | null {
    // Validate the arguments and return 'null' if invalid
  }

  static tryCreateUrl(
    scheme: string,
    port: number,
    host: string,
    path: string,
    query: string
  ): Url {
    // Validate the arguments and throw if invalid
  }
}
```

Returning an optional value from a factory method allows utilizing functional programming techniques. Here is an
example in Java:

```java
public class Url {
  private Url(
    final String scheme,
    final String host,
    final int port,
    final String path,
    final String query
  ) {
    // ...
  }

  public static Optional<Url> createUrl(
    final String scheme,
    final String host,
    final int port,
    final String path,
    final String query
  ) {
    // ...
  }
}

final var maybeUrl = Url.createUrl(...);

maybeUrl.ifPresent(url -> {
  // Do something with the validated and correct 'url'
});
```

Java's `Optional` class utilizes the static factory method pattern in an exemplary way. It has a private constructor and
three factory methods `empty`, `of` and `ofNullable` to create different kinds of `Optional` objects. The additional benefit of using the static factory method pattern is that you can name
the factory methods descriptively, which you can't do with constructors. The name of the factory method tells what
kind of object will be created.

#### Builder Pattern

> ***Builder pattern allows you to construct objects piece by piece.***

In the builder pattern, you add properties to the built object with _addXXX_
methods of the builder class. After adding all the needed properties, you can build the final object using
the _build_ or _buildXXX_ method of the builder class.

For example, you can construct a URL from parts of the URL. Below is a Java example of using a `UrlBuilder` class:

```java
final Optional<Url> url = new UrlBuilder()
  .addScheme("https")
  .addHost("www.google.com")
  .buildUrl();
```

The builder pattern has the benefit that properties given for the builder can be validated in the build method. You can make the
builder's build method return an optional indicating whether the building was successful. Or, you can make the build method throw if you need to return
an error. Then you should name the build method using a _try_ prefix, for example, `tryBuildUrl`.
The builder pattern also has the benefit of not needing to add default properties to the builder. For example, _https_ could be
the default scheme, and if you are building an HTTPS URL, the `addScheme` is not needed to be called. The only problem is
that you must consult the builder documentation to determine the default values.

One drawback with the builder pattern is that you can give the parameters logically in the wrong order like this:

```java
final Optional<Url> url = new UrlBuilder()
  .addHost("www.google.com")
  .addScheme("https")
  .buildUrl();
```

It works but does not look so nice. So if you are using a builder, always try to give the parameters for the builder in a logically correct order if such order exists. The builder pattern works well when there isn't any inherent order among the parameters.
Below is an example of such a case: A house built with a `HouseBuilder` class.

```java
final House house = new HouseBuilder()
  .addKitchen()
  .addLivingRoom()
  .addBedrooms(3)
  .addBathRooms(2)
  .addGarage()
  .buildHouse();
```

You can achieve functionality similar to a builder with a factory method with default parameters:

{title: "Url.ts"}
```ts
class Url {
  private constructor(
    host: string,
    path?: string,
    query?: string,
    scheme = 'https',
    port = 443
  ) {
    // ...
  }

  static createUrl(
    host: string,
    path?: string,
    query?: string,
    scheme = 'https',
    port = 443
  ): Url | null {
    // Validate the arguments and return 'null' if invalid
  }
}
```

In the factory method above, there is clear visibility of what the default values are. Of course, you cannot now
give the parameters in a logical order. There is also a greater possibility that you accidentally provide some parameters
in the wrong order because many of them are of the same type (string). This won't be a potential issue with
a builder where you use a method with a specific name to give a specific parameter. In modern development environments,
giving parameters in the wrong order is less probable because IDEs offer [inlay hints](https://www.jetbrains.com/help/idea/inlay-hints.html) for parameters. It is easy to see
if you provide a particular parameter in the wrong position. As shown below, giving parameters in the wrong order can also be avoided using
semantically validated function parameter types. Semantically validated function parameters will be discussed later in this chapter.

{title: "Url.ts"}
```ts
class Url {
  static createUrl(
    host: Host,
    path?: Path,
    query?: Query,
    scheme = Scheme.createScheme('https'),
    port = Port.createPort(443)
 ): Url | null {
    // ...
  }
}
```

You can also use factory method overloading in languages like Java, where default parameters are not supported.
But that solution, for example, in the `Url` class case, can not be easily implemented and requires quite many
overloaded methods to be introduced, which can be overwhelming for a developer.

You can always use a parameter object, not only in Java but in many other languages, too. Below is an
example in Java:


```java
import lombok.Getter;
import lombok.Setter;


@Getter
@Setter
public class UrlParams {
  private String scheme = "https";
  private String host;
  private int port = 443;
  private String path = "";
  private String query = "";

  UrlParams(final String host) {
    this.host = host;
  }
}


public class Url {
  private Url(final UrlParams urlParams) {
    // ...
  }

  public static Optional<Url> createUrl(
    final UrlParams urlParams
  ) {
    // ...
  }
}


final var urlParams = new UrlParams("www.google.com");
urlParams.setQuery("query=design+patterns");
final var maybeUrl = Url.createUrl(urlParams);
```

#### Singleton Pattern

> ***Singleton pattern defines that a class can have only one instance.***

Singletons are very common in pure object-oriented languages like Java. In many cases, a singleton class can be identified as not having any state.
And this is why only one instance of the class is needed. There is no point in creating
multiple instances that are the same. In some non-pure object-oriented languages, singletons are not as common as in pure object-oriented languages and
can often be replaced by just defining functions.

In JavaScript/TypeScript, a singleton instance can be created in a module and exported. When you import the instance from the module
in other modules, the other modules will always get the same exported instance, not a new instance every time.
Below is an example of such a singleton:

{title: "myClassSingleton.ts"}
```ts
class MyClass {
  // ...
}

export const myClassSingleton = new MyClass();
```

{title: "otherModule.ts"}
```ts
import { myClassSingleton } from 'myClassSingleton';

// ...
```

The singleton pattern can be implemented using a static class because it cannot be instantiated. The problem with a static class is that
the singleton class is then hardcoded, and static classes can be hard or impossible to mock in unit testing. We should remember to _program against interfaces_. The best way to implement
the singleton pattern is by using the _dependency inversion principle_ and the _dependency injection principle_. Below is an example in Java using the [Google Guice](https://github.com/google/guice) library for handling dependency
injection. The constructor of the `FileConfigReader` class expects a `ConfigParser`.
We annotate the constructor with the `@Inject` annotation to inject an instance implementing the `ConfigParser` interface:

```java
import com.google.inject.Inject;

public interface ConfigReader {
  Configuration tryRead(...);
}

public class FileConfigReader
         implements ConfigReader {
  private ConfigParser configParser;

  @Inject
  public FileConfigReader(
    final ConfigParser configParser
  ) {
    this.configParser = configParser;
  }

  public Configuration tryRead(
    final String configFilePathName
  ) {
    final String configFileContents = // Read configuration file

    final var configuration =
      configParser.tryParse(configFileContents);

    return configuration;
  }
}
```

In the below DI module, we configure a singleton with a lazy binding.
In the lazy binding, the `JsonConfigParser` class is only created
when needed to be used.

```java
import com.google.inject.AbstractModule;

public class DiModule extends AbstractModule {
  @Override
  protected void configure() {
    bind(ConfigParser.class)
      .to(JsonConfigParser.class)
      .in(Scopes.SINGLETON);
  }
}
```

Alternatively, we can define an eager singleton:

```java
import com.google.inject.AbstractModule;

public class DiModule extends AbstractModule {
  @Override
  protected void configure() {
    bind(ConfigParser.class)
      .to(JsonConfigParser.class)
      .asEagerSingleton();
  }
}
```

The best way to ensure that only one singleton instance is created is to ensure the DI container is created at the beginning
of the application initialization (before starting threads) and singletons are created eagerly, not lazily. Eagerly means the singleton is created immediately, and lazily means it is created only when somebody needs it.
A lazy instantiation is of course possible, but can bring problems in a multi-threaded environment if synchronization is not used when the singleton instance is actually created.

#### Prototype Pattern

> ***The prototype pattern lets you create a new object using an existing object as a prototype.***

Let's have a Java example with a `DrawnShape` class:

```java
public interface Shape {
  // ...
}


// Implement concrete shapes...


public interface Position {
  int getX();
  int getY();
}


public class DrawnShape {
  private final Position position;
  private final Shape shape;

  public DrawnShape(
    final Position position,
    final Shape shape
  ) {
    this.position = position;
    this.shape = shape;
  }

  public DrawnShape(
    final Position position,
    final DrawnShape drawnShape
  ) {
    this.position = position;
    shape = drawnShape.getShape();
  }

  public DrawnShape cloneTo(
    final Position position
  ) {
    return new DrawnShape(position, this);
  }

  public Shape getShape() {
    return this.shape;
  }
}
```

In the second constructor, we are using the prototype pattern. A new `DrawnShape` object is created from
an existing `DrawnShape` object. An alternative way to use the prototype pattern is to call the `cloneTo` method on
a prototype object and give the position parameter to specify where the new shape should be positioned.

The prototype pattern is also used in JavaScript to implement prototypal inheritance. Since EcmaScript version 6,
class-based inheritance has been available, and prototypal inheritance is not needed to be used.

The idea of prototypal inheritance is that the common parts for the same class objects are stored in a
prototype instance. These common parts typically mean the shared methods. There is no sense in storing the methods multiple times in each object.
That would be a waste of resources because Javascript functions are objects themselves.

When you create a new object with the `Object.create` method, you give the prototype as a parameter. After that, you can set properties
for the newly created object. When you call a method on the created object, and if that method
is not found in the object's properties, the prototype object will be looked up for the method. Prototypes can be chained
so that a prototype object contains another prototype object. This chaining is used to implement an inheritance chain.
Below is a simple example of prototypal inheritance:

```ja
const pet = {
  name: '',
  getName: function() { return this.name; }
};

// Creates a new object with 'pet' object as a prototype
const petNamedBella = Object.create(pet);

petNamedBella.name = 'Bella';
console.log(petNamedBella.getName()); // Prints 'Bella'

// Prototype of a dog which contains 'pet' as nested prototype
const dog = {
  bark: function() { console.log('bark'); },
  __proto__: pet
}

// Creates a new object with 'dog' object as prototype
const dogNamedLuna = Object.create(dog);

dogNamedLuna.name = 'Luna';
console.log(dogNamedLuna.getName()); // Prints 'Luna'
dogNamedLuna.bark(); // Prints 'bark'
```

#### Object Pool Pattern

> ***In the object pool pattern, created objects are stored in a pool where objects can be acquired from and returned for reuse. The object pool pattern is an optimization pattern because it allows the reuse of once-created objects.***

If you need to create many short-lived objects, you should utilize an object pool and reduce the need
for memory allocation and de-allocation, which takes time. In garbage-collected languages, frequent object creation and
deletion cause extra work for the garbage collector, which consumes CPU time.

Below is an example object pool implementation in C++. The below `LimitedSizeObjectPool` class implementation uses a spin lock in
its methods to achieve thread safety. More about thread safety in the coming _concurrent programming principles_ chapter.

{title: "ObjectPool.h"}
```cpp
#include <memory>

template <typename T>
class ObjectPool
{
public:
  virtual ~ObjectPool() = default;

  virtual std::shared_ptr<T> acquireObject() = 0;
  virtual void returnObject(std::shared_ptr<T> object) = 0;
};
```

{title: "LimitedSizeObjectPool.h"}
```cpp
#include <deque>
#include "ScopedSpinlock.h"
#include "Spinlock.h"
#include "ObjectPool.h"

template <typename T>
class LimitedSizeObjectPool : public ObjectPool<T>
{
public:
  explicit LimitedSizeObjectPool(const size_t maxPoolSize):
    m_maxPoolSize(maxPoolSize)
  {}

  std::shared_ptr<T> acquireObject()
  {
    std::shared_ptr<T> object;
    const ScopedSpinlock scopedLock{m_lock};

    if (m_pooledObjects.empty())
    {
      object = std::make_shared<T>();
    }
    else
    {
      object = m_pooledObjects.front();
      m_pooledObjects.pop_front();
    }

    return object;
  }

  void returnObject(std::shared_ptr<T> object)
  {
    const ScopedSpinlock scopedLock{m_lock};

    const bool poolIsFull =
      m_pooledObjects.size() >= m_maxPoolSize;

    if (poolIsFull)
    {
      object.reset();
    }
    else
    {
      m_pooledObjects.push_back(object);
    }
  }

private:
  Spinlock m_lock;
  size_t m_maxPoolSize;
  std::deque<std::shared_ptr<T>> m_pooledObjects;
};
```

Below is a slightly different implementation of an object pool. The below implementation accepts clearable objects, meaning
objects returned to the pool are cleared before reusing. The below implementation allows you to define
whether the allocated objects are wrapped inside a shared or unique pointer. You can also supply parameters used when constructing an object.

{title: "ObjectPool.h"}
```
#include <concepts>
#include <deque>
#include <memory>

template<typename T>
concept ClearableObject =
requires(T object)
{
  { object.clear() } -> std::convertible_to<void>;
};

template<typename T, typename U>
concept Pointer = std::derived_from<T, std::shared_ptr<U>> ||
                  std::derived_from<T, std::unique_ptr<U>>;

template<
  ClearableObject O,
  typename ObjectInterface,
  Pointer<ObjectInterface> OP,
  typename ...Args
>
class ObjectPool
{
public:
  virtual ~ObjectPool() = default;

  virtual OP acquireObject(Args&& ...args) = 0;

  virtual void acquireObjects(
    std::deque<OP>& objects,
    size_t objectCount,
    Args&& ...args
   ) = 0;

  virtual void returnObject(OP object) = 0;
  virtual void returnObjects(std::deque<OP>& objects) = 0;
};
```

{title: "LimitedSizeObjectPool.h"}
```cpp
#include "ScopedLock.h"
#include "Spinlock.h"
#include "ObjectPool.h"

template<
  ClearableObject O,
  typename ObjectInterface,
  Pointer<ObjectInterface> OP,
  typename ...Args
>
class LimitedSizeObjectPool :
   public ObjectPool<O, ObjectInterface, OP, Args...>
{
public:
  explicit LimitedSizeObjectPool(const size_t maxPoolSize) :
    m_maxPoolSize(maxPoolSize)
  {}

  OP acquireObject(Args&& ...args) override
  {
    const ScopedLock scopedLock(m_lock);
    OP acquiredObject;

    if (const bool poolIsEmpty = m_pooledObjects.empty();
            poolIsEmpty)
    {
      acquiredObject = OP{new O{std::forward<Args>(args)...}};
    }
    else
    {
      acquiredObject = m_pooledObjects.front();
      m_pooledObjects.pop_front();
    }

    return acquiredObject;
  }

  void acquireObjects(
    std::deque<OP>& objects,
    const size_t objectCount,
    Args&& ...args
  ) override
  {
    for (size_t n{1U}; n <= objectCount; ++n)
    {
      objects.push_back(acquireObject(std::forward<Args>(args)...));
    }
  }

  void returnObject(OP object) override
  {
    const ScopedLock scopedLock(m_lock);

    if (const bool poolIsFull = m_pooledObjects.size() >=
                                m_maxPoolSize;
            poolIsFull)
    {
        object.reset();
    }
    else
    {
        object->clear();
        m_pooledObjects.push_back(object);
    }
  }

  void returnObjects(std::deque<OP>& objects) override
  {
    while (!objects.empty())
    {
      returnObject(objects.front());
      objects.pop_front();
    }
  }

private:
  size_t m_maxPoolSize;
  Spinlock m_lock;
  std::deque<OP> m_pooledObjects;
};
```

In the below example, we create a message pool for a maximum of 5000 output messages.
We get a shared pointer to an output message from the pool. The pool's concrete class to create
new objects is `OutputMessageImpl`. When we acquire an output message from the pool, we provide a `size_t` type value (= output message length)
to the constructor of the `OutputMessageImpl` class. The `OutputMessageImpl` class must be clearable, i.e.,
it must have a `clear` method returning `void`.

```cpp
LimitedSizeObjectPool<
  OutputMessageImpl,
  OutputMessage,
  std::shared_ptr<OutputMessage>,
  size_t
> outputMessagePool{5000U};

// Acquire an output message of 1024 bytes from the pool.
const auto outputMessage = outputMessagePool.acquireObject(1024U);
```

### Structural Design Patterns

This section describes structural design patterns. Most patterns use object composition as the primary method
to achieve a particular design. The following design patterns are presented:

- Composite pattern
- Facade pattern
- Bridge pattern
- Strategy pattern
- Adapter pattern
- Proxy pattern
- Decorator pattern
- Flyweight pattern

#### Composite Pattern

> ***In the composite pattern, a class can be composed of itself, i.e., the composition is recursive.***

Recursive object composition can be depicted by how a user interface can be composed of different widgets.
In the Java example below, we have a `Pane` class that is a `Widget`. A `Pane` object can contain several other `Widget` objects,
meaning a `Pane` object can contain other `Pane` objects.

```java
public interface Widget {
  void render();
}


public class Pane implements Widget {
  private final List<Widget> widgets;

  public void render() {
    // Render each widget inside pane
  }
}


public class StaticText implements Widget {
  public void render() {
   // Render static text widget
  }

  // ...
}


public class TextInput implements Widget {
  public void render() {
    // Render text input widget
  }
}


public class Button implements Widget {
  public void render() {
    // Render button widget
  }
}


public class UIWindow {
  private final List<Widget> widgets = new ArrayList<>(10);

  public void render() {
    widgets.forEach(Widget::render);
  }
}
```

Objects that form a tree structure are composed of themselves recursively.
Below is an [Avro](https://avro.apache.org/) record field schema with a nested record field:

```json
{
  "type": "record",
  "name": "sampleMessage",
  "fields": [
    {
      "name": "field1",
      "type": "string"
    },
    {
      "name": "nestedRecordField",
      "namespace": "nestedRecordField",
      "type": "record",
      "fields": [
        {
          "name": "nestedField1",
          "type": "int",
          "signed": "false"
        }
      ]
    }
  ]
}
```

For parsing an Avro schema, we could define classes for different sub-schemas by the field type. When analyzing the below example, we can
notice that the `RecordAvroFieldSchema` class can contain any `AvroFieldSchema` object, also
other `RecordAvroFieldSchema` objects, making a `RecordAvroFieldSchema` object a composite object.

```java
public interface AvroFieldSchema {
  // ...
}

public class RecordAvroFieldSchema implements AvroFieldSchema {
  private final List<AvroFieldSchema> subFieldSchemas;

  // ...
}

public class StringAvroFieldSchema implements AvroFieldSchema {
  // ...
}

public class IntAvroFieldSchema implements AvroFieldSchema {
  // ...
}
```

#### Facade Pattern

> ***In the facade pattern, an object on a higher level of abstraction is composed of objects on a lower level of abstraction.***
> ***The higher-level object acts as a facade in front of the lower-level objects. Lower-level objects behind the facade are***
> ***either only or mainly only accessible by the facade.***

Let's use the data exporter microservice as an example. For that microservice, we could create a `Config` interface
that can be used to obtain configuration for the different parts (input,
transform, and output) of the data exporter microservice. The `Config` interface acts as a facade. Users of
the facade need not see behind the facade. They don't know what happens behind the facade. And they shouldn't care
because they are just using the interface provided by the facade.

There can be various classes doing the actual work behind the facade. In the below example, there is a `ConfigReader` class
that reads configuration from possibly different sources (from a local file or a remote service, for example)
and there are configuration parsers that can parse a specific part of the configuration, possibly in different data formats like
JSON or YAML. None of these implementations and details are visible to the user of the facade. Any of these implementations
behind the facade can change at any time without affecting the users of the facade because facade users are not coupled to the lower-level implementations.

Below is the implementation of the `Configuration` facade in Java:

```java
import com.google.inject.Inject;


public interface Configuration {
  InputConfig tryGetInputConfig();
  TransformerConfig tryGetTransformerConfig();
  OutputConfig tryGetOutputConfig();
}


public class ConfigurationImpl implements Configuration {
  private final ConfigReader configReader;
  private final InputConfigParser inputConfigParser;
  private final TransformerConfigParser transformerConfigParser;
  private final OutputConfigParser outputConfigParser;
  private String configString = "";
  private Optional<InputConfig> inputConfig = Optional.empty();
  private Optional<OutputConfig> outputConfig = Optional.empty();

  private Optional<TransformerConfig> transformerConfig =
    Optional.empty();

  @Inject
  public ConfigurationImpl(
    final ConfigReader configReader,
    final InputConfigParser inputConfigParser,
    final TransformerConfigParser transformerConfigParser,
    final OutputConfigParser outputConfigParser
  ) {
    // ...
  }

  public InputConfig tryGetInputConfig() {
    return inputConfig.orElseGet(() -> {
      tryReadConfigIfNeeded();

      inputConfig =
        inputConfigParser.tryParseInputConfig(configString);

      return inputConfig;
    });
  }

  public TransformerConfig tryGetTransformerConfig() {
    // ...
  }

  public OutputConfig tryGetOutputConfig() {
    // ...
  }

  private void tryReadConfigIfNeeded() {
    if (configString.isEmpty()) {
      configString =
        configReader.tryRead(...);
    }
  }
}
```

#### Bridge Pattern

> ***In the bridge pattern, the implementation of a class is *delegated* to another class. The original class is "abstract"***
> ***in the sense that it does not have any behavior except the delegation to another class, or it can have some higher level***
> ***control logic on how it delegates to another class.***

Don't confuse the word "abstract" here with an abstract class. In an abstract class, some behavior is not implemented at all,
but the implementation is deferred to subclasses of the abstract class. Here, instead of "abstract class", we could use the term
*delegating class* instead.

![Bridge Pattern](resources/chapter2/images/bridge_pattern.png)

Let's have a Java example with shapes and drawings capable of drawing different shapes:

```java
public interface Shape {
  void render(final ShapeRenderer renderer);
}


public class RectangleShape implements Shape {
  private final Point upperLeftCorner;
  private final int width;
  private final int height;

  public RectangleShape(
    final Point upperLeftCorner,
    final int width,
    final int height
    ) {
    this.upperLeftCorner = upperLeftCorner;
    this.width = width;
    this.height = height;
  }

  public void render(final ShapeRenderer renderer) {
    renderer.renderRectangleShape(upperLeftCorner, width, height);
  }
}


public class CircleShape implements Shape {
  private final Point center;
  private final int radius;

  public CircleShape(final Point center, final int radius) {
    this.center = center;
    this.radius = radius;
  }

  public void render(final ShapeRenderer renderer) {
    renderer.renderCircleShape(center, radius);
  }
}
```

The above `RectangleShape` and `CircleShape` classes are abstractions (or delegating classes) because they delegate their functionality (rendering)
to an external class (implementation class) of the `ShapeRenderer` type. We can provide different rendering implementations for
the shape classes. Let's define two shape renderers, one for rendering raster shapes and another for rendering vector
shapes:

```java
public interface ShapeRenderer {
  void renderCircleShape(final Point center, final int radius);

  void renderRectangleShape(
    final Point upperLeftCorner,
    final int width,
    final int height
  );

  // Methods for rendering other shapes...
}


public class RasterShapeRenderer implements ShapeRenderer {
  private final Canvas canvas;

  public RasterShapeRenderer(final Canvas canvas) {
    this.canvas = canvas;
  }

  public void renderCircleShape(
    final Point center,
    final int radius
  ) {
    // Renders circle to canvas
  }

  public void renderRectangleShape(
    final Point upperLeftCorner,
    final int width,
    final int height
  ) {
    // Renders a rectangle to canvas
  }

  // Methods for rendering other shapes to the canvas
}


public class VectorShapeRenderer implements ShapeRenderer {
  private final SvgElement svgRoot;

  public VectorShapeRenderer(final SvgElement svgRoot) {
    this.svgRoot = svgRoot;
  }

  public void renderCircleShape(
    final Point center,
    final int radius
  ) {
    // Render circle as SVG element and attach as child to SVG root
  }

  public void renderRectangleShape(
    final Point upperLeftCorner,
    final int width,
    final int height
  ) {
    // Render rectangle as SVG element
    // and attach as child to SVG root
  }

  // Methods for rendering other shapes
}
```

Let's implement two different drawings, a raster and a vector drawing:

```java
public interface Drawing {

  void draw();
  void save();
}

public abstract class AbstractDrawing implements Drawing {
  private final String name;

  public AbstractDrawing(final String name) {
    this.name = name;
  }

  public final void save() {
    final var fileName = name + getFileExtension();
    final var data = getData();

    // Save the 'data' to 'fileName'
  }

  public final void draw(final List<Shape> shapes) {
    for (final var shape: shapes) {
      shape.render(getShapeRenderer());
    }
  }

  protected abstract ShapeRenderer getShapeRenderer();
  protected abstract String getFileExtension();
  protected abstract byte[] getData();
}

public class RasterDrawing extends AbstractDrawing {
  private final Canvas canvas = new Canvas();

  private final RasterShapeRenderer shapeRenderer =
    new RasterShapeRenderer(canvas);

  public RasterDrawing(final String name) {
    super(name);
  }

  protected ShapeRenderer getShapeRenderer() {
    return shapeRenderer;
  }

  protected String getFileExtension() {
    return ".png";
  }

  protected byte[] getData() {
    // get data from the 'canvas' object
  }
}

public class VectorDrawing extends AbstractDrawing {
  private final SvgElement svgRoot = new SvgElement();

  private final VectorShapeRenderer shapeRenderer =
    new VectorShapeRenderer(svgRoot);

  public VectorDrawing(final String name) {
    super(name);
  }

  protected ShapeRenderer getShapeRenderer() {
    return shapeRenderer;
  }

  protected String getFileExtension() {
    return ".svg";
  }

  protected byte[] getData() {
    // get data from the 'svgRoot' object
  }
}

In the above example, we have delegated the rendering behavior of the shape classes to concrete classes implementing the `ShapeRenderer` protocol.
The `Shape` classes only represent a shape but don't render the shape. They have a single responsibility of representing
a shape. Regarding rendering, the shape classes are "abstractions" because they delegate the rendering to another class responsible for rendering different shapes.

Now, we can have a list of shapes and render them differently. We can do this as shown below because we did not couple the shape classes with
any specific rendering behavior.

```java
final List<Shape> shapes = new ArrayList<>(50);
// Add various shapes to 'shapes' list here...

final var rasterDrawing = new RasterDrawing("raster-drawing-1");
rasterDrawing.draw(shapes);
rasterDrawing.save();

final var vectorDrawing = new VectorDrawing("vector-drawing-1");
vectorDrawing.draw(shapes);
vectorDrawing.save();
```

#### Strategy Pattern

> ***In the strategy pattern, the functionality of an object can be changed by changing an instance of a composed type to a different instance of that type.***

Below is a Java example where the behavior of a `ConfigReader` class can be changed by changing the value of the `config_parser` attribute
to an instance of a different class. The default behavior is to parse the configuration in JSON format,
which can be achieved by calling the constructor without a parameter.

```java
public class ConfigReader {
  private final ConfigParser configParser;

  public ConfigReader() {
    configParser = new JsonConfigParser();
  }

  public ConfigReader(final ConfigParser configParser) {
    this.configParser = configParser;
  }

  public Configuration tryRead(final String configFilePathName) {
    // Try read the configuration file contents to a string
    // variable named 'configFileContents'

    final Configuration configuration =
      configParser.tryParse(configFileContents);

    return configuration;
  }
}
```

Using the strategy pattern, we can change the functionality of a `ConfigReader` instance by changing
the `config_parser` attribute value. For example, there could be the following classes available that
implement the `ConfigParser` protocol:

- `JsonConfigParser`
- `YamlConfigParser`
- `TomlConfigParser`
- `XmlConfigParser`

We can dynamically change the behavior of a `ConfigReader` instance to use the YAML parsing strategy
by giving an instance of the `YamlConfigParser` class as a parameter for the `ConfigReader` constructor.

#### Adapter Pattern

> ***The adapter pattern changes one interface to another interface. It allows you to adapt different interfaces to a single interface.***

In the below C++ example, we have defined a `Message` interface for messages that can be consumed from a data source
using a `MessageConsumer`.

{title: "Message.h"}
```cpp
#include <cstdint>


class Message
{
public:
  Message() = default;
  virtual ~Message() = default;

  virtual uint8_t* getData() const = 0;
  virtual std::size_t getDataLengthInBytes() const = 0;
};
```

{title: "MessageConsumer.h"}
```cpp
#include <memory>
#include "Message.h"


class MessageConsumer
{
public:
  MessageConsumer() = default;
  virtual ~MessageConsumer() = default;

  virtual std::shared_ptr<Message> consumeMessage() = 0;
};
```

Next, we can define the message and message consumer adapter classes for Apache Kafka and Apache Pulsar:

{title: "KafkaMessageConsumer.h"}
```cpp
#include "MessageConsumer.h"


class KafkaMessageConsumer : public MessageConsumer
{
public:
  KafkaMessageConsumer(...);
  ~KafkaMessageConsumer() override;

  std::shared_ptr<Message> consumeMessage() override {
    // Consume a message from Kafka using a 3rd party
    // Kafka library, e.g. LibRdKafka
    // Wrap the consumed LibRdKafka message inside an instance
    // of KafkaMessage class
    // Return the KafkaMessage instance
  }
};
```

{title: "KafkaMessage.h"}
```cpp
#include <bit>
#include <librdkafka/rdkafkacpp.h>
#include "Message.h"


class KafkaMessage : public Message
{
public:
  explicit KafkaMessage(RdKafka::Message* const message):
    m_message(message)
  {}

  ~KafkaMessage() override
  {
    delete m_message;
  }

  uint8_t* getData() const override
  {
    return std::bit_cast<uint8_t*>(m_message->payload());
  }

  std::size_t getDataLengthInBytes() const override
  {
    return m_message->len();
  }

private:
  RdKafka::Message* m_message;
};
```

{title: "PulsarMessageConsumer.h"}
```cpp
#include "MessageConsumer.h"


class PulsarMessageConsumer : public MessageConsumer
{
public:
  PulsarMessageConsumer(...);
  ~PulsarMessageConsumer() override;

  std::shared_ptr<Message> consumeMessage() override {
    // Consume a message from Pulsar using the Pulsar C++ client
    // Wrap the consumed Pulsar message inside an instance
    // of PulsarMessage
    // Return the PulsarMessage instance
  }
};
```

{title: "PulsarMessage.h"}
```cpp
#include "Message.h"


class PulsarMessage : public Message
{
public:
  // ...
};
```

Now we can use Kafka or Pulsar data sources with identical consumer and message interfaces.
In the future, it will be easy to integrate a new data source into the system.
We only need to implement appropriate adapter classes (message and consumer classes) for the new data source. No other code changes are required.
Thus, we would be following the _open-closed principle_ correctly.

Let's imagine that the API of the used Kafka library changed. We don't need to make changes in many
places in the code. We need to create new adapter classes (message and consumer classes) for the new API and use those new adapter classes
in place of the old adapter classes. All of this work is again following the *open-closed principle*.

Consider using the adapter pattern even if there is nothing to adapt to, especially when working with 3rd party libraries.
Because then you will be prepared for the future when changes can come. It might be possible that a 3rd party library interface
changes or there is a need to take a different library into use. If you have not used the adapter pattern, taking a new library
or library version into use could mean that you must make many small
changes in several places in the codebase, which is error-prone and against the *open-closed principle*.

Let's have an example of using a 3rd party logging library. Initially, our adapter `AbcLogger` for a fictive *abc-logging-library* is just a
wrapper around the `abc_logger` instance from the library. There is not any actual adapting done.

{title: "Logger.ts"}
```ts
import { LogLevel } from 'LogLevel';


export interface Logger {
  log(logLevel: LogLevel, logMessage: string): void;
}
```

{title: "AbcLogger.ts"}
```ts
import abcLogger from 'abc-logging-library';
import Logger from 'Logger';
import LogLevel  from 'LogLevel';


class AbcLogger implements Logger {
  log(logLevel: LogLevel, logMessage: string): void {
    abcLogger.log(logLevel, logMessage);
  }
}

export default AbcLogger;
```

When you use the logger in your application, you can utilize the *singleton pattern* and create a singleton instance of
the `AbcLogger` in the DI container and let the DI framework inject the logger to all parts of the software component where
a logger is needed. Here is how the DI module could look:

{title: "DiModule.ts"}
```ts
import { Module } from 'noicejs';
import AbcLogger from 'AbcLogger';

class DiModule extends Module {
  public async configure(options) {
    await super.configure(options);

    this.bind('logger').toConstructor(AbcLogger);
  }
}
```

When you need the logger in any other class of the application, you can get it:

```ts
import { Container, Inject } from 'noicejs';

@Inject('logger')
class SomeClass:
  private readonly Logger logger;

  constructor(args) {
    this.logger = args.logger;
  }
```

Suppose that in the future, a better logging library is available called *xyz-logging-library*, and we
would like to take that into use, but it has a slightly different interface. Its logging instance is called `xyz_log_writer`,
the logging method is named differently, and the parameters are given in different order compared to the *abc-logging-library*.
We can create a `XyzLogger` adapter class for the new logging library and update the `DiContainer`. No other code changes are required elsewhere in the codebase to take the new logging library into use.

{title: "XyzLogger.ts"}
```ts
import xyzLogWriter from 'xyz-logging-library';
import Logger from Logger;
import LogLevel from 'LogLevel';


class XyzLogger implements Logger {
  log(logLevel: LogLevel, logMessage: string): void {
    xyzLogWriter.writeLogEntry(logMessage, logLevel);
  }
}

export default XyzLogger;
```

{title: "DiModule.ts"}
```ts
import { Module } from 'noicejs';
import XyzLogger from 'XyzLogger';

class DiModule extends Module {
  public async configure(options) {
    await super.configure(options);

    this.bind('logger').toConstructor(XyzLogger);
  }
}
```

We didn't have to modify all the places where logging is used in the codebase (and we can be sure that logging is used in many places!).
We have saved ourselves from a lot of error-prone and unnecessary work, and once again, we have followed the *open-closed principle* successfully.

In some languages where mocking of, e.g., concrete classes is not possible, wrapping a 3rd party library in an adapter class enables you to unit test against the adapter class interface instead of the concrete classes of the 3rd party library.

#### Proxy Pattern

> ***The proxy pattern enables conditionally modifying or augmenting the behavior of an object.***

When using the proxy pattern, you define a proxy class that wraps another class (the proxied class). The proxy class conditionally delegates
to the wrapped class. The proxy class implements the interface of the wrapped class and is used in place of the wrapped
class in the code.

Below is an example of a TypeScript proxy class, `CachingEntityStore`, that caches the results of entity store operations:

```ts
class MemoryCache<K, V> {
  // ...

  retrieveBy(key: K): V {
    // ...
  }

  store(key: K, value: V, timeToLiveInSecs?: number): void {
    // ...
  }
}


interface EntityStore<T> {
  getEntityById(id: number): Promise<T>;
}


class DbEntityStore<T> implements EntityStore<T> {
  getEntityById(id: number): Promise<T> {
    // Try get entity from database
  }
}


class CachingEntityStore<T> implements EntityStore<T> {
  private readonly entityCache = new MemoryCache<number, T>();

  constructor(private readonly entityStore: EntityStore<T>)
  {}

  async getEntityById(id: number): Promise<T> {
    let entity = this.entityCache.retrieveBy(id);

    if (entity === undefined) {
      entity = await this.entityStore.getEntityById(id);
      const timeToLiveInSecs = 60;
      this.entityCache.store(id, entity, timeToLiveInSecs);
    }

    return entity;
  }
}
```

In the above example, the `CachingEntityStore` class is the proxy class wrapping an `EntityStore`.
The proxy class is modifying the wrapped class behavior by conditionally delegating to the wrapped class. It
delegates to the wrapped class only if an entity is not found in the cache.

Below is another TypeScript example of a proxy class that authorizes a user before performing a service operation:

```ts
interface UserService {
  getUserById(id: number): Promise<User>;
}


class UserServiceImpl implements UserService {
  getUserById(id: number): Promise<User> {
    // Try get user by id
  }
}


class AuthorizingUserService implements UserService {
  constructor(
    private readonly userService: UserService,
    private readonly userAuthorizer: UserAuthorizer
  ) {}

  async getUserById(id: number): Promise<User> {
    try {
      await this.userAuthorizer.tryAuthorizeUser(id);
    } catch (error: any) {
      throw new UserServiceError(error.message);
    }

    return this.userService.getUserById(id);
  }
}
```

In the above example, the `AuthorizingUserService` class is a proxy class that wraps a
`UserService`. The proxy class is modifying the wrapped class behavior by conditionally delegating to the wrapped
class. It will delegate to the wrapped class only if authorization is successful.


As the last example, we could define a `RateLimitedXyzService` proxy class that wraps a `XyzService` class.
The rate-limited service class delegates to the wrapped class only if the service calling rate limit is not exceeded. The rate-limited service class should raise an error if the rate is exceeded.

#### Decorator Pattern

> ***The decorator pattern enables augmenting the functionality of a class method(s) without the need to modify the class method(s).***

A decorator class wraps another class whose functionality will be augmented. The decorator class implements the interface
of the wrapped class and is used in place of the wrapped class in the code. The decorator pattern is useful when you
cannot modify an existing class, e.g., the existing class is in a 3rd party library. The decorator pattern also helps
to follow the *open-closed principle* because you don't have to modify an existing
method to augment its functionality. Instead, you can create a decorator class that contains the new functionality.

Below is a TypeScript example of the decorator pattern. There is a standard SQL statement executor implementation and
two decorated SQL statement executor implementations: one that adds logging functionality and one that adds SQL statement
execution timing functionality. Finally, a double-decorated SQL statement executor is created that logs an SQL statement and times its execution.

```ts
import logger from 'logger';
import LogLevel from 'LogLevel';


interface SqlStatementExecutor {
  tryExecute(
    sqlStatement: string,
    parameterValues?: any[]
  ): Promise<any>;
}


class SqlStatementExecutorImpl implements SqlStatementExecutor {
  // Implement getConnection()

  tryExecute(
    sqlStatement: string,
    parameterValues?: any[]
  ): Promise<any> {
    return this.getConnection().execute(sqlStatement,
                                        parameterValues);
  }
}


class LoggingSqlStatementExecutor
        implements SqlStatementExecutor {
  constructor(
    private readonly sqlStatementExecutor: SqlStatementExecutor
  ) {}

  tryExecute(
    sqlStatement: string,
    parameterValues?: any[]
  ): Promise<any> {
    logger.log(LogLevel.Debug,
               `Executing SQL statement: ${sqlStatement}`);

    return this.sqlStatementExecutor
      .tryExecute(sqlStatement, parameterValues);
  }
}


class TimingSqlStatementExecutor
        implements SqlStatementExecutor {
  constructor(
    private readonly sqlStatementExecutor: SqlStatementExecutor
  ) {}

  async tryExecute(
    sqlStatement: string,
    parameterValues?: any[]
  ): Promise<any> {
    const startTimeInMs = Date.now();

    const result =
      await this.sqlStatementExecutor
        .tryExecute(sqlStatement, parameterValues);

    const endTimeInMs = Date.now();
    const durationInMs = endTimeInMs - startTimeInMs;

    logger.log(LogLevel.Debug,
    `SQL statement execution duration: ${durationInMs} ms`);

    return result;
  }
}


const timingAndLoggingSqlStatementExecutor =
  new LoggingSqlStatementExecutor(
    new TimingSqlStatementExecutor(
      new SqlStatementExecutorImpl()));
```

You can also use the decorator pattern with functions and methods in TypeScript. Decorators allow us to wrap a function
to extend its behavior. Decorators are functions that
take a function as a parameter and return another function that is used in place of the decorated function. Let's have an elementary
example of a function decorator:

```ts
// Decorator
function printHello(func: any, context: ClassMethodDecoratorContext) {
  function wrappedFunc(this: any, ...args: any[]) {
    console.log('Hello');
    return func.call(this, ...args);
  }

  return wrappedFunc;
}


class Adder {
  @printHello
  add(a: number, b: number): number {
    return a + b;
  }
}


// Prints: Hello 3
const result = new Adder().add(1, 2);
console.log(result);
```

Decorators can accept parameters:

```ts
function printText(text: string) {
  function decorate(func: any, context: ClassMethodDecoratorContext) {
    function wrappedFunc(this: any, ...args: any[]) {
      console.log(text);
      return func.call(this, ...args);
    }

    return wrappedFunc;
  }

  return decorate;
}


class Adder {
  @printText('Hello World!')
  add(a: number, b: number): number {
    return a + b;
  }
}


// Prints: Hello World! 3
const result = new Adder().add(1, 2);
console.log(result);
```

Let's have another example with a decorator that times the execution of a function and prints it to the console:

```ts
// Decorator
function timed(func: any, context: ClassMethodDecoratorContext) {
  function wrapped_func(this: any, ...args: any[]) {
    const start_time_in_ns = process.hrtime.bigint();
    const result = func.call(this, ...args);
    const end_time_in_ns = process.hrtime.bigint();
    const duration_in_ns = end_time_in_ns - start_time_in_ns;

    console.log(
      `Exec of func "${String(context.name)}" took ${duration_in_ns} ns`
    );

    return result;
  }

  return wrapped_func;
}


  class Adder {
    @timed
    add(a: number, b: number): number {
      return a + b;
    }
  }


// Prints, for example: Exec of func "add" took 7500 ns
const result = new Adder().add(1, 2);
```

You can combine multiple decorators, for example:

```ts
function logged(func: any, context: ClassMethodDecoratorContext) {
  function wrapped_func(this: any, ...args: any[]) {
    const result = func.call(this, ...args);
    console.log(
      `Func "${String(context.name)}" executed`
    );

    return result;
  }

  return wrapped_func;
}

function timed(func: any, context: ClassMethodDecoratorContext) {
  function wrapped_func(this: any, ...args: any[]) {
    const start_time_in_ns = process.hrtime.bigint();
    const result = func.call(this, ...args);
    const end_time_in_ns = process.hrtime.bigint();
    const duration_in_ns = end_time_in_ns - start_time_in_ns;

    console.log(
      `Exec of func "${String(context.name)}" took ${duration_in_ns} ns`
    );

    return result;
  }

  return wrapped_func;
}


class Adder {
  @logged
  @timed
  add(a: number, b: number): number {
    return a + b;
  }
}

#### Flyweight Pattern

> ***The flyweight pattern is a memory-saving optimization pattern where flyweight objects reuse objects.***

Let's have a simple example with a game where different shapes are drawn at different positions. Let's assume
that the game draws a lot of similar shapes but in different positions so that we can notice the difference
in memory consumption after applying this pattern.

Shapes that the game draws have the following properties: size, form, fill color, stroke color, stroke width, and stroke style.

```java
public interface Shape {
  // ...
}


// Color...
// StrokeStyle...


public class AbstractShape implements Shape {
  private final Color fillColor;
  private final Color strokeColor;
  private final int strokeWidth;
  private final StrokeStyle strokeStyle;

  // ...
}


public class CircleShape extends AbstractShape {
  private final int radius;

  // ...
}


// LineSegment...


public class PolygonShape extends AbstractShape {
  private final List<LineSegment> lineSegments;

  // ...
}
```

When analyzing the `PolygonShape` class, we notice that it contains many properties
that consume memory. A polygon with many line segments can consume a noticeable amount of memory.
If the game draws many identical polygons in different screen positions and always creates a new `PolygonShape` object,
there would be a lot of identical `PolygonShape` objects in the memory. To remediate this, we can introduce a flyweight class, `DrawnShapeImpl`,
which contains the position of a shape and a reference to the actual shape. In this way, we can draw a lot of
`DrawnShapeImpl` objects that all contain a reference to the same `PolygonShape` object:

```java
public interface DrawnShape {
  // ...
}


public class DrawnShapeImpl implements DrawnShape {
  private final Shape shape;
  private Position screenPosition;

  public DrawnShapeImpl(
    final Shape shape,
    final Position screenPosition
  ) {
    this.shape = shape;
    this.screenPosition = screenPosition;
  }

  // ...
}


final Shape polygon = new PolygonShape(...);
final List<Position> positions = generateLotsOfPositions();

final var drawnPolygons = positions.stream().map(position ->
  new DrawnShapeImpl(polygon, position)
);
```

### Behavioral Design Patterns

Behavioral design patterns describe ways to implement new behavior using object-oriented design.
The following behavioral design patterns will be presented in the following sections:

- Chain of responsibility pattern
- Observer pattern
- Command/Action pattern
- Iterator pattern
- Interpreter pattern
- State pattern
- Mediator pattern
- Template method pattern
- Memento pattern
- Visitor pattern
- Null object pattern

#### Chain of Responsibility Pattern

> ***The chain of responsibility pattern lets you pass requests along a chain of handlers.***

The chain of responsibility pattern allows you to add pluggable behavior to handling requests. That pluggable behavior is something
that can be executed always or conditionally. This pattern allows you to follow the open-closed principle because you don't modify the
request-handling process directly but only extend it with plug-ins. This pattern allows you to follow the single responsibility principle by putting specific behavior into a plug-in.

When receiving a request, each handler can decide what to do:

- Process the request and then pass it to the next handler in the chain
- Process the request without passing it to the subsequent handlers (terminating the chain)
- Leave the request unprocessed and pass it to the next handler

One of the most famous implementations of this pattern is Java servlet filters. A servlet filter processes
incoming HTTP requests before passing them to the actual servlet for handling. Servlet filters can be used to implement
various functionality like logging, compression, encryption/decryption, input validation, etc.

Let's have an example of a servlet filter that adds logging before and after each HTTP request is processed:

{title: "LoggingFilter.java"}
```java
import java.io.IOException;

import javax.servlet.*;
import javax.servlet.annotation.WebFilter;


@WebFilter(urlPatterns = {"/*"})
public class LoggingFilter implements Filter {
  // No initialization needed, thus empty method
  public void init(final FilterConfig filterConfig)
    throws ServletException
  {}

  // No cleanup needed, thus empty method
  public void destroy()
  {}

  public void doFilter(
    final ServletRequest request,
    final ServletResponse response,
    final FilterChain filterChain
  ) throws IOException, ServletException
  {
    final var responseWriter = response.getWriter();
    responseWriter.print("Before response\n");

    // Sends request to the next filter
    // or when no more filters to the servlet
    filterChain.doFilter(request, response);

    responseWriter.print("\nAfter response");
  }
}
```

{title: "HelloWorldServlet.java"}
```java
import java.io.IOException;

import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.*;


@WebServlet("/helloworld")
public class HelloWorldServlet extends HttpServlet {
  public void doGet(
    HttpServletRequest request,
    HttpServletResponse response
  ) throws ServletException, IOException {
    response.setContentType("text/plain");
    final var responseWriter = response.getWriter();
    responseWriter.print("Hello, world!");
  }
}
```

When we send an HTTP GET request to the `/helloworld` endpoint, we should get the following response:

```
Before response
Hello, world!
After response
```

Let's implement a JWT authorization filter:

{title: "JwtAuthorizationFilter.java"}
```
import java.io.IOException;

import javax.servlet.*;
import javax.servlet.annotation.WebFilter;
import javax.servlet.http.HttpServletResponse;


@WebFilter(urlPatterns = {"/*"})
public class AuthorizationFilter implements Filter {
  public void init(final FilterConfig filterConfig)
    throws ServletException
  {}

  public void destroy()
  {}

  public void doFilter(
    final ServletRequest request,
    final ServletResponse response,
    final FilterChain filterChain
  ) throws IOException, ServletException {

    // From request's 'Authorization' header,
    // extract the bearer JWT
    // Set 'tokenIsPresent' variable value
    // to true or false
    // Verify the validity of JWT and assign result
    // to 'tokenIsValid' variable

    HttpServletResponse httpResponse =
      (HttpServletResponse) response;

    if (tokenIsValid) {
      filterChain.doFilter(request, response);
    } else if (tokenIsPresent) {
      // NOTE! filterChain is not invoked,
      // this will terminate the request
      httpResponse.setStatus(403);
      final var responseWriter = response.getWriter();
      responseWriter.print("Unauthorized");
      responseWriter.close();
    } else {
    // NOTE! filterChain is not invoked,
    // this will terminate the request
    httpResponse.setStatus(401);
    final var responseWriter = response.getWriter();
    responseWriter.print("Unauthenticated");
    responseWriter.close();
    }
  }
}
```

The [Express](https://expressjs.com/) framework for Node.js utilizes the chain of responsibility pattern for handling requests.
In the Express framework, you can write pluggable behavior using _middlewares_, a concept similar to
servlet filters in Java. Below is the same logging and authorization example as above, but written using JavaScript and
the Express framework:

```js
const express = require('express')

const app = express()

// Authorization middleware
function authorize(request, response, next) {
  // From request's 'Authorization' header,
  // extract the bearer JWT, if present
  // Set 'tokenIsPresent' variable value
  // Verify the validity of JWT and assign result
  // to 'tokenIsValid' variable

  if (tokenIsValid) {
    next();
  } else if (tokenIsPresent) {
    // NOTE! next is not invoked,
    // this will terminate the request
    response.writeHead(403);
    response.end('Unauthorized');
  } else {
    // NOTE! next is not invoked,
    // this will terminate the request
    response.writeHead(401);
    response.end('Unauthenticated');
  }
}

// Logging before middleware
function logBefore(request, response, next) {
  response.write('Before response\n');
  next();
}

// Use authorization and logging middlewares
app.use(authorize, logBefore);

app.get('/helloworld', (request, response, next) => {
  response.write('Hello World!\n');
  next();
});

// Logging after middleware
function logAfter(request, response, next) {
  response.write('After response\n');
  response.end();
  next();
}

app.use(logAfter);

app.listen(4000);
```

We cannot use Express middlewares as described below:

```js
// Logging middleware
async function log(request, response, next) {
  response.write('Before response\n');
  await next();
  response.write('After response\n');

  // You cannot use response.end('After response\n')
  // because that would close the response stream
  // before Hello World! is written and the output
  // would be just:
  // Before response
  // After response
}

// Use authorization and logging middlewares
app.use(authorize, log);

app.get('/helloworld', (request, response) => {
  setTimeout(() => response.end('Hello World!\n'), 1000);
});
```

The reason is that the `next` function does not return a promise we could await.
For this reason, the output from the `/helloworld` endpoint would be in the wrong order:

```
Before response
After response
Hello World!
```

ESLint plugins utilize the chain of responsibility pattern, too. Below is code for defining one rule in an
ESLint plugin:

```js
create(context) {
  return {
    NewExpression(newExpr) {
      if (
        newExpr.callee.name === "SqlFilter" &&
        newExpr.arguments &&
        newExpr.arguments[0] &&
        newExpr.arguments[0].type !== "Literal"
      ) {
        context.report(
          newExpr,
          `SqlFilter constructor's 1st parameter must be a string literal`
        );
      }
    }
  };
}
```

ESLint plugin framework will call the `create` function and supply the `context` parameter. The `create` function should return an
object of functions to analyze different _abstract syntax tree_ (AST) nodes. In the above example, we are only interested
in `NewExpression` nodes and analyze the creation of a new `SqlFilter` object. The first parameter supplied for
the `SqlFilter` constructor should be a literal. If not, we report an issue using the `context.report` method.

When running ESLint with the above plugin and rule enabled, whenever ESLint encounters a _new_ expression in a code file,
the above-supplied `NewExpression` handler function will be called to check if the _new_ expression in the code is valid.

The following code will pass the above ESLint rule:

```js
const sqlFilter = new SqlFilter('field1 > 0');
```

And the following code won't:

```js
const sqlExpression = 'field1 > 0';
const sqlFilter = new SqlFilter(sqlExpression);
```

#### Observer Pattern

> ***The observer pattern lets you define an observe-notify (or publish-subscribe) mechanism to notify one or more objects***
> ***about events that happen to the observed object.***

One typical example of using the observer pattern is a UI view observing a model. The UI view will be notified whenever the model changes and can redraw itself. Let's have an example with Java:

```java
public interface Observer {
  void notifyAboutChange();
}


public interface Observable {
  void observeBy(Observer observer);
}


public class ObservableImpl {
  private final List<Observer> observers = new ArrayList<>();

  public void observeBy(final Observer observer) {
    observers.add(observer);
  }

  protected void notifyObservers() {
    observers.forEach(Observer::notifyAboutChange);
  }
}


public class TodosModel extends ObservableImpl {
  private List<Todo> todos = new ArrayList<>(25);

  // ...

  public void addTodo(final Todo todo) {
    todos.add(todo);
    notifyObservers();
  }

  public void removeTodo(final Todo todo) {
    todos.remove(todo);
    notifyObservers();
  }
}


public class TodosView implements Observer {
  private final TodosModel todosModel;

  public TodosView(final TodosModel todosModel) {
    this.todosModel = todosModel;
    todosModel.observeBy(this);
  }

  public void notifyAboutChange() {
    // Will be called when todos model change
    render();
  }

  public void render() {
    // Renders todos...
  }
}
```

Let's have another example that utilizes the publish-subscribe pattern. Below we define a `MessageBroker` class that contains the following methods: `publish`, `subscribe`, and `unsubscribe`.

```java
public interface MessagePublisher<T> {
  void publish(String topic, T message);
}


@FunctionalInterface
public interface MessageHandler<T> {
  void handle(T message);
}


public interface MessageSubscriber<T> {
  void subscribe(String topic,
                 MessageHandler<T> messageHandler);
}


public class MessageBroker<T> implements
               MessagePublisher<T>, MessageSubscriber<T> {
  private final Map<String, List<MessageHandler<T>>>
    topicToMessageHandlers = new HashMap<>();

  public void publish(
    final String topic,
    final T message
  ) {
    final var messageHandlers =
      topicToMessageHandlers.get(topic);

    if (messageHandlers != null) {
      messageHandlers.forEach(messageHandler ->
        messageHandler.handle(message));
    }
  }

  public void subscribe(
    final String topic,
    final MessageHandler<T> messageHandler
  ) {
    final var messageHandlers =
      topicToMessageHandlers.get(topic);

      if (messageHandlers == null) {
        topicToMessageHandlers.put(topic, List.of(messageHandler));
      } else {
        messageHandlers.add(messageHandler);
      }
  }

   public void unsubscribe(
    final String topic,
    final MessageHandler<T> messageHandlerToRemove
  ) {
    final var messageHandlers = topicToMessageHandlers.get(topic);

    messageHandlers.removeIf(messageHandler ->
      messageHandler == messageHandlerToRemove);
  }
}
```

In the above example, we could have used the built-in Java `Consumer<T>` interface instead of the custom `MessageHandler<T>` interface.

#### Command/Action Pattern

> ***Command or action pattern defines commands or actions as objects that can be given as parameters to other functions for later execution.***

The command/action pattern is one way to follow the open-closed principle, i.e., extending code by creating new command/action classes for additional functionality instead of modifying existing code.

Let's create a simple action and command interface:

```java
public interface Action {
  void perform();
}

public interface Command {
  void execute();
}
```

Let's create a simple concrete action/command that prints a message:

```java
public class PrintAction implements Action {
  private final String message;

  public PrintAction(final String message) {
    this.message = message;
  }

  public void perform() {
    System.out.print(message);
  }
}


public class PrintCommand implements Command {
  private final String message;

  public PrintCommand(final String message) {
    this.message = message;
  }

  public void execute() {
    System.out.print(message);
  }
}
```

As can be seen, the above `PrintAction` and `PrintCommand` instances encapsulate the state that is used when the action/command
is performed (usually at a later stage compared to action/command instance creation).

Now we can use our print action/command:

```java
final var actions = List.of(new PrintAction("Hello"), new PrintAction("World"));

for (final var action : actions) {
  action.perform();
}

final var commands = List.of(new PrintCommand("Hello"), new PrintCommand("World"));

for (final var command : commands) {
  command.execute();
}
```

Using actions or commands makes it possible to follow the open-closed principle because every new action or command
does not modify existing code but adds a new class.

Actions and commands can be made undoable, provided that the action/command is undoable. The above print action/command
is not undoable because you cannot undo print to the console. Let's introduce an undoable action: add an item to a list.
It is an action that can be undone by removing the item from the list.

```java
interface UndoableAction extends Action {
  void undo();
}


class AddToListAction<T> implements UndoableAction {
  private final T item;
  private final List<T> items;

  public AddToListAction(final T item, final List<T> items) {
    this.item = item;
    this.items = items;
  }

  public void perform() {
    items.add(item);
  }

  public void undo() {
    items.remove(item);
  }
}


final var values = new ArrayList<>(List.of(1, 2));
final var add3ToValuesAction = new AddToListAction<>(3, values);
add3ToValuesAction.perform();
System.out.println(values);  //  Prints [1, 2, 3]
add3ToValuesAction.undo();
System.out.println(values);  // Prints [1, 2]
```

Let's have an example using the [Redux](https://redux.js.org/) library's *legacy syntax*, well-known by many React developers.
We are not using the newer syntax offered by the *@reduxjs/toolkit* package.

Below is a Redux reducer:

{title: "todoReducer.js"}
```ts
function todoReducer(state = initialState, action) {
  switch (action.type) {
    case 'ADD_TODO':
      return {
        ...state,
        todos: [...state.todos, {
          id: action.payload.id,
          name: action.payload.name,
          isDone: false
        }]
      };
    case 'MARK_TODO_DONE':
      const newTodos = state.todos.map(todo => {
        if (todo.id !== action.payload.id) {
          return todo;
        }

        return {
          ...todo,
          isDone: true
        };
      });

      return {
        ...state,
        todos: newTodos
      };
    default:
      return state;
  }
}
```

In the above example, we define a `todoReducer` which can handle two different actions: `ADD_TODO` and
`MARK_TODO_DONE`. The implementation of the actions is inlined inside the switch statement, which makes the code somewhat
hard to read. We can refactor the above code so that we introduce two classes for action objects:

{title: "AddTodoAction.ts"}
```ts
export default class AddTodoAction {
  constructor(
    private readonly id: number,
    private readonly name: string
  ) {}

  perform(state: TodoState): TodoState {
    return {
      ...state,
      todos: [...state.todos, {
        id: this.id,
        name: this.name,
        isDone: false
      }]
   };
  }
}
```

{title: "MarkDoneTodoAction.ts"}
```ts
export default class MarkDoneTodoAction {
  constructor(private readonly id: number) {}

  perform(state: TodoState): TodoState {
    const newTodos = state.todos.map(todo => {
      if (todo.id !== this.id) {
        return todo;
      }

      return {
        ...todo,
        isDone: true
      };
    });

    return {
      ...state,
      todos: newTodos
    };
  }
}
```

Now we can redesign the `todoReducer` to look like the following:

{title: "todoReducer.ts"}
```ts
import AddTodoAction from './AddTodoAction';
import MarkDoneTodoAction from './MarkDoneTodoAction';

function todoReducer(
  state: TodoState = initialState,
  { payload: { id, name }, type }: any
) {
  switch (type) {
    case 'ADD_TODO':
      return new AddTodoAction(id, name).perform(state);
    case 'MARK_TODO_DONE':
      return new MarkDoneTodoAction(id).perform(state);
    default:
      return state;
  }
}
```

We have separated actions into classes, and the `todoReducer` function becomes simpler.
However, we should make the code object-oriented by replacing the conditionals (switch-case) with polymorphism.
Let's do the following modifications: introduce a generic base class for actions and a base class for
todo-related actions:

{title: "AbstractAction.ts"}
```ts
export default abstract class AbstractAction<S> {
  abstract perform(state: S): S;
}
```

{title: "AbstractTodoAction.ts"}
```
import AbstractAction from './AbstractAction';

export default abstract class AbstractTodoAction extends
  AbstractAction<TodoState> {}
```

The todo action classes must be modified to extend the `AbstractTodoAction` class:

{title: "AddTodoAction.ts"}
```ts
import AbstractTodoAction from './AbstractTodoAction';

export default class AddTodoAction extends AbstractTodoAction {
  // ...
}
```

{title: "MarkDoneTodoAction.ts"}
```
import AbstractTodoAction from './AbstractTodoAction';

export default class MarkDoneTodoAction extends AbstractTodoAction {
  // ...
}
```

Then we can introduce a generic function to create a reducer. This function will create a reducer function
that perform actions for a given action base class:

{title: "createReducer.ts"}
```ts
import AbstractAction from './AbstractAction';

export default function createReducer<S>(
  initialState: S,
  ActionBaseClass:
    abstract new (...args: any[]) => AbstractAction<S>
) {
  return function(
    state: S = initialState,
    action: { type: AbstractAction<S> }
   ) {
     return action.type instanceof ActionBaseClass
       ? action.type.perform(state)
       : state;
  };
}
```

Let's create the initial state for todos:

{title: "Todo.ts"}
```ts
export type Todo = {
  id: number,
  name: string,
  isDone: boolean
}
```

{title: "initialTodoState.ts"}
```ts
import { Todo } from './Todo';

export type TodoState = {
  todos: Todo[];
}

const initialTodosState = {
  todos: []
} as TodoState

export default initialTodoState;
```

Next, we can create a Redux store using the `createReducer` function, the initial todo state, and the base action class for
todo-related actions:

{title: "store.ts"}
```ts
import { combineReducers, createStore } from "redux";
import createReducer from "./createReducer";
import initialTodoState from "./initialTodoState";
import AbstractTodoAction from "./AbstractTodoAction";

const rootReducer = combineReducers({
  todoState: createReducer(initialTodoState, AbstractTodoAction)
});

export default createStore(rootReducer);
```

Now we have an object-oriented solution for dispatching actions in the following way:

```ts
dispatch({ type: new AddTodoAction(id, name) });
dispatch({ type: new MarkTodoDoneAction(id) });
```

Let's modify the `AbstractAction` class to support undoable actions. By default, an action is not undoable:

{title: "AbstractAction.ts"}
```ts
export default abstract class AbstractAction<S> {
  abstract perform(state: S): S;

  getName(): string {
    return this.constructor.name;
  }

  isUndoable(): boolean {
    return false;
  }
}
```

Let's also create a new class to serve as a base class for undoable actions:

{title: "AbstractUndoableAction.ts"}
```ts
import AbstractAction from "./AbstractAction";

export default abstract class AbstractUndoableAction<S> extends
         AbstractAction<S> {
  override isUndoable(): boolean {
    return true;
  }
}
```

Let's define a class for undo-actions. An undo-action
sets the state as it was before performing the actual action.

{title: "UndoAction.ts"}
```ts
import AbstractAction from "./AbstractAction";

export default class UndoAction<S> extends AbstractAction<S> {
  constructor(
    private readonly actionName: string,
    private readonly ActionBaseClass:
      abstract new (...args: any[]) => AbstractAction<S>,
    private readonly state: S
  ) {
    super();
  }

  override getName(): string {
    return this.actionName;
  }

  override perform(state: S): S {
    return this.state;
  }

  getActionBaseClass():
    abstract new (...args: any[]) => AbstractAction<S>
  {
    return this.ActionBaseClass;
  }
}
```

Let's modify the `createReducer` function to create undo-actions for undoable actions and store them in a stack named `undoActions`.
When a user wants to perform an undo of the last action, the topmost element from the `undoActions` stack can be popped and executed.

{title: "undoActions.ts"}
```ts
import UndoAction from "./UndoAction";

const undoActions = [] as UndoAction<any>[];
export default undoActions;
```

{title: "createReducer.ts"}
```ts
// ...
import undoActions from './undoActions';
import AbstractAction from "./AbstractAction";
import UndoAction from "./UndoAction";

function createReducer<S>(
  initialState: S,
  ActionBaseClass:
    abstract new (...args : any[]) => AbstractAction<S>
) {
  return function(
    state: S = initialState,
    action: { type: AbstractAction<S> }
  ) {
    let newState;

    if (action.type instanceof UndoAction &&
        action.type.getActionBaseClass() === ActionBaseClass) {
      newState = action.type.perform(state);
    } else if (action.type instanceof ActionBaseClass) {
      if (action.type.isUndoable()) {
          undoActions.unshift(new UndoAction(
            action.type.getName(),
            ActionBaseClass,
            state));
      }

      newState = action.type.perform(state);
    } else {
      newState = state;
    }

    return newState;
  };
}
```

Commands/Actions can also be defined without an object-oriented approach using a newly created function with a closure.
In the below example, the function `() => toggleTodoDone(id)` is redefined for each todo. The function redefinition will
always create a new closure that stores the current `id` variable value. We can treat the `() => toggleTodoDone(id)` as an
action or command because it "encapsulates" the `id` value in the closure.

{title: "TodosTableView.tsx"}
```tsx
// type Props = ...

export default function TodosTableView(
  { toggleTodoDone, todos }: Props
) {
  const todoElements = todos.map(({ id, name }) => (
    <tr>
      <td>{id}</td>
      <td>{name}</td>
      <td>
        <input
          type="checkbox"
          onChange={() => toggleTodoDone(id)}
        />
      </td>
    </tr>
  ));

  return <table><tbody>{todoElements}</tbody></table>;
}
```

#### Iterator Pattern

> ***The iterator pattern can be used to add iteration capabilities to a class.***

Let's create a reverse iterator for Java's `List` class. We implement the `Iterator` interface by supplying implementations
for the `hasNext` and the `next` methods:

{title: "ReverseListIterator.java"}
```java
public class ReverseListIterator<T> implements Iterator<T> {
  private final List<T> values;
  private int iteratorPosition;

  public ReverseListIterator(final List<T> values) {
    this.values = Collections.unmodifiableList(values);
    iteratorPosition = values.size() - 1;
  }

  @Override
  public boolean hasNext() {
    return iteratorPosition >= 0;
  }

  @Override
  public T next() {
    // Note! We don't check the iteratorPosition
    // validity here, it is checked in hasNext() method,
    // which must be called before calling next() method
    // and only call next() method if hasNext() method
    // returned true
    final var nextValue = values.get(iteratorPosition);
    iteratorPosition--;
    return nextValue;
  }
}
```

We can put the `ReverseListIterator` class into use in a `ReverseArrayList` class defined below:

{title: "ReverseArrayList.java"}
```java
public class ReverseArrayList<T> extends ArrayList<T>
{
  @Override
  public Iterator<T> iterator() {
    return new ReverseListIterator<>(this);
  }
}
```

Now we can use the new iterator to iterate over a list in reverse order:

```java
final var reversedNumbers = new ReverseArrayList<Integer>();
reversedNumbers.addAll(List.of(1,2,3,4,5));

for (final var number : reversedNumbers) {
  System.out.println(number);
}

// Prints:
// 5
// 4
// 3
// 2
// 1
```

#### Interpreter Pattern

> ***The interpreter pattern evaluates an expression in a specialized computer language using an abstract syntax tree (AST).***

The [abstract syntax tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree) (AST) is represented by expression objects using the *composite pattern* to create a tree
structure of the expressions. The expressions are divided into two main types: a leaf and a non-leaf expression:

```java
public interface Expression {
  void evaluate();
}


public class LeafExpression implements Expression {
  public void evaluate() {
    // ...
  }
}


public class NonLeafExpression implements Expression {
  public void evaluate() {
    // ...
  }
}
```

Let's have an example with a simple specialized language where we can write addition operations, like `1 + 2 + 3`.
We need to define the expression classes. Our implementation will have one non-leaf type expression class called `AddExpression`
that represents an addition operation and another leaf type expression class named `LiteralExpression` that represents a literal
(integer) value.

```java
public interface Expression {
  int evaluate();
}


public class AddExpression implements Expression {
  private final Expression left;
  private final Expression right;

  public AddExpression(final Expression left, final Expression right) {
    this.left = left;
    this.right = right;
  }

  public int evaluate() {
    return left.evaluate() + right.evaluate();
  }
}


public class LiteralExpression implements Expression {
  private final int value;

  public LiteralExpression(final int value) {
    this.value = value;
  }

  public int evaluate() {
    return value;
  }
}
```

What we need is a parser for the AST. A parser goes through a "sentence" in the specialized language and produces
an AST ready for evaluation. The parser implementation is not part of this design pattern, but I will present the parser implementation below using the *test-driven development* (TDD) process.
The TDD process is better described in the coming *testing principles* chapter.

First, we will list the things we need to test.

- Parse a literal, e.g., 5
- Parse another literal, e.g., 7
- Parse an invalid literal, e.g., XX
- Parse empty sentence
- Parse single addition, e.g,. 2+5
- Parse single addition with white space, e.g., ' 2  +   5 '
- Parse invalid operator, e.g., 2 * 5
- Parse addition with invalid left literal, e.g., XX + 5
- Parse addition with invalid right literal, e.g., 2 + YY
- Parse two additions, e.g., 1 + 2 + 3
- Parse two additions with invalid operator, e.g., 1 + 2 ++ 3
- Parse two additions with invalid literal, e.g., 1 + 2 + XX
- Parse three additions, e.g., 1 + 2 + 3 + 4
- Parse nine additions, e.g., '1+  2 +3 +  4 +5+ 6 +7 +8 +9+10 '
- We can stop adding tests because we have generalized the implementation enough to support any number of additions.

Let's start with the first test:

```java
import org.junit.jupiter.api.Test;

import static org.junit.jupiter.api.Assertions.assertEquals;


class ParserTests {
  private final Parser parser = new Parser();

  @Test
  void testParseWithLiteral() {
    // WHEN
    final var ast = parser.parse("5");

    // THEN
    assertEquals(5, ast.evaluate());
  }
}
```

Let's create an implementation that makes the above test pass. We should write the simplest possible code and only enough code to make
the test pass.

```java
public class Parser {
  Expression parse(final String sentence) {
    return new LiteralExpression(5);
  }
}
```

Let's add a test:

```java
class ParserTests {
  private final Parser parser = new Parser();

  @Test
  void testParseWithLiteral() {
    // WHEN
    final var ast = parser.parse("5");
    final var ast2 = parser.parse("7");

    // THEN
    assertEquals(5, ast.evaluate());
    assertEquals(7, ast2.evaluate());
  }
}
```

Let's generalize the implementation:

```java
public class Parser {
  Expression parse(final String sentence) {
    final var literal = Integer.parseInt(sentence);
    return new LiteralExpression(literal);
  }
}
```

Let's add a test:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithInvalidLiteral() {
    // WHEN + THEN
    assertThrows(Parser.ParseError.class, () -> parser.parse("XX"));
  }
}
```

Let's modify the implementation to make the above test pass:

```java
public class Parser {
  public static class ParseError extends Exception {
  }

  Expression tryParse(final String sentence) throws ParseError {
    try {
      final var literal = Integer.parseInt(sentence);
      return new LiteralExpression(literal);
    } catch(final NumberFormatException error) {
      throw new ParseError();
    }
  }
}
```

Let's add a test:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithInvalidLiteral() {
    // WHEN + THEN
    assertThrows(Parser.ParseError.class, () -> parser.parse("XX"));
    assertThrows(Parser.ParseError.class, () -> parser.parse(""));
  }
}
```

The above test passes without code modification. Let's add a test:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithAddition() throws Parser.ParseError {
    // WHEN
    final var ast = parser.parse("2+5");

    // THEN
    assertEquals(7, ast.evaluate());
  }
}
```

Let's modify the implementation to make the above test pass. We will split the input sentence and also extract the
literal parsing into a separate private method:

```java
public class Parser {
  public static class ParseError extends Exception {
  }

  Expression parse(final String sentence) throws ParseError {
    final var tokens = sentence.split("\\+");
    final var leftLiteral = parseLiteral(tokens[0].trim());

    if (tokens.length == 1) {
      return leftLiteral;
    } else {
      final var rightLiteral = parseLiteral(tokens[1].trim());
      return new AddExpression(leftLiteral, rightLiteral);
    }
  }

  Expression parseLiteral(final String string) throws ParseError {
    try {
      final var literal = Integer.parseInt(string);
      return new LiteralExpression(literal);
    } catch (final NumberFormatException error) {
      throw new ParseError();
    }
  }
}
```

Let's add a test:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithAddition() throws Parser.ParseError {
    // WHEN
    final var ast = parser.parse("2+5");
    final var ast2 = parser.parse(" 3  +   5 ");

    // THEN
    assertEquals(7, ast.evaluate());
    assertEquals(8, ast2.evaluate());
  }
}
```

We notice that the above test passes. Let's add another test, then:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithInvalidAddition() {
    // WHEN + THEN
    assertThrows(Parser.ParseError.class, () -> parser.parse("2 * 5"));
    assertThrows(Parser.ParseError.class, () -> parser.parse("XX + 5"));
    assertThrows(Parser.ParseError.class, () -> parser.parse("2 + YY"));
  }
}
```

These tests pass. Let's add a test with more than one addition:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithAddition() throws Parser.ParseError {
    // WHEN
    final var ast = parser.parse("2+5");
    final var ast2 = parser.parse(" 3  +   5 ");
    final var ast3 = parser.parse("1 + 2 + 3");

    // THEN
    assertEquals(7, ast.evaluate());
    assertEquals(8, ast2.evaluate());
    assertEquals(6, ast3.evaluate());
  }
}
```

Let's make the test pass:

```java
class Parser:
  // ...

  Expression parse(final String sentence) throws ParseError {
    final var tokens = sentence.split("\\+");
    final var leftLiteral = parseLiteral(tokens[0].trim());

    if (tokens.length == 1) {
      return leftLiteral;
    } else if (tokens.length == 2){
      final var rightLiteral = parseLiteral(tokens[1].trim());
      return new AddExpression(leftLiteral, rightLiteral);
    } else {
      final var restOfSentence = Arrays
          .stream(tokens, 1, tokens.length)
          .collect(Collectors.joining("+"));

      return new AddExpression(leftLiteral, parse(restOfSentence));
    }
  }

  // ...
```

The final four tests also pass:

```java
class ParserTests {
  // ...

  @Test
  void testParseWithInvalidAddition() {
    // WHEN + THEN
    assertThrows(Parser.ParseError.class, () -> parser.parse("2 * 5"));
    assertThrows(Parser.ParseError.class, () -> parser.parse("XX + 5"));
    assertThrows(Parser.ParseError.class, () -> parser.parse("2 + YY"));

    // Added tests
    assertThrows(
      Parser.ParseError.class, () -> parser.parse("1 + 2 ++ 3")
    );

    assertThrows(
      Parser.ParseError.class, () -> parser.parse("1 + 2 + XX")
    );
  }
}
```

```java
class ParserTests {
  // ...

  @Test
  void testParseWithAddition() throws Parser.ParseError {
    // WHEN
    final var ast = parser.parse("2+5");
    final var ast2 = parser.parse(" 3  +   5 ");
    final var ast3 = parser.parse("1 + 2 + 3");
    final var ast4 = parser.parse("1 + 2 + 3 + 4");
    final var ast5 = parser.parse("1+  2 +3 +  4 +5+ 6 +7 +8 +9+10 ");

    // THEN
    assertEquals(7, ast.evaluate());
    assertEquals(8, ast2.evaluate());
    assertEquals(6, ast3.evaluate());
    assertEquals(10, ast4.evaluate());
    assertEquals(55, ast5.evaluate());
  }
}
```

In the above example, I added new tests to existing methods. You can also put each test into a separate test method.
I didn't do that because most test methods would have been only 1-2 statements long.

{aside}
If you are interested in creating a parser, read about [Recursive descent parser](https://en.wikipedia.org/wiki/Recursive_descent_parser).
{/aside}

For the expression `1 + 2 + 3`, the parser should produce the following kind of AST:

```java
// Parser should return 'ast' of below kind
final var ast = new AddExpression(
  new LiteralExpression(1),
  new AddExpression(
    new LiteralExpression(2),
    new LiteralExpression(3)
  )
);

// Prints 6
System.out.print(ast.evaluate());
```

#### State Pattern

> ***The state pattern lets an object change its behavior depending on its current state.***

Developers don't often treat an object's state as an object but as an enumerated value (enum), for example.
Below is a Java example where we have defined a `UserStory` class representing a user story that can be
rendered on screen. An enum value represents the state of a `UserStory` object.

```java
public enum UserStoryState {
  TODO, IN_DEVELOPMENT, IN_VERIFICATION, READY_FOR_REVIEW, DONE
}


public class UserStory {
  private String name;
  private UserStoryState state = UserStoryState.TODO;
  // Other properties...

  public UserStory(final String name, ...) {
    this.name = name;
    // ...
  }

  public void setState(
    final UserStoryState newState
  ) {
    state = newState;
  }

  public void render() {
    final var icon = switch(state) {
      case TODO -> new TodoIcon();
      case IN_DEVELOPMENT -> new InDevelopmentIcon();
      case IN_VERIFICATION -> new InVerificationIcon();
      case READY_FOR_REVIEW -> new ReadyForReviewIcon();
      case DONE -> new DoneIcon();
      default -> throw new IllegalArgumentException(...);
    };

    // Draw a UI elements on screen representing the user story
    // using the given 'icon'
  }
}
```

The above solution is not an object-oriented one. We should replace the conditionals (switch-case statement) with a polymorphic design.
This can be done by introducing state objects. In the state pattern, the state of an object is represented with an object instead of an enum value.
Below is the above code modified to use the state pattern:


```java
public interface UserStoryState {
  Icon getIcon();
}


public class TodoUserStoryState implements UserStoryState {
  public Icon getIcon() {
    return new TodoIcon();
  }
}


public class InDevelopmentUserStoryState
         implements UserStoryState {
  public Icon getIcon() {
    return new InDevelopmentIcon();
  }
}


public class InVerificationUserStoryState
         implements UserStoryState {
  public Icon getIcon() {
    return new InVerificationIcon();
  }
}


public class ReadyForReviewUserStoryState
         implements UserStoryState {
  public Icon getIcon() {
    return new ReadyForReviewIcon();
  }
}


public class DoneUserStoryState
         implements UserStoryState {
  public Icon getIcon() {
    return new DoneIcon();
  }
}


public class UserStory {
  private String name;
  private UserStoryState state = new TodoUserStoryState();
  // Other properties...

  public UserStory(final String name, ...) {
    this.name = name;
    // ...
  }

  public void setState(
    final UserStoryState newState
  ) {
    state = newState;
  }

  public void render() {
    final Icon icon = state.getIcon();
    // Draw a UI element on screen representing
    // the user story using the given 'icon'
  }
}
```

Let's have another example with an `Order` class. An order can have a state, like paid, packaged, delivered, etc.
Below we implement the order states as classes:


```java
public interface OrderState {
  String getMessage(String orderId);
}


public class PaidOrderState implements OrderState {
  public String getMessage(final String orderId) {
    return "Order " + orderId + " is successfully paid";
  }
}


public class DeliveredOrderState implements OrderState {
  public String getMessage(final String orderId) {
    return "Order " + orderId + " is delivered";
  }
}


// Implement the rest of possible order states here...


public class Order {
  private String id;
  private OrderState state;
  private Customer customer;

  // ...

  public String getCustomerEmailAddress() {
    return customer.getEmailAddress();
  }

  public String getStateMessage() {
    return state.getMessage(id);
  }
}


emailService.sendEmail(order.getCustomerEmailAddress(),
                       order.getStateMessage());
```

#### Mediator Pattern

> ***The mediator pattern lets you reduce dependencies between objects. It restricts direct communication between***
> ***two different layers of objects and forces them to collaborate only via a mediator object or objects.***

The mediator pattern eliminates the coupling of two different layers of objects. So, changes to one layer of objects can be
made without the need to change the objects in the other layer. This pattern is called *indirection* in GRASP principles.

A typical example of the mediator pattern is the Model-View-Controller (MVC) pattern. In the MVC pattern, model and view
objects do not communicate directly but only via mediator objects (controllers). Next, several ways to use the MVC
pattern in frontend clients are presented. Traditionally, the MVC pattern was used in the backend when the backend also generated
the view to be shown in the client device (web browser). With the advent of [single-page web clients](https://en.wikipedia.org/wiki/Single-page_application), a modern backend is a simple API containing only a model and controller (MC).

![Model-View-Controller](resources/chapter2/images/03-06.png)

In the below picture, you can see how dependency inversion is used, and none of the implementation classes depend on concrete implementations.
You can easily change any implementation class to a different one without the need to modify any other implementation class.
Notice how the `ControllerImpl` class uses the *bridge pattern* and implements two bridges, one towards the model and the other towards the view.

We should be able to replace a view implementation or create a new one without changes to other layers (model and controller). For example, we could have a view implementation that is a GUI, and we could have a "view" implementation where input and output are voice. This is called *orthogonality*, a concept from the *Pragmatic Programmer* book. Orthogonality means that a change in one place should not require a change in another place. The orthogonality principle is related to the *single responsibility principle* and the *separation of concerns principle*. When you implement software using the two
latter principles, the software becomes orthogonal.

![Dependencies in MVC pattern](resources/chapter2/images/04-06.png)

The picture below shows that the controller can also be used as a bridge adapter. The controller can be modified to
adapt to changes in the view layer (`View2` instead of `View`) without changing the model layer.
The modified modules are shown with a gray background in the picture. Similarly, the controller can be modified to adapt to
changes in the model layer without changing the view layer (not shown in the picture).

![Adapting to Changes in MVC pattern](resources/chapter2/images/04-07.png)

The following examples use a specialization of the MVC pattern called Model-View-Presenter (MVP). In the MVP pattern, the controller is
called the presenter. I use the more generic term *controller* in all examples, though. A presenter acts as a middle-man
between a view and a model. A presenter-type controller object has a reference to a view object and a model object. A view object
commands the presenter to perform actions on the model. The model object asks the presenter to update the view object.

In the past, making desktop UI applications using Java Swing as the UI layer was popular. Let's have
a simple todo application as an example:

First, we implement the `Todo` class, which is part of the model.

{title: "Todo.java"}
```java
public class Todo {
  private int id;
  private String name;
  private boolean isDone;

  // Constructor...

  public int getId() {
    return id;
  }

  public void setId(final int id) {
    this.id = id;
  }

  public String getName() {
    return name;
  }

  public void setName(final String name) {
    this.name = name;
  }

  public boolean isDone() {
    return isDone;
  }

  public void setIsDone(final boolean isDone) {
    this.isDone = isDone;
  }
}
```

Next, we implement the view layer:

{title: "TodoView.java"}
```java
public interface TodoView {
  void show(List<Todo> todos);
  void show(String message);
}
```

{title: "TodoViewImpl.java"}
```java
public class TodoViewImpl implements TodoView {
  private final TodoController controller;

  public TodoViewImpl(final TodoController controller) {
    this.controller = controller;
    controller.setView(this);
    controller.startFetchTodos();
  }

  public void show(final List<Todo> todos) {
    // Update the view to show the given todos
    // Add listener for each todo checkbox.
    // Listener should call: controller.toggleTodoDone(todo.id)
  }

  public void show(final String errorMessage) {
    // Update the view to show error message
  }
}
```

Then we implement a generic `Controller` class that acts as a base class for concrete controllers:

{title: "Controller.java"}
```java
public class Controller<M, V> {
  private M model;
  private V view;

  public M getModel() {
    return model;
  }

  public void setModel(final M model) {
    this.model = model;
  }

  public V getView() {
    return view;
  }

  public void setView(final V view) {
    this.view = view;
  }
}
```

The below `TodoControllerImpl` class implements two actions, `startFetchTodos` and `toggleTodoDone`, which
delegate to the model layer. It also implements two actions, `updateViewWith(todos)` and `updateViewWith(errorMessage)`, that delegate to the view layer.
The latter two actions are executed in the Swing UI thread using `SwingUtilities.invokeLater`.

{title: "TodoController.java"}
```java
public interface TodoController {
  void startFetchTodos();
  void toggleTodoDone(final int id);
  void updateViewWith(final List<Todo> todos);
  void updateViewWith(final String errorMessage);
}
```

{title: "TodoControllerImpl.java"}
```java
public class TodoControllerImpl
         extends Controller<TodoModel, TodoView>
         implements TodoController {

  public void startFetchTodos() {
    getModel().fetchTodos();
  }

  public void toggleTodoDone(final int id) {
    getModel().toggleTodoDone(id);
  }

  public void updateViewWith(final List<Todo> todos) {
    SwingUtilities.invokeLater(() ->
      getView().show(todos));
  }

  public void updateViewWith(final String errorMessage) {
    SwingUtilities.invokeLater(() ->
      getView().show(errorMessage));
  }
}
```

The below `TodoModelImpl` class implements the fetching of todos (`fetchTodos`) using the supplied `todoService`.
The `todoService` accesses the backend to read todos from a database, for example.
When todos are successfully fetched, the controller is told to update the view. If fetching
of the todos fails, the view is updated to show an error. Toggling a todo done is implemented
using the `todoService` and its `updateTodo` method.

{title: "TodoService.java"}
```java
public interface TodoService {
  public List<Todo> getTodos();
  public void updateTodo(Todo todo);
}
```

{title: TodoModel.java}
```java
public interface TodoModel {
  public void fetchTodos();
  public void toggleTodoDone(int id);
}
```

{title: "TodoModelImpl.java"}
```java
public class TodoModelImpl implements TodoModel {
  private final TodoController controller;
  private final TodoService todoService;
  private List<Todo> todos = new ArrayList<>();

  public TodoModelImpl(
    final TodoController controller,
    final TodoService todoService
  ) {
    this.controller = controller;
    controller.setModel(this);
    this.todoService = todoService;
  }

  public void fetchTodos() {
    CompletableFuture
      .supplyAsync(todoService::getTodos)
      .thenAccept(todos -> {
        this.todos = todos;
        controller.updateViewWith(todos);
      })
      .exceptionally((error) -> {
        controller.updateViewWith(error.getMessage());
        return null;
      });
  }

  public void toggleTodoDone(final int id) {
    todos.stream()
      .filter(todo -> todo.getId() == id)
      .findAny()
      .ifPresent(todo -> {
          todo.setIsDone(!todo.isDone());

          CompletableFuture
            .runAsync(() ->
              todoService.updateTodo(todo))
            .exceptionally((error) -> {
              controller.updateViewWith(error.getMessage());
              return null;
            });
      });
  }
}
```

Let's have the same example using [Web Components](https://developer.mozilla.org/en-US/docs/Web/API/Web_components). The web component view should extend the `HTMLElement` class.
The `connectedCallback` method of the view will be called on the component mount. It starts fetching todos.
The `showTodos` method renders the given todos as HTML elements. It also adds event listeners for
the _Mark done_ buttons. The `showError` method updates the inner HTML of the view to show an error
message.

{title: "Todo.ts"}
```ts
export type Todo = {
  id: number;
  name: string;
  isDone: boolean;
};
```

{title: "TodoView.ts"}
```ts
interface TodoView {
  showTodos(todos: Todo[]): void;
  showError(errorMessage: string): void;
}
```

{title: "TodoViewImpl.ts"}
```ts
import controller from './todoController';
import { Todo } from './Todo';

export default class TodoViewImpl
         extends HTMLElement implements TodoView {
  constructor() {
    super();
    controller.setView(this);
  }

  connectedCallback() {
    controller.startFetchTodos();
    this.innerHTML = '<div>Loading todos...</div>';
  }

  showTodos(todos: Todo[]) {
    const todoElements = todos.map(({ id, name, isDone }) => `
      <li id="todo-${id}">
        ${id}&nbsp;${name}&nbsp;
        ${isDone ? '' : '<button>Mark done</button>'}
      </li>
    `);

    this.innerHTML = `<ul>${todoElements}</ul>`;

    todos.map(({ id }) => this
      .querySelector(`#todo-${id} button`)?
      .addEventListener('click',
                        () => controller.toggleTodoDone(id)));
  }

  showError(errorMessage: string) {
    this.innerHTML = `
      <div>
        Failure: ${errorMessage}
      </div>
    `;
  }
}
```

We can use the same controller and model APIs for this web component example as in the Java Swing example. We just need to convert the Java code to TypeScript code:

{title: "Controller.ts"}
```ts
export default class Controller<M, V> {
  private model: M | undefined;
  private view: V | undefined;

  getModel(): M | undefined {
    return this.model;
  }

  setModel(model: M): void {
    this.model = model;
  }

  getView(): V | undefined {
    return this.view;
  }

  setView(view: V): void {
    this.view = view;
  }
}
```

{title: "TodoController.ts"}
```ts
import { Todo } from "./Todo";

export interface TodoController {
  startFetchTodos(): void;
  toggleTodoDone(id: number): void;
  updateViewWithTodos(todos: Todo[]): void;
  updateViewWithError(message: string): void;
}
```

{title: "todoController.ts"}
```ts
import TodoView from './TodoView';
import Controller from "./Controller";
import { TodoController } from './TodoController';
import { Todo } from "./Todo";
import TodoModel from './TodoModel';

class TodoControllerImpl
         extends Controller<TodoModel, TodoView>
         implements TodoController {

  startFetchTodos(): void {
    this.getModel()?.fetchTodos();
  }

  toggleTodoDone(id: number): void {
    this.getModel()?.toggleTodoDone(id);
  }

  updateViewWithTodos(todos: Todo[]): void {
    this.getView()?.showTodos(todos);
  }

  updateViewWithError(message: string): void {
    this.getView()?.showError(message);
  }
}

const controller = new TodoControllerImpl();
export default controller;
```

{title: "TodoService.ts"}
```ts
export interface TodoService {
  getTodos(): Promise<Todo[]>;
  updateTodo(todo: Todo): Promise<void>;
}
```

{title: "TodoModel.ts"}
```ts
export interface TodoModel {
  fetchTodos(): void;
  toggleTodoDone(id: number): void;
}
```

{title: "TodoModelImpl.ts"}
```ts
import controller, { TodoController } from './todoController';
import { TodoModel } from './TodoModel';
import { Todo } from "./Todo";

export default class TodoModelImpl implements TodoModel {
  private todos: Todo[] = [];

  constructor(
    private readonly controller: TodoController,
    private readonly todoService: TodoService
  ) {
    controller.setModel(this);
  }

  fetchTodos(): void {
    this.todoService.getTodos()
      .then((todos) => {
        this.todos = todos;
        controller.updateViewWithTodos(todos);
      })
      .catch((error) =>
        controller.updateViewWithError(error.message));
  }

  toggleTodoDone(id: number): void {
    const foundTodo = this.todos.find(todo => todo.id === id);

    if (foundTodo) {
      foundTodo.isDone = !foundTodo.isDone;
      this.todoService
          .updateTodo(foundTodo)
          .catch((error: any) =>
            controller.updateViewWithError(error.message));
    }
  }
}
```

We could use the above-defined controller and model as such with a React view component:

{title: "ReactTodoView.tsx"}
```tsx
// ...
import controller from './todoController';

// ...

export default class ReactTodoView
        extends Component<Props, State>
        implements TodoView {

  constructor(props: Props) {
    super(props);
    controller.setView(this);

    this.state = {
      todos: []
    }
  }

  componentDidMount() {
    controller.startFetchTodos();
  }

  showTodos(todos: Todo[]) {
    this.setState({ ...this.state, todos });
  }

  showError(errorMessage: string) {
     this.setState({ ...this.state, errorMessage });
  }

  render() {
    // Render todos from 'this.state.todos' here
    // Or show 'this.state.errorMessage' here
  }
}
```

If you have multiple views using the same controller, you can derive your controller from the below-defined `MultiViewController` class:

{title: "MultiViewController.ts"}
```ts
export default class MultiViewController<M, V> {
  private model: M | undefined;
  private views: V[] = [];

  getModel(): M | undefined {
    return this.model;
  }

  setModel(model: M): void {
    this.model = model;
  }

  getViews(): V[]  {
    return this.views;
  }

  addView(view: V): void {
    this.views.push(view);
  }
}
```

Let's say we want to have two views for todos, one for the actual todos and one viewing the todo count.
We need to modify the controller slightly to support multiple views:

{title: "todoController.ts"}
```ts
import TodoView from './TodoView';
import MultiViewController from './MultiViewController';
import { Todo } from "./Todo";
import { TodoController } from './TodoController';
import TodoModel from './TodoModel';

class TodoControllerImpl
         extends MultiViewController<TodoModel, TodoView>
         implement TodoController {
  startFetchTodos(): void {
    this.getModel()?.fetchTodos();
  }

  toggleTodoDone(id: number): void {
    this.getModel()?.toggleTodoDone(id);
  }

  updateViewsWithTodos(todos: Todo[]): void {
    this.getViews().forEach(view => view.showTodos(todos));
  }

  updateViewWithError(message: string): void {
    this.getViews().forEach(view => view.showError(message));
  }
}

const controller = new TodoController();
export default controller;
```

Many modern UI frameworks and state management libraries implement a specialization of the MVC pattern called,
Model-View-ViewModel (MVVM). In the MVVM pattern, the controller is called the view model. I use the more
generic term _controller_ in the below example, though. The main difference between the view model and the presenter
in the MVP pattern is that in the MVP pattern, the presenter has a reference to the view, but the view model does not.
MVVM is an application of *clean microservice design (or architecture)*. As can be seen in the below picture, the
dependencies goes from views to view models to the model (actions and entities). Similarly, the model does not depend
on particular services, but service interfaces which concrete services implement. For example, if you have a weather forecast web
application, the model of the application should define a weather forecast API service interface for fetching weather information.
The model should not depend on any particular weather forecast API. If you want to integrate your application with a new weather
forecast API, you should be able to do it by defining a new service class that implements the weather forecast API service interface.
Next, in the dependency injection container, you can define that you want to use the new service implementation instead of some old
implementation. Now you have successfully modified your web application using the *open-closed principle*. You can apply the *open-closed principle*,
when you introduce various views that use existing view models. For example, in a todo application, you could introduce
todo list, todo table and todo grid views that all use the same todo view model.

![Clean Architecture with MVVM](resources/chapter2/images/mvvm_clean_arch.png)

The view model provides bindings between the view's events and actions in the model. This can happen so that the view model
adds action dispatcher functions as properties of the view. And in the other direction, the view model
maps the model's state to the properties of the view. When using React and Redux, for example, you can connect the view to the model
using the `mapDispatchToProps` function and connect the model to the view using the `mapStateToProps` function.
These two mapping functions form the view model (or the controller) that binds the view and model together.

Let's first implement the todo example with React and Redux and later show how the React view can be replaced
with an Angular view without any modification to the controller or the model layer. Note that the code for some classes
is not listed below. You can assume those classes are the same as defined in _command/action pattern_ examples.

Let's implement a list view for todos:

{title: "TodosListView.tsx"}
```
import { connect } from 'react-redux';
import { useEffect } from "react";
import { controller, ActionDispatchers, State }
  from './todosController';

type Props = ActionDispatchers & State;

function TodosListView({
  toggleTodoDone,
  startFetchTodos,
  todos
}: Props) {
  useEffect(() => {
    startFetchTodos();
  }, [startFetchTodos]);

  const todoElements = todos.map(({ id, name, isDone }) => (
    <li key={id}>
      {id}&nbsp;
      {name}&nbsp;
      {isDone
        ? undefined
        : <button onClick={() => toggleTodoDone(id)}>
            Mark done
          </button>
      }
    </li>
  ));

  return <ul>{todoElements}</ul>;
}

// Here we connect the view to the model using the controller
export default connect(
  controller.getState,
  () => controller.actionDispatchers
)(TodosListView);
```

Below is the base class for controllers:

{title: "Controller.ts"}
```ts
import AbstractAction from "./AbstractAction";

export type ReduxDispatch =
 (reduxActionObject: { type: AbstractAction<any> }) => void;

export default class Controller {
  protected readonly dispatch:
    (action: AbstractAction<any>) => void;

  constructor(reduxDispatch: ReduxDispatch) {
    this.dispatch = (action: AbstractAction<any>) =>
      reduxDispatch({ type: action });
  }
}
```

Below is the controller for todos:

{title: "todosController.ts"}
```ts
import store from './store';
import { AppState } from "./AppState";
import ToggleDoneTodoAction from "./ToggleDoneTodoAction";
import StartFetchTodosAction from "./StartFetchTodosAction";
import Controller from "./Controller";

class TodosController extends Controller {
  readonly actionDispatchers = {
    toggleTodoDone: (id: number) =>
      this.dispatch(new ToggleDoneTodoAction(id)),

    startFetchTodos: () =>
      this.dispatch(new StartFetchTodosAction())
  }

  getState(appState: AppState) {
    return {
      todos: appState.todosState.todos,
    }
  }
}

export const controller = new TodosController(store.dispatch);
export type State = ReturnType<typeof controller.getState>;
export type ActionDispatchers = typeof controller.actionDispatchers;
```

In the development phase, we can use the following temporary
implementation of the `StartFetchTodosAction` class:

{title: "StartFetchTodosAction.ts"}
```ts
import { TodoState } from "./TodoState";
import AbstractTodoAction from "./AbstractTodoAction";

export default class StartFetchTodosAction extends
                       AbstractTodoAction {
  perform(state: TodoState): TodoState {
    return {
      todos: [
        {
          id: 1,
          name: "Todo 1",
          isDone: false,
        },
        {
          id: 2,
          name: "Todo 2",
          isDone: false,
        },
      ],
    };
  }
}
```

Now we can introduce a new view for todos, a `TodosTableView` which can utilize the same controller as the
`TodosListView`.

{title: "TodosTableView.tsx"}
```tsx
import { connect } from 'react-redux';
import { useEffect } from "react";
import { controller, ActionDispatchers, State }
  from './todosController';

type Props = ActionDispatchers & State;

function TodosListView({
  toggleTodoDone,
  startFetchTodos,
  todos
}: Props) {
  useEffect(() => {
    startFetchTodos();
  }, [startFetchTodos]);

  const todoElements = todos.map(({ id, isDone, name }) => (
    <tr key={id}>
      <td>{id}</td>
      <td>{name}</td>
        <td>
          <input
            type="checkbox"
            checked={isDone}
            onChange={() => toggleTodoDone(id)}
          />
        </td>
    </tr>
  ));

  return <table><tbody>{todoElements}</tbody></table>;
}

export default connect(
  controller.getState,
  () => controller.actionDispatchers
)(TodosListView);
```

We can notice some duplication in the `TodosListView` and `TodosTableView` components.
For example, both are using the same effect. We can create a `TodosView` for which we can give
as parameter the type of a single todo view, either a list item or a table row view:

{title: "TodosView.tsx"}
```tsx
import { useEffect } from "react";
import { connect } from "react-redux";
import ListItemTodoView from './ListItemTodoView';
import TableRowTodoView from './TableRowTodoView';
import { controller, ActionDispatchers, State }
  from './todosController';

type Props = ActionDispatchers & State & {
    TodoView: typeof ListItemTodoView | typeof TableRowTodoView;
};

function TodosView({
  toggleTodoDone,
  startFetchTodos,
  todos,
  TodoView
}: Props) {
  useEffect(() => {
    startFetchTodos()
  }, [startFetchTodos]);

  const todoViews = todos.map((todo) =>
    <TodoView
      key={todo.id}
      todo={todo}
      toggleTodoDone={toggleTodoDone}
    />
  );

  return TodoView === ListItemTodoView
      ? <ul>{todoViews}</ul>
      : <table><tbody>{todoViews}</tbody></table>;
}

export default connect(
  controller.getState,
  () => controller.actionDispatchers
)(TodosView);
```

Below is the view for showing a single todo as a list item:

{title: "TodoViewProps.ts"}
```ts
import { Todo } from "./Todo";

export type TodoViewProps = {
  toggleTodoDone: (id: number) => void,
  todo: Todo
}
```

{title: "ListItemTodoView.tsx"}
```tsx
import { TodoViewProps } from './TodoViewProps';

export default function ListItemTodoView({
  toggleTodoDone,
  todo: { id, name, isDone }
}: TodoViewProps) {
  return (
    <li>
      {id}&nbsp;
      {name}&nbsp;
      { isDone ?
        undefined :
        <button onClick={() => toggleTodoDone(id)}>
          Mark done
        </button> }
    </li>
  );
}
```

Below is the view for showing a single todo as a table row:

{title: "TableRowTodoView.tsx"}
```tsx
import { TodoViewProps } from './TodoViewProps';

export default function TableRowTodoView({
  toggleTodoDone,
  todo: { id, name, isDone }
}: TodoViewProps) {
  return (
    <tr>
      <td>{id}</td>
      <td>{name}</td>
      <td>
        <input
          type="checkbox"
          checked={isDone}
          onChange={() => toggleTodoDone(id)}
        />
      </td>
    </tr>);
}
```

![Figure 3.9 Frontend MVC Architecture with Redux](images/03-07.png)

![Figure 3.10 Frontend MVC Architecture with Redux + Backend](images/03-08.png)

In most cases, you should not store state in a view even if the state is for that particular view only. Instead, when you store it in the model, it brings
the following benefits:

- Possibility to easily persist state either in the browser or in the backend
- Possibility to easily implement undo-actions
- State can be easily shared with another view(s) later if needed
- Migrating views to use a different view technology is more straightforward
- Easier debugging of state-related problems, e.g., using the Redux DevTools browser extension

We can also change the view implementation from React to Angular without modifying the controller
or model layer. This can be done, for example, using the _@angular-redux2/store_ library.
Below is a todos table view implemented as an Angular component:

{title: "todos-table-view.component.ts"}
```ts
import { Component, OnInit } from "@angular/core";
import { NgRedux, Select } from '@angular-redux2/store';
import { Observable } from "rxjs";
import { controller } from './todosController';
import { TodoState } from "./TodoState";
import { AppState } from "./AppState";

const { startFetchTodos,
        toggleTodoDone } = controller.actionDispatchers;

@Component({
  selector: 'todos-table-view',
  template: `
    <table>
      <tr *ngFor="let todo of (todoState | async)?.todos">
        <td>{{ todo.id }}</td>
        <td>{{ todo.name }}</td>
        <td>
          <input
            type="checkbox"
            [checked]="todo.isDone"
            (change)="toggleTodoDone(todo.id)"
          />
        </td>
      </tr>
    </table>
  `
})
export class TodosTableView implements OnInit {
  @Select(controller.getState) todoState: Observable<TodoState>;

  constructor(private ngRedux: NgRedux<AppState>) {}

  ngOnInit(): void {
    startFetchTodos();
  }

  toggleTodoDone(id: number) {
    toggleTodoDone(id);
  }
}
```

{title: "app.component.ts"}
```ts
import { Component } from '@angular/core';

@Component({
  selector: 'app-root',
  template: `
  <div>
    <todos-table-view></todos-table-view>
  </div>`,
  styleUrls: ['./app.component.css']
})
export class AppComponent {
  title = 'angular-test';
}
```

{title: "app.module.ts"}
```ts
import { NgModule } from '@angular/core';
import { BrowserModule } from '@angular/platform-browser';
import { NgReduxModule, NgRedux } from '@angular-redux2/store';

import { AppComponent } from './app.component';
import store from './store';
import { AppState } from "./AppState";
import { TodosTableView } from "./todos-table-view.component";

@NgModule({
  declarations: [
    AppComponent, TodosTableView
  ],
  imports: [
    BrowserModule,
    NgReduxModule
  ],
  providers: [],
  bootstrap: [AppComponent]
})
export class AppModule {
  constructor(ngRedux: NgRedux<AppState>) {
    ngRedux.provideStore(store);
  }
}
```

#### Template Method Pattern

> ***Template method pattern allows you to define a *template method* in a base class, and subclasses define the final***
> ***implementation of that method. The template method contains one or more calls to abstract methods implemented in the subclasses.***

In the below example, the `AbstractDrawing` class contains a template method, `draw`. This method includes a call to
the `getShapeRenderer` method,
an abstract method implemented in the subclasses of the `AbstractDrawing` class. The `draw` method is a template method,
and a subclass defines how to draw a single shape.

```java
public interface Drawing {
  ShapeRenderer getShapeRenderer();
  void draw();
}


public abstract class AbstractDrawing implements Drawing {
  private final List<Shape> shapes;

  public AbstractDrawing(final List<Shape> shapes) {
    this.shapes = shapes;
  }

  public final void draw() {
    for (final Shape shape: shapes) {
      shape.render(getShapeRenderer());
    }
  }

  protected abstract ShapeRenderer getShapeRenderer();
}
```

We can now implement two subclasses of the `AbstractDrawing` class, which define the final behavior of
the templated `draw` method. We mark the template method `draw` as `final` because subclasses should not override it. It is best practice to declare a template method as final. They
should only provide an implementation for the abstract `getShapeRenderer` method.

```java
public class RasterDrawing extends AbstractDrawing {
  public RasterDrawing(final List<Shape> shapes) {
    super(shapes);
  }

  protected ShapeRenderer getShapeRenderer() {
    return new RasterShapeRenderer(new Canvas());
  }
}


public class VectorDrawing extends AbstractDrawing {
  public VectorDrawing(final List<Shape> shapes) {
    super(shapes);
  }

  protected ShapeRenderer getShapeRenderer() {
    return new VectorShapeRenderer(new SvgElement());
  }
}
```

Template method pattern is useful to avoid code duplication in case two subclasses have methods with almost identical behavior. In that case, make that common functionality a template method in a common superclass and refine that template
method behavior in the two subclasses.

#### Memento Pattern

> ***The memento pattern can be used to save the internal state of an object to another object called the *memento* object.***

Let's have a Java example with a `TextEditor` class. First, we define a `TextEditorState` interface and its implementation.
Then we define a `TextEditorStateMemento` class for storing a memento of the text editor's state.


```java
public interface TextEditorState {
  TextEditorState clone();
}


public class TextEditorStateImpl implements TextEditorState {
  // Implement text editor state here
}


public class TextEditorStateMemento {
  private final TextEditorState state;

  public TextEditorStateMemento(final TextEditorState state) {
    this.state = state.clone();
  }

  public TextEditorState getState() {
    return state;
  }
}
```

The `TextEditor` class stores mementos of the text editor's state. It provides methods
to save a state, restore a state, or restore the previous state:

{title: "TextEditor.java"}
```java
class TextEditor {
  private final List<TextEditorStateMemento> stateMementos =
    new ArrayList<>(20);

  private TextEditorState currentState;
  private int currentVersion = 1;

  public void saveState() {
    stateMementos.add(new TextEditorStateMemento(currentState));
    currentVersion += 1;
  }

  public void restoreState(final int version) {
    if (version >= 1 && version <= stateMementos.size()) {
      currentState = stateMementos.get(version - 1).getState();
      currentVersion += 1;
    }
  }

  public void restorePreviousState() {
    if (currentVersion > 1) {
      restoreState(currentVersion - 1);
    }
  }
}
```

In the above example, we can add a memento
for the text editor's state by calling the `saveState` method. We can recall the previous version
of the text editor's state with the `restorePreviousState` method, and we can recall any version of the text editor's state
using the `restoreState` method.

#### Visitor Pattern

> ***Visitor pattern allows adding functionality to a class (like adding new methods) without modifying the class.***
> ***This is useful, for example, with library classes that you cannot modify.***

First, let's have a Java example with classes that we can modify:

```java
public interface Shape {
  void draw();
}


public class CircleShape implements Shape {
  private final int radius;

  // ...

  public void draw() {
    // ...
  }

  public int getRadius() {
    return radius;
  }
}


public class RectangleShape implements Shape {
  private final int width;
  private final int height;

  // ...

  public void draw() {
    // ...
  }

  public int getWidth() {
    return width;
  }

  public int getHeight() {
    return height;
  }
}
```

Let's assume we need to calculate the total area of shapes in a drawing. Currently, we are in a situation where
we can modify the shape classes, so let's add `calculateArea` methods to the classes:


```java
public interface Shape {
  // ...

  double calculateArea();
}


public class CircleShape implements Shape {
  // ...

  public double calculateArea() {
    return Math.PI * radius * radius;
  }
}


class RectangleShape implements Shape {
  // ...

  public double calculateArea() {
    return width * height;
  }
}
```

Adding a new method to an existing class may be against the _open-closed principle_.
In the above case, adding the `calculateArea` methods
is safe because the shape classes are immutable. And even if they were not, adding the `calculateArea` methods would be safe because
they are read-only methods, i.e., they don't modify the object's state, and we don't have to worry about thread safety because
we can agree that our example application is not multithreaded.

Now we have the area calculation methods added, and we can use a common algorithm to calculate the total area of shapes
in a drawing:

```java
final var totalAreaOfShapes = drawing
  .getShapes()
  .stream()
  .reduce(0.0, (subTotalArea, shape) ->
     subTotalArea + shape.calculateArea(), Double::sum);
```

But what if the shape classes, without the area calculation capability, were in a 3rd party library that we cannot modify?
We would have to do something like this:

```java
final var totalAreaOfShapes = drawing
  .getShapes()
  .stream()
  .reduce(0.0, (subTotalArea, shape) -> {
    double shapeArea;

    if (shape instanceof CircleShape) {
      shapeArea = Math.PI *
                  Math.pow(((CircleShape)shape).getRadius(), 2);
    } else if (shape instanceof RectangleShape){
      shapeArea = ((RectangleShape)shape).getWidth() *
                  ((RectangleShape)shape).getHeight();
    }
    else {
      throw new IllegalArgumentException("Invalid shape");
    }

    return subTotalArea + shapeArea;
  }, Double::sum);
```

The above solution is complicated and needs updating every time a new type of shape is introduced.
The above example does not follow object-oriented design principles: it contains an if/else-if structure with `instanceof` checks.

We can use the visitor pattern to replace the above conditionals with polymorphism. First, we introduce a visitor interface that can be used to provide
additional behavior to the shape classes. Then we introduce an `execute` method in the `Shape` interface. And in the shape classes, we implement the `execute` methods so that additional
behavior provided by a concrete visitor can be executed:

```java
// This is our visitor interface that
// provides additional behaviour to the shape classes
public interface ShapeBehavior {
  Object executeForCircle(final CircleShape circle);
  Object executeForRectangle(final RectangleShape rectangle);

  // Add methods for possible other shape classes here...
}


public interface Shape {
  // ...

  Object execute(final ShapeBehavior behavior);
}


public class CircleShape implements Shape {
  public Object execute(final ShapeBehavior behavior) {
    return behavior.executeForCircle(this);
  }
}


public class RectangleShape implements Shape {
  public Object execute(final ShapeBehavior behavior) {
    return behavior.executeForRectangle(this);
  }
}
```

Suppose that the shape classes were mutable and made thread-safe. We would have to define the `execute` methods with appropriate
synchronization to make them also thread-safe:

```java
public class CircleShape implements Shape {
  public synchronized Object execute(
    final ShapeBehavior behavior
  ) {
    return behavior.executeForCircle(this);
  }
}


public class RectangleShape implements Shape {
  public synchronized Object execute(
    final ShapeBehavior behavior
  ) {
    return behavior.executeForRectangle(this);
  }
}
```

Let's implement a concrete visitor for calculating areas of different shapes:

```java
public class AreaCalculationShapeBehavior implements
               ShapeBehavior {
  public Object executeForCircle(final CircleShape circle) {
    return (Double)(Math.PI * Math.pow(circle.getRadius(), 2));
  }

  public Object executeForRectangle(
    final RectangleShape rectangle
  ) {
    return (Double)(double)(rectangle.getWidth() * rectangle.getHeight());
  }
}
```

Now we can implement the calculation of shapes' total area using a common algorithm, and we get rid of the
conditionals. We execute the `areaCalculation` behavior for each shape and convert the result of behavior execution
to `Double`. Methods in a visitor usually return some common type like `Object`. This enables various
operations to be performed. After executing a visitor, the return value should be cast to the right type.

```java
final var areaCalculation = new AreaCalculationShapeBehavior();

final var totalAreaOfShapes = drawing
  .getShapes()
  .stream()
  .reduce(0.0, (subTotalArea, shape) ->
    subTotalArea + (Double)shape.execute(areaCalculation),
      Double::sum);
```

You can add more behavior to the shape classes by defining a new visitor. Let's define a
`PerimeterCalculationShapeBehaviour` class:

```java
public class PerimeterCalculationShapeBehavior
               implements ShapeBehavior {
  public Object executeForCircle(final CircleShape circle) {
    return (Double)(2 * Math.PI * circle.getRadius());
  }

  public Object executeForRectangle(
    final RectangleShape rectangle
  ) {
    return (Double)(double)(2 * rectangle.getWidth() +
                            2 * rectangle.getHeight());
  }
}
```

Notice that we did not need to use the _visitor_ term in our code examples. Adding the design pattern name to the names of
software entities (class/function names, etc.) often does not bring any real benefit but makes the names longer. However, there are some design patterns,
like the _factory pattern_ and _builder pattern_ where you always use the design pattern name in a class name.

If you develop a third-party library and want the behavior of its classes to be extended by its users, you should make your library classes accept visitors who can perform additional behavior. Using the visitor pattern allows to add behavior to existing classes without modifying them, i.e., in accordance with the open-closed principle. However, there is one drawback to using the visitor pattern. You must create getters and setters for class attributes to allow visitors to add behavior. Adding getters and setters breaks the class encapsulation, as was discussed earlier in this chapter.

#### Null Object Pattern

> ***A null object is an object that does nothing.***

Use the null object pattern to implement a class for null objects that don't do anything. A null object can be used in place of a real object that
does something.

Let's have an example with a `Shape` interface:

{title: "Shape.java"}
```java
public interface Shape {
  void draw();
}
```

We can easily define a class for null shape objects:

{title: "NullShape.java"}
```java
public class NullShape implements Shape {
  void draw() {
    // Intentionally no operation
  }
}
```

We can use an instance of the `NullShape` class everywhere where a concrete implementation of the `Shape` interface is wanted.

## Don't Ask, Tell Principle

> ***Don't ask, tell principle states that you should *tell* another object what to do, and not ask about the other object's state and then do the work by yourself in your object.***

If your object asks many things from another object using, e.g., multiple getters, you might be guilty of the _feature envy_ design smell.
Your object is envious of a feature that the other object should have.

Let's have an example and define a cube shape class:

```java
public interface ThreeDShape {
  // ...
}

public class Cube3DShape implements ThreeDShape {
  private final int width;
  private final int height;
  private final int depth;

  // Constructor...

  public int getWidth() {
    return width;
  }

  public int getHeight() {
    return height;
  }

  public int getDepth() {
    return depth;
  }
}
```

Next, we define another class, `CubeUtils`, that contains a method for calculating the total volume of cubes:

```java
public class CubeUtils {
  public int calculateTotalVolume(
    final List<Cube3DShape> cubes
  ) {
    int totalVolume = 0;

    for (final Cube3DShape cube : cubes) {
      final var width = cube.getWidth();
      final var height = cube.getHeight();
      final var depth = cube.getDepth();
      totalVolume += width * height * depth;
    }

    return totalVolume;
  }
}
```

In the `calculateTotalVolume` method, we ask three times about a cube object's state. This is
against the _tell, don't ask principle_. Our method is envious of the volume calculation feature
and wants to do it by itself rather than telling a `Cube3DShape` object to calculate its volume.

Let's correct the above code so that it follows the _tell, don't ask principle_:

```java
public interface ThreeDShape {
  int calculateVolume();
}

public class Cube3DShape implements ThreeDShape {
  private final int width;
  private final int height;
  private final int depth;

  // Constructor

  public int calculateVolume() {
    return height * width * depth;
  }
}

public class ThreeDShapeUtils {
  public int calculateTotalVolume(
    final List<ThreeDShape> threeDShapes
  ) {
    int totalVolume = 0;

    for (final var threeDShape : threeDShapes) {
      totalVolume += threeDShape.calculateVolume();
    }

    return totalVolume;
  }
}
```

Now our `calculateTotalVolume` method is not asking anything about a cube object. It just tells a cube object
to calculate its volume. We also removed the _asking_ methods (getters) from the `Cube3DShape` class because
they are no longer needed.

Below is a C++ example of asking instead of telling:

```cpp
using namespace std::chrono_literals;
using std::chrono::system_clock;

void AnomalyDetectionEngine::runEngine()
{
  while (m_isRunning)
  {
    const auto now = system_clock::now();

    if (m_anomalyDetector->shouldDetectAnomalies(now))
    {
      const auto anomalies = m_anomalyDetector->detectAnomalies();
      // Do something with the detected anomalies
    }

    std::this_thread::sleep_for(1s);
  }
}
```

In the above example, we ask the anomaly detector if we should detect anomalies now. Then, depending
on the result, we call another method on the anomaly detector to detect anomalies. This could be simplified by making the `detectAnomalies` method to check if anomalies should be detected using the `shouldDetectAnomalies` method. Then the `shouldDetectAnomalies` method can be made private, and we can simplify the above code as follows:


```cpp
using namespace std::chrono_literals;

void AnomalyDetectionEngine::runEngine()
{
  while (m_isRunning)
  {
    const auto anomalies = m_anomalyDetector->detectAnomalies();
    // Do something with the detected anomalies
    std::this_thread::sleep_for(1s);
  }
}
```

Following the *tell, don't ask principle* is a great way to reduce coupling in your software component. In the above example,
we reduced the number of methods the `calculate_total_volume` method is dependent on from three to one. Following the principle
also contributed to higher cohesion in the software component because operations related to a cube are now inside the
`Cube` class and not scattered around in the code base. The *tell, don't ask principle* is the same as the *information
expert* from the GRASP principles. The information expert principle says to put behavior in a class with the most information required
to implement the behavior. In the above example, the `Cube` class clearly has the most information needed (width, height, and depth) to calculate a cube's area.

## Law of Demeter

> ***A method on an object received from another object's method call should not be called.***

The below statements are considered to break the law:

```java
user.getAccount().getBalance();
user.getAccount().withdraw(...);
```

The above statements can be corrected either by moving functionality to a different class or by making
the second object to act as a facade between the first and the third object.

Below is an example of the latter solution, where we introduce two new methods in the `User` class and remove the
`getAccount` method:

```java
user.getAccountBalance();
user.withdrawFromAccount(...);
```

In the above example, the `User` class is a facade in front of the `Account` class that we should not
access directly from our object.

However, you should always check if the first solution alternative could be used instead. It makes the
code more object-oriented and does not require creating additional methods.

Below is a Java example that uses `User` and `SalesItem` entities and is not obeying the law of Demeter:

```java
void purchase(final User user, final SalesItem salesItem) {
  final var account = user.getAccount();

  // Breaks the law
  final var accountBalance = account.getBalance();

  final var salesItemPrice = salesItem.getPrice();

  if (accountBalance >= salesItemPrice) {
    account.withdraw(salesItemPrice); // Breaks the law
  }

  // ...
}
```

We can resolve the problem in the above example by moving the `purchase` method
to the correct class, in this case, the `User` class:

```java
class User {
  private Account account;

  // ...

  void purchase(final SalesItem salesItem) {
    final var accountBalance = account.getBalance();
    final var salesItemPrice = salesItem.getPrice();

    if (accountBalance >= salesItemPrice) {
      account.withdraw(salesItemPrice);
    }

    // ...
  }
}
```

Following the *law of Demeter* is a great way to reduce coupling in your software component. When you follow the
*law of Demeter* you are not depending on the objects behind another object, but that other object provides a facade
to the objects behind it.

## Avoid Primitive Obsession Principle

> ***Avoid primitive obsession by defining semantic types for function parameters and function return value.***

Some of us have experienced situations where we have supplied arguments to a function in the wrong order.
This is easy if the function, for example, takes two integer parameters, but you accidentally give those two integer parameters
in the wrong order. You don't get a compilation error.

Another problem with primitive types as function arguments is that the argument values are not necessarily validated.
You have to implement the validation logic in your function.

Suppose you accept an integer parameter for a port number in a function.
In that case, you might get any integer value as the parameter value,
even though the valid port numbers are from 1 to 65535. Suppose you also had other functions in the same codebase
accepting a port number as a parameter. In that case, you could end up doing the same validation logic in multiple places and have
thus duplicate code in your codebase.

Let's have a simple Java example of using this principle:

{title: "RectangleShape.java"}
```java
public class RectangleShape implements Shape {
  private int width;
  private int height;

  public RectangleShape(final int width, final int height) {
    this.width = width;
    this.height = height;
  }
}
```

In the above example, the constructor has two parameters with the same primitive type (int). It is possible
to give `width` and `height` in the wrong order. But if we refactor the code to use objects instead of primitive
values, we can make the likelihood of giving the arguments in the wrong order much smaller:

```java
public class Value<T> {
  private final T value;

  public Value(final T value) {
    this.value = checkNotNull(value);
  }

  T get() {
    return value;
  }
}


public class Width extends Value<Integer> {
  public Width(final int width) {
    super(width);
  }
}


public class Height extends Value<Integer> {
  public Height(final int height) {
    super(height);
  }
}


public class RectangleShape implements Shape {
  private final int width;
  private final int height;

  public RectangleShape(final Width width, final Height height) {
    this.width = width.get();
    this.height = height.get();
  }
}


final var width = new Width(20);
final var height = new Height(50);

// OK
final Shape rectangle = new RectangleShape(width, height);

// Does not compile, parameters are in wrong order
final Shape rectangle2 = new RectangleShape(height, width);

// Does not compile, first parameter is not a width
final Shape rectangle3 = new RectangleShape(height, height);

// Does not compile, second parameter is not a height
final Shape rectangle4 = new RectangleShape(width, width);

// Does not compile, Width and Height objects must be used
// instead of primitive types
final Shape rectangle5 = new RectangleShape(20, 50);
```

In the above example, `Width` and `Height` are simple data classes. They don't contain any behavior. You
can use concrete data classes as function parameter types. There is no need to create an interface for a data class. So, the _program against interfaces_ principle does not apply here.

Let's have another simple example where we have the following function signature:

```java
public void doSomething(final String namespacedName, ...) {
  // ...
}
```

The above function signature allows function callers to supply a non-namespaced name accidentally.
By using a custom type for the namespaced name, we can formulate the above function signature to the following:

```java
public class NamespacedName {
  private final String namespacedName;

  public NamespacedName(
    final String namespace,
    final String name
  ) {
    this.namespacedName = namespace.isEmpty()
                            ? name
                            : (namespace + '.' + name);
  }

  public String get() {
    return this.namespacedName;
  }
}

public void doSomething(final NamespacedName namespacedName, ...) {
  // ...
}
```

Let's have a more comprehensive example with an `HttpUrl` class. The class constructor has several parameters
that should be validated upon creating an HTTP URL:

{title: "HttpUrl.java"}
```java
public class HttpUrl {
  private final String httpUrl;

  public HttpUrl(
    final String scheme,
    final String host,
    final int port,
    final String path,
    final String query
  ) {
    httpUrl = scheme +
              "://" +
              host +
              ":" +
              port +
              path +
              "?" +
              query;
  }
}
```

Let's introduce an abstract class for validated values:

{title: "AbstractValidatedValue.java"}
```java
public abstract class AbstractValidatedValue<T> {
  protected final T value;

  public AbstractValidatedValue(final T value) {
    this.value = checkNotNull(value);
  }

  abstract boolean valueIsValid();

  Optional<T> get() {
    return valueIsValid()
             ? Optional.of(value)
             : Optional.empty();
  }

  T tryGet() {
    if (valueIsValid()) {
      return value;
    } else {
      throw new ValidatedValueGetError(...);
    }
  }
}
```

Let's create a class for validated HTTP scheme objects:

{title: "HttpScheme.java"}
```java
public class HttpScheme extends AbstractValidatedValue<String> {
  public HttpScheme(final String value) {
    super(value);
  }

  public boolean valueIsValid() {
    // Because the AbstractValidatedValue<String> is immutable,
    // if you had complex validation logic, you could cache
    // the validation result and store it to a class attribute.

    return "https".equalsIgnoreCase(value) ||
           "http".equalsIgnoreCase(value);
  }
}
```

Let's create a `Port` class (and similar classes for the host, path, and query should be created):

```java
public class Port extends AbstractValidatedValue<Integer> {
  public Port(final Integer value) {
    super(value);
  }

  public boolean valueIsValid() {
    return value >= 1 && value <= 65535;
  }
}

// public class Host ...
// public class Path ...
// public class Query ...
```

Let's create a utility class, `OptionalUtils`, with a method for mapping a result for five optional values:

```java
@FunctionalInterface
public interface Mapper<T, U, V, X, Y, R> {
  R map(T value,
        U value2,
        V value3,
        X value4,
        Y value5);
}


public final class OptionalUtils {
  public static <T, U, V, X, Y, R> Optional<R>
    mapAll(
      final Optional<T> opt1,
      final Optional<U> opt2,
      final Optional<V> opt3,
      final Optional<X> opt4,
      final Optional<Y> opt5,
      final Mapper<T, U, V, X, Y, R> mapper
  ) {
    if (opt1.isPresent() &&
        opt2.isPresent() &&
        opt3.isPresent() &&
        opt4.isPresent() &&
        opt5.isPresent()
    ) {
      return Optional.of(mapper.map(opt1.get(),
                                    opt2.get(),
                                    opt3.get(),
                                    opt4.get(),
                                    opt5.get()));
    } else {
      return Optional.empty();
    }
  }
}
```

Next, we can reimplement the `HttpUrl` class to contain two alternative factory methods for creating an HTTP URL:

{title: "HttpUrl.java"}
```java
public class HttpUrl {
  private final String httpUrl;

  // Constructor is private because factory methods
  // should be used to create instances of this class
  private HttpUrl(final String httpUrl) {
    this.httpUrl = httpUrl;
  }

  // Factory method that returns an optional HttpUrl
  public static Optional<HttpUrl> create(
    final HttpScheme scheme,
    final Host host,
    final Port port,
    final Path path,
    final Query query
  ) {
    return OptionalUtils.mapAll(scheme.get(),
                                host.get(),
                                port.get(),
                                path.get(),
                                query.get(),
            (schemeValue,
             hostValue,
             portValue,
             pathValue,
             queryValue) ->
                    new HttpUrl(schemeValue +
                                "://" +
                                hostValue +
                                ":" +
                                portValue +
                                pathValue +
                                "?" +
                                queryValue));
  }

  // Factory method that returns a valid HttpUrl or
  // throws an error
  public static HttpUrl tryCreate(
    final HttpScheme scheme,
    final Host host,
    final Port port,
    final Path path,
    final Query query
  ) {
    try {
      return new HttpUrl(scheme.tryGet() +
                          "://" +
                          host.tryGet() +
                          ":" +
                          port.tryGet() +
                          path.tryGet() +
                          "?" +
                          query.tryGet());
    } catch (final ValidatedValueGetError error) {
      throw new HttpUrlCreateError(error);
    }
  }
}
```

Notice how we did not hardcode the URL validation inside the `HttpUrl` class, but we created
small validated value classes: `HttpScheme`, `Host`, `Port`, `Path`, and `Query`. These classes can be further utilized
in other parts of the codebase if needed and can even be put into a common validation library for broader usage.

For TypeScript, I have created a library called _validated-types_ for easily creating and using semantically validated types.
The library is available at [https://github.com/pksilen/validated-types](https://github.com/pksilen/validated-types).
The library's idea is to validate data when the data is received from the input. You can then pass already
validated, strongly typed data to the rest of the functions in your software component.

An application typically receives unvalidated input data from external sources in the following ways:

- Reading command line arguments
- Reading environment variables
- Reading standard input
- Reading files from the file system
- Reading data from a socket (network input)
- Receiving input from a user interface (UI)

Make sure that you validate any data received from the sources mentioned above. Use a ready-made validation library or
create your own validation logic if needed. Validate the input immediately after receiving it from an untrustworthy source and only pass valid values to other functions in the codebase. In this way, other functions in the codebase can trust the input they receive, and they don't have to validate it again. If you pass unvalidated data freely around in your application, you may need to implement validation logic in every function, which is unreasonable.

Below is an example of using the *validated-types* library to create a validated integer type that allows values between 1 and 10.
The `VInt` generic type takes a type argument of string type, which defines the allowed value range in the following format:
`<min-value>,<max-value>`

```ts
import { VInt } from 'validated-types';

function useInt(int: VInt<'1,10'>) {
  // The wrapped integer value can be accessed
  // through the 'value' property
  console.log(int.value);
}

const int: VInt<'1,10'> = VInt.tryCreate('1,10', 5);
useInt(int); // prints to console: 5

// Returns null, because 12 is not between 1 and 10
const maybeInt: VInt<'1,10'> | null = VInt.create('1,10', 12);

// Prints to console: 10
useInt(maybeInt ?? VInt.tryCreate('1,10', 10));

// Throws, because 500 is not between 1 and 10
const int2: VInt<'1,10'> = VInt.tryCreate('1,10', 500);
```

The below example defines a `Url` type which contains six validations that validate a string matching the following criteria:

- is at least one character long
- is at most 1024 characters long
- is a lowercase string
- is a valid URL
- URL starts with 'https'
- URL ends with '.html'

```ts
import { SpecOf, VString } from 'validated-types';

// First element in the VString type parameter array validates
// a lowercase string between 1-1024 characters long

// Second element in the VString type parameter array validates
// an URL

// Third element in the VString type parameter array validates
// a string that starts with "https"

// Fourth element in the VString type parameter array validates
// a string that ends with ".html"

type Url = VString<['1,1024,lowercase',
                    'url',
                    'startsWith,https',
                    'endsWith,.html']>;

const urlVSpec: VSpecOf<Url> = ['1,1024,lowercase',
                                'url',
                                'startsWith,https',
                                'endsWith,.html'];

function useUrl(url: Url) {
  console.log(url.value);
}

const url: Url = VString.tryCreate(
  urlVSpec,
  'https://server.domain.com:8080/index.html'
);

// Prints to console: https://server.domain.com:8080/index.html
useUrl(url);

// 'maybeUrl' will be null
const maybeUrl: Url | null = VString.create(urlVSpec,
                                            'invalid URL');

const defaultUrl: Url = VString.tryCreate(
  urlVSpec,
  'https://default.domain.com:8080/index.html'
);

// Prints to console: https://default.domain.com:8080/index.html
useUrl(maybeUrl ?? defaultUrl);
```

If you don't need validation but would like to create a semantic type, you can
use the `SemType` class from the _validated-types_ library:

```ts
import { SemType } from 'validated-types';

// Defines a semantic boolean type with name 'isRecursiveCall'
type IsRecursiveCall = SemType<boolean, 'isRecursiveCall'>

// Defines a semantic boolean type with name 'isInternalCall'
type IsInternalCall = SemType<boolean, 'isInternalCall'>;

function myFunc(isRecursiveCall: IsRecursiveCall,
                isInternalCall: IsInternalCall) {
  // The value of a semantic type variable
  // can be obtained from the 'value' property
  console.log(isRecursiveCall.value);
  console.log(isInternalCall.value);
}

const isRecursiveCall = false;
const isInternalCall = true;

// This will succeed
myFunc(new SemType({ isRecursiveCall }),
       new SemType({ isInternalCall }));

// All the below myFunc calls will fail during
// the compilation
myFunc(new SemType({ isInternalCall }),
       new SemType({ isRecursiveCall }));

myFunc(true, true);

myFunc(new SemType('isSomethingElse', true),
       new SemType('isInternalCall', true));

myFunc(new SemType('isRecursiveCall', false),
       new SemType('isSomethingElse', true));

myFunc(new SemType('isSomethingElse', true),
       new SemType('isSomethingElse', true));
```

## Dependency Injection (DI) Principle

> ***Dependency injection (DI) allows changing the behavior of an application based on static or dynamic configuration.***

When using dependency injection, the dependencies are injected only after the application startup. The application can
first read its configuration and then decide what objects are created for the application. In many languages,
dependency injection is crucial for unit tests, too. When executing a unit test using DI, you can inject mock
dependencies into the tested code instead of using the standard dependencies of the application.

Below is a C++ example of using the singleton pattern without dependency injection:

{title: "main.cpp"}
```cpp
int main()
{
  Logger::initialize();

  Logger::writeLogEntry(LogLevel::Info,
                        std::source_location::current(),
                        "Starting application");

  // ...
}
```

A developer must remember to call the `initialize` method before calling any other method on the `Logger` class. This kind of coupling
between methods should be avoided. Also, it is hard to unit test the static methods of the `Logger` class.

We should refactor the above code to use dependency injection:

{title: "main.cpp"}
```cpp
int main()
{
  DependencyInjectorFactory::createDependencyInjector(...)
    ->injectDependencies();

  Logger::getInstance()->writeLogEntry(
    LogLevel::Info,
    std::source_location::current(),
    "Starting application"
  );

  // ...
}
```

{title: "Singleton.h"}
```
template<typename T>
class Singleton
{
public:
  Singleton() = default;

  virtual ~Singleton()
  {
    m_instance.reset();
  };

  static inline std::shared_ptr<T>& getInstance()
  {
    return m_instance;
  }

  static void setInstance(const std::shared_ptr<T>& instance)
  {
    m_instance = instance;
  }

private:
  static inline std::shared_ptr<T> m_instance;
};
```

{title: "Logger.h"}
```cpp
class Logger : public Singleton<Logger>
{
public:
  virtual void writeLogEntry(...) = 0;
};
```

{title: "StdOutLogger.h"}
```cpp
class StdOutLogger : public Logger
{
public:
  void writeLogEntry(...) override
  {
    // Write the log entry
    // to the standard output
  }
};
```

{title: "DependencyInjectorFactory.h"}
```cpp
class DependencyInjectorFactory {
public:
  static std::shared_ptr<DependencyInjector>
  createDependencyInjector(...)
  {
    // You can use a switch-case here to create
    // different kinds of dependency injectors
    // that inject different kinds of dependencies
    return std::make_shared<DefaultDependencyInjector>();
  }
}
```

{title: "DependencyInjector.h"}
```cpp
class DependencyInjector {
public:
  virtual ~DependencyInjector = default;
  virtual void injectDependencies() = 0;
}
```

{title: "DefaultDependencyInjector.h"}
```cpp
class DefaultDependencyInjector : public DependencyInjector {
public:
  void injectDependencies() override;
}
```

{title: "DefaultDependencyInjector.cpp"}
```cpp
void DefaultDependencyInjector::injectDependencies()
{
  // Inject other dependencies...

  Logger::setInstance(
    std::make_shared<StdOutLogger>()
  );
}
```

Let's introduce a new kind of logger:

{title: "FileLogger.h"}
```cpp
class FileLogger : public Logger
{
public:
  void writeLogEntry(...) override
  {
    // Write the log entry
    // to a file
  }
};
```

We could modify the default dependency injector to choose a logger implementation dynamically
based on an environment variable value:

{title: "DefaultDependencyInjector.cpp"}
```cpp
void DefaultDependencyInjector::injectDependencies()
{
  // Inject other dependencies...


  const auto maybeLogDestination = std::getenv("LOG_DESTINATION");
  const auto logDestination =
    maybeLogDestination == null ? std::string{} : std::string{maybeLogDestination};

  if (logDestination == "file")
  {
    Logger::setInstance(std::make_shared<FileLogger>());
  }
  else
  {
    Logger::setInstance(std::make_shared<StdOutLogger>());
  }
}
```

If you have a very simple microservice with few dependencies, you might think dependency injection is an overkill.
One thing that is sure in software development is change. Change is inevitable, and you cannot predict the future.
For example, your microservice may start growing larger. Introducing DI in a late phase of a project might require
substantial refactoring. Therefore, consider using DI in all non-trivial applications from
the beginning.

Below is a TypeScript example of a *data-visualization-web-client* where the [noicejs](https://github.com/ssube/noicejs) NPM library is used for
dependency injection. This library resembles the famous [Google Guice](https://github.com/google/guice) library. Below is a `FakeServicesModule` class
that configures dependencies for different backend services that the web client uses.
As you can notice, all the services are configured to use fake implementations because this DI module is used when
the backend services are not yet available. A `RealServicesModule` class
can be implemented and used when the backend services become available. In the `RealServicesModule` class, the
services are bound to their actual implementation classes instead of fake implementations.

```ts
import { Module } from 'noicejs';
import FakeDataSourceService from ...;
import FakeMeasureService from ...;
import FakeDimensionService from ...;
import FakeChartDataService from ...;

export default class FakeServicesModule extends Module {
  override async configure(): Promise<void> {
    this.bind('dataSourceService')
      .toInstance(new FakeDataSourceService());

    this.bind('measureService')
      .toInstance(new FakeMeasureService());

    this.bind('dimensionService')
      .toInstance(new FakeDimensionService());

    this.bind('chartDataService')
      .toInstance(new FakeChartDataService());
    );
  }
}
```

With the *noicejs* library, you can configure several DI modules and create a DI container from the wanted modules.
The module approach lets you divide dependencies into multiple modules, so you don't have a single big
module and lets you instantiate a different module or modules based on the application configuration.

In the below example, the DI container is created from a single module, an instance of the `FakeServicesModule` class:

{title: "diContainer.ts"}
```ts
import { Container } from 'noicejs';
import FakeServicesModule from './FakeServicesModule';

const diContainer = Container.from(new FakeServicesModule());

export default diContainer;
```

In the development phase, we could create two separate modules, one for fake services and another one for real services,
and control the application behavior based on the web page's URL query parameter:

{title: "diContainer.ts"}
```ts
import { Container } from 'noicejs';
import FakeServicesModule from './FakeServicesModule';
import RealServicesModule from './RealServicesModule';

const diContainer = (() => {
  if (location.href.includes('useFakeServices=true')) {
    // Use fake services if web page URL
    // contains 'useFakeServices=true'
    return Container.from(new FakeServiceModule());
  } else {
    // Otherwise use real services
    return Container.from(new RealServicesModule());
  }
})();

export default diContainer;
```

Then, you must configure the `diContainer` before the dependency injection can be used.
In the below example, the `diContainer` is configured before a React application is rendered:

{title: "app.ts"}
```ts
import React from 'react';
import ReactDOM from 'react-dom';
import diContainer from './diContainer';
import AppView from './app/view/AppView';

diContainer.configure().then(() => {
  ReactDOM.render(<AppView />, document.getElementById('root'));
});
```

Then, in Redux actions, where you need a service, you can inject the required service with
the `@Inject` decorator. You specify the name of the service you want to inject. The service
will be injected as the class constructor argument's property (with the same name).

{title: "StartFetchChartDataAction.ts"}
```ts
// Imports ...

type ConstructorArgs = {
  chartDataService: ChartDataService,
  chart: Chart,
  dispatch: Dispatch;
};

export default
@Inject('chartDataService')
class StartFetchChartDataAction extends AbstractChartAreaAction {
  private readonly chartDataService: ChartDataService;
  private readonly chart: Chart;

  constructor({ chart,
                chartDataService,
                dispatch }: ConstructorArgs) {
    super(dispatch);
    this.chartDataService = chartDataService;
    this.chart = chart;
  }

  perform(currentState: ChartAreaState): ChartAreaState {
    this.chartDataService
      .fetchChartData(
        this.chart.dataSource,
        this.chart.getColumns(),
        this.chart.getFilters(),
        this.chart.getSortBys()
      )
      .then((columnNameToValuesMap: ColumnNameToValuesMap) => {
        this.dispatch(
          new FinishFetchChartDataAction(columnNameToValuesMap,
                                         this.chart.id)
        );
      })
      .catch((error) => {
        // Handle error
      });

    this.chart.isFetchingChartData = true;
    return ChartAreaStateUpdater
            .getNewStateForChangedChart(currentState, this.chart);
  }
}
```

To be able to dispatch the above action, a controller should be implemented:

```ts
import diContainer from './diContainer';
import StartFetchChartDataAction from './StartFetchChartDataAction';
import Controller from './Controller';
import store from './store';

class ChartAreaController extends Controller {
  readonly actionDispatchers = {
    startFetchChartData: (chart: Chart) =>
      // the 'chart' is given as a property to
      // StartFetchChartDataAction class constructor
      this.dispatchWithDi(diContainer,
                         StartFetchChartDataAction,
                         { chart });
  }
}

export const controller = new ChartAreaController(store.dispatch);
export type ActionDispatchers = typeof controller.actionDispatchers;
```

The following base classes are also defined:

{title: "AbstractAction.ts"}
```ts
export default abstract class AbstractAction<S> {
  abstract perform(state: S): S;
}
```

{title: "AbstractDispatchingAction.ts"}
```ts
// Imports...

export default abstract class AbstractDispatchingAction<S>
    extends AbstractAction<S> {
  constructor(protected readonly dispatch: Dispatch) {}
}
```

{title: "AbstractChartAreaAction.ts"}
```ts
// Imports...

export default abstract class AbstractChartAreaAction
         extends AbstractDispatchingAction<ChartAreaState> {
}
```

{title: "Controller.ts"}
```ts
export type ReduxDispatch =
  (reduxActionObject: { type: AbstractAction<any> }) => void;

export default class Controller {
  protected readonly dispatch:
    (action: AbstractAction<any>) => void;

  constructor(reduxDispatch: ReduxDispatch) {
    this.dispatch = (action: AbstractAction<any>) =>
      reduxDispatch({ type: action });
  }

  dispatchWithDi(
    diContainer: { create: (...args: any[]) => Promise<any> },
    ActionClass:
      abstract new (...args: any[]) => AbstractAction<any>,
    otherArgs: {}
  ) {
    // diContainer.create will create a new object of
    // class ActionClass.
    // The second parameter of the create function defines
    // additional properties supplied to ActionClass constructor.
    // The create method is asynchronous. When it succeeds,
    // the created action object is available in the 'then'
    // function and it can be now dispatched

    diContainer
      .create(ActionClass, {
        dispatch: this.dispatch,
        ...otherArgs
      })
      .then((action: any) => this.dispatch(action));
  }
}
```

## Avoid Code Duplication Principle

> ***At the class level, when you spot duplicated code in two different classes implementing the same interface, you should create a new base class to accommodate the common functionality and let the classes extend the new base class.***

Below is an `AvroBinaryKafkaInputMessage` class that implements the `InputMessage` interface:

{title: "InputMessage.h"}
```cpp
class InputMessage
{
public:
  virtual ~InputMessage() = default;

  virtual uint32_t tryDecodeSchemaId() const = 0;

  virtual std::shared_ptr<DecodedMessage>
  tryDecodeMessage(const std::shared_ptr<Schema>& schema)
  const = 0;
};
```

{title: "AvroBinaryKafkaInputMessage.h"}

```cpp
class AvroBinaryKafkaInputMessage : public InputMessage
{
public:
  AvroBinaryKafkaInputMessage(
    std::unique_ptr<RdKafka::Message> kafkaMessage
  ) : m_kafkaMessage(std::move(kafkaMessage))
  {}

  uint32_t tryDecodeSchemaId() const override;

  std::shared_ptr<DecodedMessage>
  tryDecodeMessage(const std::shared_ptr<Schema>& schema)
  const override;

private:
  std::unique_ptr<RdKafka::Message> m_kafkaMessage;
};

uint32_t AvroBinaryKafkaInputMessage::tryDecodeSchemaId() const
{
  // Try decode schema id from the beginning of
  // the Avro binary Kafka message
}

std::shared_ptr<DecodedMessage>
AvroBinaryKafkaInputMessage::tryDecodeMessage(
  const std::shared_ptr<Schema>& schema
) const
{
  return schema->tryDecodeMessage(m_kafkaMessage->payload(),
                                  m_kafkaMessage->len());
}
```

If we wanted to introduce a new Kafka input message class for JSON, CSV, or XML format, we could create a class like the `AvroBinaryKafkaInputMessage` class. But then we can notice the duplication of code in the
`tryDecodeMessage` method. We can notice that the `tryDecodeMessage` method is the same regardless of the input message source and format.
According to this principle, we should move the duplicate code to a common base class, `BaseInputMessage`. We could make
the `tryDecodeMessage` method a template method according to the _template method pattern_ and create abstract methods for getting the message data and
its length:

{title: "BaseInputMessage.h"}
```cpp
class BaseInputMessage : public InputMessage
{
public:
  std::shared_ptr<DecodedMessage>
  tryDecodeMessage(const std::shared_ptr<Schema>& schema)
  const final;

protected:
  // Abstract methods
  virtual uint8_t* getData() const = 0;
  virtual size_t getLengthInBytes() const = 0;
};

// This is a template method
// 'getData' and 'getLengthInBytes' will be
// implemented in subclasses
std::shared_ptr<DecodedMessage>
BaseInputMessage::tryDecodeMessage(
  const std::shared_ptr<Schema>& schema
) const
{
  return schema->tryDecodeMessage(getData(), getLengthInBytes());
}
```

Next, we should refactor the `AvroBinaryKafkaInputMessage` class to extend the new `BaseInputMessage` class and implement the `getData` and `getLengthInBytes` methods.
But we can realize these two methods are the same for all Kafka input message data formats.
We should not implement those two methods in the `AvroBinaryKafkaInputMessage` class because
we would need to implement them as duplicates if we needed to add a Kafka input message class for another data format.
Once again, we can utilize this principle and create a new base class for Kafka input messages:

{title: "KafkaInputMessage.h"}
```cpp
class KafkaInputMessage : public BaseInputMessage
{
public:
  KafkaInputMessage(
    std::unique_ptr<RdKafka::Message> kafkaMessage
  ) : m_kafkaMessage(std::move(kafkaMessage))
  {}

protected:
  uint8_t* getData() const final;
  size_t getLengthInBytes() const final;

private:
  std::unique_ptr<RdKafka::Message> m_kafkaMessage;
};

uint8_t* KafkaInputMessage::getData() const
{
  return std::bit_cast<uint8_t*>(m_kafkaMessage->payload());
}

size_t KafkaInputMessage::getLengthInBytes() const
{
  return m_kafkaMessage->len();
}
```

Finally, we can refactor the `AvroBinaryKafkaInputMessage` class to contain no duplicated code:

{title: "AvroBinaryKafkaInputMessage.h"}
```cpp
class AvroBinaryKafkaInputMessage : public KafkaInputMessage
{
public:
  uint32_t tryDecodeSchemaId() const final;
};

uint32_t AvroBinaryKafkaInputMessage::tryDecodeSchemaId() const
{
  // Try decode the schema id from the beginning of
  // the Avro binary Kafka message
  // Use base class getData() and getDataLengthInBytes()
  // methods to achieve that
}
```

## Inheritance in Cascading Style Sheets (CSS)

This last section of this chapter is for full-stack Python developers interested in how inheritance works in CSS.
In HTML, you can define classes (class names) for HTML elements in the following way:

```html
<span class="icon pie-chart-icon">...</span>
```

In a CSS file, you define CSS properties for CSS classes, for example:

```css
.icon {
  background-repeat: no-repeat;
  background-size: 1.9rem 1.9rem;
  display: inline-block;
  height: 2rem;
  margin-bottom: 0.2rem;
  margin-right: 0.2rem;
  width: 2rem;
}

.pie-chart-icon {
  background-image: url('pie_chart_icon.svg');
}
```

The problem with the above approach is that it is not correctly object-oriented. In the HTML code, you
must list all the class names to combine all the needed CSS properties. It is easy to forget
to add a class name. For example, you could specify `pie-chart-icon` only and forget to specify the `icon`.

It is also difficult to change the inheritance hierarchy afterward. Suppose you wanted to add a new
class `chart-icon` for all the chart icons:

```css
.chart-icon {
  // Define properties here...
}
```

You would have to remember to add the `chart-icon` class name to all places in the HTML code where you are rendering chart icons:

```html
<span class="icon chart-icon pie-chart-icon">...</span>
```

The above-described approach is very error-prone. What you should do is introduce proper object-oriented design.
You need a CSS preprocessor that makes extending CSS classes possible. In the below example, I am using [SCSS](https://sass-lang.com/guide/):

```html
<span class="pieChartIcon">...</span>
```

```scss
.icon {
  background-repeat: no-repeat;
  background-size: 1.9rem 1.9rem;
  display: inline-block;
  height: 2rem;
  margin-bottom: 0.2rem;
  margin-right: 0.2rem;
  width: 2rem;
}

.chartIcon {
  @extend .icon;

  // Other chart icon related properties...
}

.pieChartIcon {
  @extend .chartIcon;

  background-image: url('../../../../../assets/images/icons/chart/pie_chart_icon.svg');
}
```

In the above example, we define only one class for the HTML element. The inheritance hierarchy is defined in the SCSS file using the
`@extend` directive. We are now free to change the inheritance hierarchy in the future without
any modification needed in the HTML code.
