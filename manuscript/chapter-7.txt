# Databases And Database Principles

This chapter presents principles for selecting and using databases. Principles are presented for the following database types:

- Relational databases
- Document databases
- Key-value databases
- Wide column databases
- Search engines

Relational databases are also called SQL databases because accessing a relational database involves issuing SQL statements.
Databases of the other database types are called [NoSQL](https://en.wikipedia.org/wiki/NoSQL) databases because they don't support SQL at all, or they support
only a subset of it, possibly with some additions and modifications.

## Relational Databases

> ***Relational databases are multipurpose databases that suit many needs. Choose a relational database if you are not aware***
> ***of all the requirements you have for a database now or in the future.***

For example, if you don't know what kind of database table relations and queries you need now or will need in the future, you should
consider using a relational database that is well-suited for different kinds of queries.

### Structure of Relational Database

Data in a relational database is organized in the following hierarchy:

- Logical databases (or schemas)
  - Tables
    - Columns

A table consists of columns and rows. Data in a database is stored as rows in the tables. Each row has
a value for each column in the table. A special 'NULL' value is used if a row does not have a value for a particular column. You can specify if null values are allowed for a column or not.

A microservice should have a single logical database (or schema).
Some relational databases have one logical database (or schema) available by default and in other databases,
you must create a logical database (or schema) by yourself.

### Use Object Relational Mapper (ORM) Principle

> ***Use an object-relational mapper (ORM) to avoid the need to write SQL and to avoid making your microservice potentially vulnerable to SQL injection attacks. Use an ORM to automatically map the database rows to objects that can be serialized to JSON.***

This section presents examples using the [SQLAlchemy](https://www.sqlalchemy.org/) library's ORM functionality.
An ORM uses *entities* as building blocks for the database schema. Each entity class in a microservice is reflected as a table in the database.
SQLAlchemy uses the term *model* instead of *entity*. I use the term entity in this book because it is a commonly used term, e.g., in domain-driven design.
Use the same name for an entity and the database table, except the table name should be plural. Below is an example of a `SalesItem` entity class.
Before defining the actual entity class(es), we need to declare a `Base` entity class:

{title: "Base.py"}
```python
from sqlalchemy.orm import DeclarativeBase

class Base(DeclarativeBase):
    pass
```

{title: "SalesItem.py"}
```python
from sqlalchemy import BigInteger, Double, String
from sqlalchemy.orm import Mapped
from sqlalchemy.orm import mapped_column

from Base import Base


class SalesItem(Base):
    __tablename__ = 'salesitems'

    id: Mapped[int] = mapped_column(
        BigInteger(), primary_key=True, autoincrement=True
    )

    name: Mapped[str] = mapped_column(String(256))
    price: Mapped[float] = mapped_column(Double())
```

Name the related table in the plural, e.g., `SalesItem` entities are stored in a table named `salesitems`. In this book, I write all identifiers in lowercase. The case sensitivity of a database
depends on the database and the operating system it is running on. For example, MySQL is case-sensitive only on Linux
systems.

The attributes of an entity map to columns of the entity table, meaning that the `salesitems` table has
the following columns:

- id
- name
- price

Each entity table should have a [primary key](https://en.wikipedia.org/wiki/Primary_key) defined. The primary key must be unique for each row in the table.
In the above example, we give the `primary_key=True` argument for the `mapped_column` function to define that the particular
column should be a primary key and contain a unique value for each row. We also define that the database
should generate an automatically incremented value for the `id` column (The default value for the `autoincrement` parameter is True, so it is not specified anymore in further examples).

ORM can create database tables according to entity definitions in code. Below is an example SQL statement that the ORM generates to create a table for storing `SalesItem` entities:

```sql
CREATE TABLE salesitems (
    id BIGINT NOT NULL AUTO_INCREMENT,
    name VARCHAR(256) NOT NULL,
    price DOUBLE NOT NULL,
    PRIMARY KEY (id)
)
```

Columns of a table can be specified as unique and nullable. We want to store sales items with unique names. Below is an example where we define the values of the `name` column in the `salesitems` table as unique (using the `UniqueConstraint`). We also add a `description` column that is nullable.

```python
from typing import Optional

from Base import Base
from sqlalchemy import BigInteger, String, UniqueConstraint
from sqlalchemy.orm import Mapped, mapped_column


class SalesItem(Base):
    __tablename__ = 'salesitems'
    __table_args__ = (UniqueConstraint('name'))

    id: Mapped[int] = mapped_column(BigInteger(), primary_key=True)
    name: Mapped[str] = mapped_column(String(256))
    price: Mapped[float] = mapped_column(Double())
    description: Mapped[Optional[str]] = mapped_column(String(1024))
```

ORM generates the following SQL statement for creating the above-defined `salesitems` table:

```sql
CREATE TABLE salesitems (
    id BIGINT NOT NULL AUTO_INCREMENT,
    name VARCHAR(256) NOT NULL,
    price DOUBLE NOT NULL,
    description VARCHAR(1024),
    PRIMARY KEY (id),
    UNIQUE (name)
)
```

Let's create an entity and store it in the database. First, we have to create a database engine:

```python
import os

from sqlalchemy import create_engine

engine = create_engine(os.environ.get('DATABASE_URL'))
```

For demonstration purposes, we could use an in-memory SQLite database:

```python
from sqlalchemy import create_engine

engine = create_engine('sqlite://', echo=True)
```

The `echo=True` parameter defines that SQL statements generated and used by the ORM will be logged to standard output.
This is handy for debugging purposes. After we have created the database engine, we must create the database tables
in the database. That can be done using the following command:

```python
from Base import Base


Base.metadata.create_all(engine)
```

Next, we can create a sales item and persist it to the database:

```python
from SalesItem import SalesItem
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import Session

sales_item = SalesItem(name='Sample sales item', price='10')

try:
    with Session(engine) as session:
        session.add(sales_item)
        session.commit()
except SQLAlchemyError:
    # Handle error
```

ORM will generate the needed SQL statement on your behalf and execute it.
Below is an example SQL statement generated by the ORM to persist a sales item
(Remember that the database autogenerates the `id` column).

```sql
INSERT INTO salesitems (name, price)
VALUES ('Sample sales item', 10)
```

You can search for the created sales item in the database:

```python
from SalesItem import SalesItem
from sqlalchemy import select
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import Session

statement = select(SalesItem).where(SalesItem.id == sales_item.id)

try:
    with Session(engine) as session:
        sales_item = session.scalars(statement).one()
except SQLAlchemyError:
    # Handle error
```

For the above operation, the ORM will generate the following SQL query:

```sql
SELECT id, name, price, description FROM salesitems WHERE id = 1
```

Then, you can modify the entity by setting the values of its attributes and using `commit` on the `session` to update the database:

```python
from SalesItem import SalesItem
from sqlalchemy import select
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import Session

try:
    with Session(engine) as session:
        sales_item = session.get(SalesItem, 1)
        sales_item.price = 20
        session.commit()
except SQLAlchemyError:
    # Handle error
```

For the above operation, the ORM will generate the following SQL statement:

```sql
UPDATE salesitems SET price = 20 WHERE id = 1
```

Lastly, you can delete the sales item:

```python
try:
    with Session(engine) as session:
        sales_item = session.get(SalesItem, 1)
        session.delete(sales_item)
        session.commit()
except SQLAlchemyError:
    # Handle error
```

The ORM will execute the following SQL statement:

```sql
DELETE FROM salesitems WHERE id = 1
```

Suppose your microservice executes SQL queries that do not include the primary key column in the
query's WHERE clause. In that case, the database engine must perform a [full table scan](https://en.wikipedia.org/wiki/Full_table_scan) to find the wanted rows. Let's say
you want to query sales items, the price of which is less than 10. This can be achieved with
the below query:

```python
# price = ...

statement = select(SalesItem).where(SalesItem.price < price)

try:
    with Session(engine) as session:
        sales_items = session.scalars(statement).all()
except SQLAlchemyError:
    # Handle error
```

The database engine must perform a full table scan to find all the sales items where the `price` column has
a value below the `price` variable's value. If the database is large, this can be slow. If you
perform the above query often, you should optimize those queries by creating an index. For the above
query to be fast, we must create an index for the `price` column:

```python
from typing import Optional

from Base import Base
from sqlalchemy import BigInteger, Double, String, UniqueConstraint
from sqlalchemy.orm import Mapped, mapped_column


class SalesItem(Base):
    __tablename__ = 'salesitems'
    __table_args__ = (UniqueConstraint('name'),)

    id: Mapped[int] = mapped_column(BigInteger(), primary_key=True)
    name: Mapped[str] = mapped_column(String(256))
    price: Mapped[float] = mapped_column(Double(), index=True)
    description: Mapped[Optional[str]] = mapped_column(String(1024))
```

#### Entity/Table Relationships

Tables in a relational database can have relationships with other tables. There are three types of relationships:

- One-to-one
- One-to-many
- Many-to-many

##### One-To-One/Many Relationships

In this section, we focus on one-to-one and one-to-many relationships. In a one-to-one relationship, a single row in a table can
have a relationship with another row in another table. In a one-to-many relationship, a single row in a table can
have a relationship with multiple rows in another table.

Let's have an example with an *order-service* that can store orders in a database. Each order consists of one
or more order items. An order item contains information about the bought sales item.

```python
from Base import Base
from sqlalchemy import BigInteger, ForeignKey
from sqlalchemy.orm import Mapped, mapped_column, relationship


class Order(Base):
    __tablename__ = 'orders'

    id: Mapped[int] = mapped_column(BigInteger(), primary_key=True)
    # Other fields ...
    items: Mapped[list['OrderItem']] = relationship(lazy='joined')


class OrderItem(Base):
    __tablename__ = 'orderitems'
    __table_args__ = (
        PrimaryKeyConstraint('orderId', 'id', name='orderitems_pk'),
    )

    id: Mapped[int]
    salesitemid: Mapped[int] = mapped_column(BigInteger())
    orderid: Mapped[int] = mapped_column(ForeignKey('orders.id'))
```

Orders are stored in the `orders` table, and order items
are stored in the `orderitems` table, which contains a join column named `orderid`. Using this join column, we can map a particular
order item to a specific order. Each order item maps to precisely one sales item. For this reason, the `orderitems` table
also contains a column named `salesitemid`. Sales items are stored in a different database in a separate microservice (*sales-item-service*), so there are no intra-database inter-table relationships with the  *order-service* and *sales-item-service*.

Below is the SQL statement generated by the ORM for creating the `orderitems` table. The one-to-many relationship
is reflected in the [foreign key](https://en.wikipedia.org/wiki/Foreign_key) constraint:

```sql
CREATE TABLE orderitems (
    id INTEGER NOT NULL,
    salesitemid BIGINT NOT NULL,
    orderid BIGINT NOT NULL,
    CONSTRAINT orderitems_pk PRIMARY KEY (orderid, id),
    FOREIGN KEY (orderid) REFERENCES orders (id)
)
```

The ORM executes the below SQL query to fetch the order with id 123 and its order items:

```sql
SELECT o.id, oi.id
FROM orders o
LEFT JOIN orderitems oi ON o.id = oi.orderid
WHERE o.id = 123
```

##### Many-To-Many Relationships

In a many-to-many relationship, one entity has a relationship with many entities of another type, and those entities have
a relationship with many entities of the first entity type. For example, a student can attend many courses, and a course can have numerous students attending it.

Suppose we have a service that stores student and course entities in a database. Each student entity contains the courses the student has
attended. Similarly, each course entity contains a list of students that have attended the course. We have a many-to-many relationship where
one student can attend multiple courses, and multiple students can attend one course. This means an additional [association/associative table](https://en.wikipedia.org/wiki/Associative_entity), `studentcourse,` must be created.
This new table maps a particular student to a particular course.

```python
from sqlalchemy import BigInteger Column, ForeignKey, Table
from sqlalchemy.orm import (
    DeclarativeBase,
    Mapped,
    mapped_column,
    relationship,
)


class Base(DeclarativeBase):
    pass


student_course_assoc_table = Table(
    'studentcourse',
    Base.metadata,
    Column('studentid', ForeignKey('students.id'), primary_key=True),
    Column('courseid', ForeignKey('courses.id'), primary_key=True),
)


class Student(Base):
    __tablename__ = 'students'

    id: Mapped[int] = mapped_column(BigInteger(), primary_key=True)
    # Other fields...

    courses: Mapped[list['Course']] = relationship(
        secondary=student_course_assoc_table, back_populates='students'
    )


class Course(Base):
    __tablename__ = 'courses'

    id: Mapped[int] = mapped_column(BigInteger(), primary_key=True)
    # Other fields...

    students: Mapped[list[Student]] = relationship(
        secondary=student_course_assoc_table, back_populates='courses'
    )
```

The ORM creates the `students` and `courses` tables in addition to the `studentcourse` mapping table:

```sql
CREATE TABLE studentcourse (
  studentid BIGINT NOT NULL,
  courseid BIGINT NOT NULL,
  PRIMARY KEY (studentid, courseid),
  FOREIGN KEY (studentid) REFERENCES students (id),
  FOREIGN KEY (courseid) REFERENCES courses (id)
)

```

Below is an example SQL query that the ORM executes to fetch attended courses for the user identified with id 123:

```sql
SELECT s.id, c.id
FROM students s
LEFT JOIN studentcourse sc ON s.id = sc.studentid
LEFT JOIN courses c ON c.id = sc.courseid
WHERE s.id = 123
```

Below is an example SQL query that the ORM executes to fetch students for the course identified with id 123:

```sql
SELECT c.id, s.id
FROM courses c
LEFT JOIN studentcourse sc ON c.id = sc.courseid
LEFT JOIN students s ON s.id = sc.studentid
WHERE c.id = 123
```

In real-life scenarios, you don't necessarily have to or should implement many-to-many database relations inside a single microservice.
For example, the above service that handles students and courses is against the *single responsibility principle* on the abstraction
level of courses and students. (However, if we created a *school* microservice on a higher abstraction level, we can have students and courses tables in the same microservice)
If we created a separate microservice for students and a separate microservice for courses, then there wouldn't be
many-to-many relationships between database tables in a single microservice.

#### Sales Item Repository Example

Let's define a `SalesItemRepository` implementation using SQLAlchemy's ORM capabilities for the *sales-item-service* API defined in the previous chapter. Let's start by defining the `Base`, `SalesItem`, and `SalesItemImage` entities:

{format: python}
![entities/Base.py](resources/chapter6/code/salesitemservice/entities/Base.py)

{format: python}
![entities/SalesItem.py](resources/chapter6/code/salesitemservice/entities/SalesItem.py)

{format: python}
![entities/SalesItemImage.py](resources/chapter6/code/salesitemservice/entities/SalesItemImage.py)

Below is the implementation of the `OrmSalesItemRepository`:

{format: python}
![repositories/OrmSalesItemRepository.py](resources/chapter6/code/salesitemservice/repositories/OrmSalesItemRepository.py)

The domain entity and database entity are not necessarily the same. A typical example is when the entity id in the database entity is numeric, a 64-bit integer, but the domain entity has it as a string so that it can be used by any client (including JavaScript, where numeric limits are
less than 64-bit).
You often benefit from creating separate entity classes for a repository and the domain model. You might want to store domain entities in a database in a slightly different format. In that case, you
must define separate entity classes for the domain and the repository. You can name database-related entities with a Db-prefix, e.g. DbSalesItem.
In the DbSalesItem class, you need two conversion methods: from a domain entity and to a domain entity:

```java
DbSalesItem.from(domainEntity)
DbSalesItem.from(salesItem)

salesItem = dbSalesItem.toDomainEntity()
```

If you need to change your database, you can have mixed format ids (e.g., from a relational database with BIGINT ids to a MongoDB with string-format ObjectIds). If you want uniform unique ids, you must generate them
in your software component, not by the database. This might be a good approach also from the security point of view to prevent [IDOR](https://cheatsheetseries.owasp.org/cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html). If you generate random UUIDs in your application, and you have accidentally broken authorization (IDOR), it is not possible for an attacker to guess UUIDs and try to access other users' resources using them.


### Use Parameterized SQL Statements Principle

> ***If you are not using an ORM for database access, use parameterized SQL statements to prevent potential SQL injection attacks.***

Let's use the Python MySQL connector library [mysql-connector-python](https://dev.mysql.com/doc/connector-python/en/). First, we insert data to the `salesitems` table:

```python
from mysql.connector import connect, Error

connection = None

try:
    connection = connect(
        host='...',
        database='...',
        user='...',
        password='...'
    )

    cursor = connection.cursor(prepared=True)
    sql_statement = 'INSERT INTO salesitems (name, price) VALUES (%s, %s)'
    cursor.execute(sql_statement, ('Sample sales item 1', 20))
    connection.commit()
except Error as error:
    # Handle error
finally:
    if connection:
        connection.close()
```

The `%s` in the above SQL statement are placeholders for parameters in a parameterized SQL statement. The second argument for the `execute`
method contains the parameter values in a tuple. When a database engine receives a parameterized query, it will replace the placeholders in the SQL statement with the supplied parameter values.

Next, we can update a row in the `salesitems` table. The below example changes the price of the sales item with id 123 to 20:

```python
from mysql.connector import connect, Error

connection = None

try:
    connection = connect(
        host='...',
        database='...',
        user='...',
        password='...'
    )

    cursor = connection.cursor(prepared=True)
    sql_statement = 'UPDATE salesitems SET PRICE = %s WHERE id = %s'
    cursor.execute(sql_statement, (20, 123))
    connection.commit()
except Error as error:
    # Handle error
finally:
    if connection:
        connection.close()
```

Let's execute a SELECT statement to get sales items with their price over 20:

```python
from mysql.connector import connect, Error

connection = None

try:
    connection = connect(
        host='...',
        database='...',
        user='...',
        password='...'
    )

    cursor = connection.cursor(prepared=True)
    sql_statement = 'SELECT id, name, price FROM salesitems WHERE price >= %s'
    cursor.execute(sql_statement, (20,))
    result = cursor.fetchall()
except Error as error:
    # Handle error
finally:
    if connection:
        connection.close()
```

In an SQL SELECT statement, you cannot use parameters everywhere. You can use them as value placeholders in the WHERE clause. You need string concatenation to put user-supplied data in other parts of an SQL SELECT statement. You should not concatenate user-supplied data without sanitation because that would open up possibilities for SQL injection attacks. Let's say you allow the microservice client to specify a sorting column:

```python
import string


class ValidateColNameError(Exception):
    pass


def try_validate_col_name(column_name: str) -> str:
    allowed_chars = string.ascii_letters + string.digits + '_' + '$'

    if all(
        col_name_char in allowed_chars for col_name_char in column_name
    ):
        return column_name

    raise ValidateColNameError()


sort_column_name = # Unvalidated data got from client

sql_query = (
    'SELECT id, name, price FROM salesitems ORDER BY '
    + try_validate_col_name(sort_column_name)
)

# ...
```

As shown above, you must validate the `sort_column` value to contain only valid characters for a MySQL column name. If you need to get the sorting direction from the client, you should validate
that value as `ASC` or `DESC`.

```python
class ValidateSortDirError(Exception):
    pass


def try_validate_sort_dir(sort_dir: str) -> str:
    lower_case_sort_dir = sort_dir.lower()

    if lower_case_sort_dir == 'asc' or lower_case_sort_dir == 'desc':
        return sort_dir

    raise ValidateSortDirError()


sort_column_name = # Unvalidated data got from client
sort_direction = # Unvalidated data got from client

sql_query = (
  'SELECT id, name, price'
  'FROM salesitems'
  'ORDER BY'
  f'{try_validate_col_name(sort_column_name)}'
  f'{try_validate_sort_dir(sort_direction)'
)

# ...
```

When you get values for a MySQL query's `LIMIT` clause from a client, you must validate that those values are
integers and in a valid range. Don't allow the client to supply random, very large values. In the example below, we assume
two validation functions exist: `try_validate_row_offset` and `try_validate_row_count`. The validation functions will raise an error if
validation fails.

```python

def try_validate_row_offset(row_offset: str) -> str:
    # Implement ...

def try_validate_row_count(row_count: str) -> str:
    # Implement ...

row_offset = # Unvalidated data got from client
row_count = # Unvalidated data got from client

try_validate_row_offset(row_offset)
try_validate_row_count(row_count)

sql_query = (
  'SELECT id, name, price'
  'FROM salesitems'
  f'LIMIT {row_offset}, {row_count}'
)

# ...
```

When you get a list of wanted column names from a client, you must validate that each of them is a valid column identifier:

```python
column_names = # Unvalidated data got from client
validated_col_names = [try_validate_col_name(column_name) for column_name in column_names]
sql_query = f'SELECT {", ".join(validated_col_names)} FROM salesitems'

# ...
```

#### Sales Item Repository Example

Let's implement the `SalesItemRepository` for the *sales-item-service* API from the previous chapter using parameterized SQL:

{format: python}
![repositories/ParamSqlSalesItemRepository.py](resources/chapter6/code/salesitemservice/repositories/ParamSqlSalesItemRepository.py)

### Normalization Rules

> ***Apply normalization rules to your database design.***

Below are listed the three most basic [database normalization rules](https://en.wikipedia.org/wiki/Database_normalization):

- First normal form (1NF)
- Second normal form (2NF)
- Third normal form (3NF)

A database relation is often described as "normalized" if it meets the first, second, and third normal forms.

#### First Normal Form (1NF)

The first normal form requires that a single value exists at every intersection of a row and column, never a list of values.
When considering a sales item, the first normal form states that there cannot be two different price values in
the `price` column or more than one name for the sales item in the `name` column. If you need multiple names for a sales item, you
must establish a one-to-many relationship between a `SalesItem` entity and `SalesItemName` entities. What this means in practice
is that you remove the `name` property from the `SalesItem` entity class and create a new `SalesItemName` entity class used to
store sales items' names. Then, you create a one-to-many mapping between a `SalesItem` entity and `SalesItemName` entities.

#### Second Normal Form (2NF)

The second normal form requires that each non-key column entirely depends on the primary key. Let's assume that we have the following columns in an `orderitems` table:

- `orderid` (primary key)
- `productid` (primary key)
- `orderstate`

The `orderstate` column only depends on the `orderid` column, not the entire primary key. The `orderstate` column is in the wrong table.
It should, of course, be in the `orders` table.

#### Third Normal Form (3NF)

The third normal form requires that non-key columns are independent of each other.

Let's assume that we have the following columns in a `salesitems` table:

- `id` (primary key)
- `name`
- `price`
- `category`
- `discount`

Let's assume that the discount depends on the category. This table violates the third normal form because a non-key column, `discount`,
depends on another non-key column, `category`. Column independence means that you can change any non-key column value without
affecting any other column. If you changed the category, the discount would need to be changed accordingly, thus violating the third normal form rule.

The discount column should be moved to a new `categories` table with the following columns:

- `id` (primary key)
- `name`
- `discount`

Then we should update the `salesitems` table to contain the following columns:

- `id` (primary key)
- `name`
- `price`
- `categoryid` (a foreign key that references the `id` column in the `categories` table)

## Document Databases

> ***Use a document database in cases where complete documents (e.g., JSON objects) are typically stored and retrieved as a whole.***

Document databases, like [MongoDB](https://www.mongodb.com/), are useful for storing complete documents. A document is usually a JSON object containing
information in arrays and nested objects. Documents are stored as such, and a whole document will be fetched when queried.

Let's consider a microservice for sales items. Each sales item contains an id, name, price, image URLs, and user reviews.

Below is an example sales item as a JSON object:

```json
{
  "id": "507f191e810c19729de860ea",
  "category": "Power tools",
  "name": "Sample sales item",
  "price": 10,
  "imageUrls": ["https://url-to-image-1...",
                "https://url-to-image-2..."],
  "averageRatingInStars": 5,
  "reviews": [
     {
       "reviewerName": "John Doe",
       "date": "2022-09-01",
       "ratingInStars": 5,
       "text": "Such a great product!"
     }
  ]
}
```

A document database usually has a size limit for a single document. Therefore, the above example does not store sales item images
directly inside the document but only URLs for the images. Actual images are stored in another data store more suitable for storing
images, like Amazon S3.

When creating a microservice for sales items, we can choose a document database because we usually store and access whole documents.
When sales items are created, they are created as JSON objects of the above shape with the `reviews` array being empty and `averageRatingInStars` being `null`.
When a sales item is fetched, the whole document is retrieved from the database. When a client
adds a review for a sales item, the sales item is fetched from the database. The new review is appended to the `reviews` array, a new average
rating is calculated, and finally, the document is persisted with the modifications.

Below is an example of inserting one sales item to a MongoDB collection named `salesItems` using the [PyMongo](https://pymongo.readthedocs.io/en/stable/api/index.html) library. MongoDB uses the term [collection](https://www.mongodb.com/docs/manual/core/databases-and-collections/)
instead of *table*. A MongoDB collection can store multiple documents.

```python
from pymongo import MongoClient

URL = "mongodb://localhost:27017"
client = MongoClient(URL)

# Create the database for our example
database = client['sales_item_service']
sales_items_coll = database['sales_items']

sales_items_coll.insert_one({
  'category': 'Power tools',
  'name': 'Sample sales item 1',
  'price': 10,
  'images': ['https://url-to-image-1...',
             'https://url-to-image-2...'],
  'averageRatingInStars': None,
  'reviews': []
})

client.close()
```

You can find sales items for the *Power tools* category with the following query:

```python
sales_items = sales_items_coll.find({ 'category': 'Power tools' })
print(sales_items.next())
```

If clients are usually querying sales items by category, it is wise to create an index for that field:

```python
# 1 means ascending index, -1 means descending index
sales_items_coll.create_index([('category', 1)])
```

When a client wants to add a new review for a sales item, you first fetch the document for the sales item:

```python
sales_items_coll.find({ '_id': ObjectId('507f191e810c19729de860ea') })
```

Then, you calculate a new value for the `averageRatingInStars` field using the existing ratings and the new rating
and add the new review to the `reviews` array and then update the document with the following command:

```python
sales_items_coll.update_one(
    {'_id': ObjectId('6527a461bd3c27d2d1822508')},
    {
        '$set': {'averageRatingInStars': 5},
        '$push': {
            'reviews': {
                'reviewerName': 'John Doe',
                'date': '2022-09-01',
                'ratingInStars': 5,
                'text': 'Such a great product!',
            }
        },
    },
)
```

Clients may want to retrieve sales items sorted descending by the average rating. For this reason, you might want
to change the indexing to the following:

```python
sales_items_coll.create_index( [ ('category', 1), ('averageRatingInStars', -1) ] )
```

A client can issue, for example, a request to get the best-rated sales items in the *power tools* category.
This request can be fulfilled with the following query that utilizes the above-created index:

```python
sales_items_coll.find({'category': 'Power tools'}).sort(
    [('averageRatingInStars', -1)]
)
```

### Sales Item Repository Example

Let's implement the `SalesItemRepository` for the *sales-item-service* API from the previous chapter using MongoDB:

{format: python}
![repositories/MongoDbSalesItemRepository.py](resources/chapter6/code/salesitemservice/repositories/MongoDbSalesItemRepository.py)

## Key-Value Database Principle

> ***Use a key-value database for fast real-time access to data stored by a key. Key-value stores usually store data in memory with a possibility for persistence.***

A simple use case for a key-value database is to use it as a cache for a relational database. For example, a microservice can store SQL query results
from a relational database in the cache. [Redis](https://redis.io/) is a popular open-source key-value store. Let's have an example with Redis
to cache an SQL query result. In the below example, we assume that the SQL query result is available as a dict:

```python
import json
from redis import Redis


redis_client = Redis(host='localhost', port=6379, decode_responses=True)
redis_client.set(sql_query_statement, json.dumps(sql_query_result))
```

The cached SQL query result can be fetched from Redis:

```python
sql_query_result_json = redis_client.get(sql_query_statement)
```

With Redis, you can create key-value pairs that expire automatically after a specified time. This is a useful feature if you are using the key-value database as a cache. You may want the cached items to expire after a while.

In addition to plain strings, Redis also supports other data structures. For example, you
can store a list, queue, or hash map as a value for a key in Redis. If you store a queue in Redis, you can
use it as a simple single-consumer message broker. Below is an example of producing a
message to a topic in the message broker:

```python
# RPUSH command (= right push) pushes a new message
# to the end of the list identified by key *topic*.
redis_client.rpush(topic, message)
```

Below is an example of consuming a message from a topic in the message broker:

```python
# LPOP command (= left pop) pops a message from
# the beginning of the list identified by key *topic*
# The LPOP command removes the value from the list
message = redis_client.lpop(topic)
```

## Wide-Column Databases

> ***Use a wide-column database when you have a large amount of data and know what queries you need to execute, and you want these queries to be fast.***

Table structures of a wide-column database are optimized for specific queries.
With a wide-column database, storing duplicate data is okay to make the queries
faster. Wide-column databases also scale horizontally well, making them suitable for storing a large amount of data.

This section uses [Apache Cassandra](https://cassandra.apache.org/_/index.html) as an example wide-column database. Cassandra is
a scalable multi-node database engine. In Cassandra, the data of a table is divided into
partitions according to the table's [partition key](https://www.baeldung.com/cassandra-keys). A partition key is composed of one or more
columns of the table. Each partition is stored on a single Cassandra node. You can think that Cassandra is a key-value store where the key is the partition key, and the value is another
"nested" table. The rows in the "nested" table are uniquely identified by clustering columns sorted by default in ascending order. The sort order can be changed to descending if wanted.

The partition key and the clustering columns form the table's primary key. The primary key uniquely
identifies a row. The order of these components always puts the partition key first and then the clustering columns (or clustering key).
Let's have an example table that is used to store hotels near a particular point of interest (POI):

```cql
CREATE TABLE hotels_by_poi (
  poi_name text,
  hotel_distance_in_meters_from_poi int,
  hotel_id uuid,
  hotel_name text,
  hotel_address text,
  PRIMARY KEY (poi_name, hotel_distance_in_meters_from_poi, hotel_id)
);
```

In the above example, the primary key consists of three columns. The first column (`poi_name`) is always the partition key.
The partition key must be given in a query. Otherwise, the query will be slow because Cassandra must perform a full table
scan because it does not know which node data is located. When the partition key is given in a SELECT
statement's WHERE clause, Cassandra can find the appropriate node where the data for that particular partition resides. The two other primary key columns, `hotel_distance_in_meters_from_poi` and `hotel_id`, are the clustering columns. They define the order and uniqueness of the rows in the "nested" table.

![hotels_by_poi Table](resources/chapter7/images/03-01.png)

The above figure shows that when you give a partition key value (`poi_name`), you have access to the
respective "nested" table where rows are ordered first by the `hotel_distance_in_meters_from_poi` (ascending)
and second by the `hotel_id` (ascending).

Now, it is easy for a hotel room booking client to ask the server to execute a query to find hotels near a POI given
by a user. The following query will return the first 15 hotels nearest to *Piccadilly Circus* POI:

```cql
SELECT
  hotel_distance_in_meters_from_poi,
  hotel_id,
  hotel_name,
  hotel_address
FROM hotels_by_poi
WHERE poi_name = 'Piccadilly Circus'
LIMIT 15
```

When a user selects a particular hotel from the result of the above query, the client can request the execution of
another query to fetch information about the selected hotel. The user wants to see
other POIs near the selected hotel. For that query, we should create another table:

```cql
CREATE TABLE pois_by_hotel_id (
  hotel_id uuid,
  poi_distance_in_meters_from_hotel int,
  poi_id uuid,
  poi_name text,
  poi_address text,
  PRIMARY KEY (hotel_id, poi_distance_in_meters_from_hotel, poi_id)
);
```

Now, a client can request the server to execute a query to fetch the nearest 20 POIs for a selected hotel.
(hotel with id c5a49cb0-8d98-47e3-8767-c30bc075e529):

```cql
SELECT
  poi_distance_in_meters_from_hotel,
  poi_id,
  poi_name,
  poi_address
FROM pois_by_hotel_id
WHERE hotel_id = c5a49cb0-8d98-47e3-8767-c30bc075e529
LIMIT 20
```

In a real-life scenario, a user wants to search for hotels near a particular POI for a selected period. The server should respond with the nearest hotels having free rooms for the selected period.
For that kind of query, we can create an additional table for storing hotel room availability:

```cql
CREATE TABLE availability_by_hotel_id (
  hotel_id uuid,
  accommodation_date date,
  available_room_count counter,
  PRIMARY KEY (hotel_id, accommodation_date)
);
```

The above table is updated whenever a room for a specific day is booked, or a booking for a room
is canceled. The `available_room_count` column value is either decremented or incremented by one in the update procedure.

Let's say that the following query has been executed:

```cql
SELECT
  hotel_distance_in_meters_from_poi,
  hotel_id,
  hotel_name,
  hotel_address
FROM hotels_by_poi
WHERE poi_name = 'Piccadilly Circus'
LIMIT 30
```

Next, we should find hotels from the result of 30 hotels that have available rooms between the 1st of September
2023 and 3rd of September 2023. We cannot use joins in Cassandra, but we can execute the following query where we specifically list the hotel ids returned by the above query:

```cql
SELECT hotel_id, MIN(available_room_count)
FROM availability_by_hotel_id
WHERE hotel_id IN (List the 30 hotel_ids here...) AND
      accommodation_date >= '2022-09-01' AND
      accommodation_date <= '2022-09-03'
GROUP BY hotel_id
LIMIT 15
```

As a result of the above query, we have a list of a maximum of 15 hotels for which the minimum available room count is listed.
We can return a list of those maximum 15 hotels where the minimum available room count is one or more to the user.

If Cassandra's query language supported the `HAVING` clause, which it does not currently support,
we could have issued the following query to get what we wanted:

```cql
SELECT hotel_id, MIN(available_room_count)
FROM availability_by_hotel_id
WHERE hotel_id IN (List the 30 hotel_ids here...) AND
      accommodation_date >= '2022-09-01' AND
      accommodation_date <= '2022-09-03'
GROUP BY hotel_id
HAVING MIN(available_room_count) >= 1
LIMIT 15
```

A wide-column database is also useful for storing time-series data, e.g., from IoT devices and sensors. Below is a table definition
for storing measurement data in a telecom network analytics system:

```cql
CREATE TABLE measurements (
  measure_name text,
  dimension_name text,
  aggregation_period text,
  measure_timestamp timestamp,
  measure_value double,
  dimension_value text,
  PRIMARY KEY ((measure_name, dimension_name, aggregation_period),
               measure_timestamp,
               measure_value,
               dimension_value)
) WITH CLUSTERING ORDER BY (
  measure_timestamp DESC,
  measure_value DESC
  dimension_value ASC
);
```

In the above table, we have defined a *compound partition key* containing three columns: `measure_name`,
`dimension_name`, and `aggregation_period`. Columns for a compound partition key are given in parentheses because the first column of the primary key is always the partition key.

Suppose we have implemented a client that visualizes measurements. In the client, a user can first choose what
counter/KPI (= measure name) to visualize, then select a dimension and aggregation period. Let's say that the user wants
to see *dropped_call_percentage* for *cells* calculated for one minute at 2023-02-03 16:00. The following kind of
query can be executed:

```cql
SELECT measure_value, dimension_value
FROM measurements
WHERE measure_name = 'dropped_call_percentage' AND
      dimension_name = 'cell' AND
      aggregation_period = '1min' AND
      measureTimestamp = '2022-02-03T16:00+0000'
LIMIT 50;
```

The above query returns the top 50 cells with the highest dropped call percentage for the given minute.

We can create another table to hold measurements for a selected dimension value, e.g., for a particular cell id. This table can be used to
drill down to a particular dimension and see measure values in the history.

```cql
CREATE TABLE measurements_by_dimension (
  measure_name text,
  dimension_name text,
  aggregation_period text,
  dimension_value text,
  measure_timestamp timestamp,
  measure_value double,
  PRIMARY KEY ((measure_name,
                dimension_name,
                aggregation_period,
                dimension_value), measure_timestamp)
) WITH CLUSTERING ORDER BY (measureTimestamp DESC);
```

The below query will return dropped call percentage values for the last 30 minutes for the cell identified by
*cell id* 3000:

```cql
SELECT measure_value, measureTimestamp
FROM measurements_by_dimension
WHERE measure_name = 'dropped_call_percentage' AND
      dimension_name = 'cell' AND
      aggregation_period = '1min' AND
      dimension_value = '3000'
LIMIT 30;
```

## Search Engines

> ***Use a search engine if you have free-form text data that users should be able to query.***

A search engine (like [Elasticsearch](https://www.elastic.co/elasticsearch)) is useful for storing information like log entries collected
from microservices. You typically want to search the collected log data by the text in the log messages.

It is not necessary to use a search engine when you need to search for text data. Other databases, both document and relational,
have a special index type that can index free-form text data in a column. Considering the earlier example with MongoDB,
we might want a client to be able to search sales items by the text in the sales item's name. We don't need to store sales items in a search engine database. We can continue storing them in a document database
(MongoDB) and introduce a *text* type index for the `name` field. That index can be created with
the following MongoDB command:

```python
sales_items.create_index( { 'name': 'text' } )
```

