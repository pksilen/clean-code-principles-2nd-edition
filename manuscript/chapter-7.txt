# Databases And Database Principles

This chapter presents principles for selecting and using databases. Principles are presented for the following database types:

- Relational databases
- Document databases
- Key-value databases
- Wide column databases
- Search engines

Relational databases are also called SQL databases because accessing a relational database involves issuing SQL statements.
Databases of the other database types are called [NoSQL](https://en.wikipedia.org/wiki/NoSQL) databases because they don't support SQL at all or they support
only a subset of it, possibly with some additions and modifications.

## Relational Databases

> ***Relational databases are multipurpose databases that suit many needs. Choose a relational database if you are not aware***
> ***of all the requirements you have for a database now or in the future.***

For example, if you don't know what kind of database table relations and queries you need now or will need in the future, you should
consider using a relational database that is well-suited for different kinds of queries.

### Structure of Relational Database

Data in a relational database is organized in the following hierarchy:

- Logical databases (or schemas)
  - Tables
    - Columns

A table consists of columns and rows. Data in a database is stored as rows in the tables. Each row has
a value for each column in the table. A special `NULL` value is used if a row does not have a value for a particular column. You can specify if null values are allowed for a column or not.

A microservice should have a single logical database (or schema).
Some relational databases have one logical database (or schema) available by default; in other databases, you must create a logical database (or schema) by yourself.

### Use Object Relational Mapper (ORM) Principle

> ***Use an object-relational mapper (ORM) to avoid writing SQL and to avoid making your microservice potentially vulnerable to SQL injection attacks. An ORM automatically maps the database rows to objects that can be serialized to JSON.***

Many languages have ORM frameworks. Java has Java Persistence API (JPA, the most famous implementation of which is Hibernate),
JavaScript/TypeScript has TypeORM and Prisma, and Python has the Django framework and SQLAlchemy, for example.

An ORM uses entities as building blocks for the database schema. Each entity class in a microservice is reflected as a table in the database. Use the same name for an entity and the database table, except the table name should
be plural.

The domain entity and database entity are not necessarily the same. A typical example is when the entity id in the database entity is numeric, a 64-bit integer (BIGINT), but the domain entity has it as a string so that it can be used by any client (including JavaScript, where the number type is
less than 64-bit).
You often benefit from creating separate entity classes for a repository and the domain model. You might want to store domain entities in a database in a slightly different format. In that case, you
must define separate entity classes for the domain and the repository. You can name database-related entities with a Db-prefix, e.g., `DbSalesItem`.
In the `DbSalesItem` class, you need two conversion methods: from a domain entity and to a domain entity:

```java
DbSalesItem.from(domainEntity)
// For example
DbSalesItem.from(salesItem)

salesItem = dbSalesItem.toDomainEntity()
```

If you need to change your database, you can end up having mixed format ids (e.g., from a relational database with BIGINT ids to a MongoDB with string-format ObjectIds). If you want uniform unique ids, you must generate them
in your software component, not by the database. This might be a good approach also from the security point of view to prevent [IDOR](https://cheatsheetseries.owasp.org/cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html).
If you generate random UUIDs in your application, and you have accidentally broken authorization (IDOR), it is not possible for an attacker to guess UUIDs and try to access other users' resources using them.

Below is an example of a `DbSalesItem` entity class:

{title: DbSalesItem.java"}
```java
@Entity
public class DbSalesItem {
  private Long id;
  private String name;
  private Integer price;
}
```

Store `DbSalesItem` entities in a table named `salesitems`. In this book, I write all identifiers in lowercase. The case sensitivity of a database
depends on the database and the operating system it is running on. For example, MySQL is case-sensitive only on Linux
systems.

The properties of an entity map to columns of the entity table, meaning that the `salesitems` table has
the following columns:

- id
- name
- price

Each entity table must have a primary key defined. The primary key must be unique for each row in the table.
In the example below, we use the `@Id` annotation to define the `id` column as the primary key containing
a unique value for each row. The `@GeneratedValue` annotation states that the database should automatically generate
a value for the `id` column using the supplied strategy.

{title: "DbSalesItem.java"}
```java
@Entity
@Table(name = "salesitems")
public class DbSalesItem {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  private String name;
  private Integer price;
}
```

ORM can create database tables according to entity specifications in code. Below is
an example SQL statement for PostgreSQL that an ORM generates to create a table for storing `SalesItem` entities:

```sql
CREATE TABLE salesitems (
  id BIGINT GENERATED ALWAYS AS IDENTITY,
  name TEXT,
  price INTEGER,
  PRIMARY KEY (id)
);
```

A table's columns can be specified as containing unique or non-nullable values. By default, a column can contain nullable values, which need not be unique.
Below is an example where we define that the `name` column in the `salesitems` table cannot have null values, and values
must be unique. We don't want to store sales items with null names, and we want to store sales items with unique names.

{title: "DbSalesItem.java"}
```java
@Entity
@Table(name = "salesitems")
public class DbSalesItem {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  @Column(unique=true, nullable=false)
  private String name;

  private Integer price;
}
```

When you have a `DbSalesItem` entity, you can persist it with an instance of JPA's `EntityManager`:

```java
entityManager.persist(dbSalesItem);
```

JPA will generate the needed SQL statement and execute it on your behalf.
Below is an example SQL statement generated by the ORM to persist a sales item (Remember that the database autogenerates the `id` column).

```sql
INSERT INTO salesitems (name, price)
VALUES ('Sample sales item', 10);
```

You can search for the created sales item in the database (assuming here that we have a `getId` getter defined):

```java
entityManager.find(DbSalesItem.class, salesItem.getId());
```

For the above operation, the ORM will generate the following SQL query:

```sql
SELECT id, name, price FROM salesitems WHERE id = 1;
```

Then, you can modify the entity and merge it with the entity manager to update the database:

```java
dbSalesItem.setPrice(20);
entityManager.merge(dbSalesItem);
```

Finally, you can delete the sales item with the entity manager:

```java
entityManager.remove(dbSalesItem);
```

The ORM will execute the following SQL statement:

```sql
DELETE FROM salesitems WHERE id = 1;
```

Suppose your microservice executes SQL queries that do not include the primary key column in the
query's WHERE clause. In that case, the database engine must perform a full table scan to find the wanted rows. Let's say
you want to query sales items, the price of which is less than 10. This can be achieved with
the below query:

```java
// final var price = ...

final TypedQuery<DbSalesItem> dbSalesItemsQuery = entityManager
 .createQuery("SELECT s FROM salesitems s WHERE s.price < :price",
              DbSalesItem.class);

dbSalesItemsQuery.setParameter("price", price);

final List<DbSalesItem> dbSalesItems = dbSalesItemsQuery.getResultList();
```

The database engine must perform a full table scan to find all the sales items where the `price` column has
a value below the `price` variable's value. If the database is large, this can be slow. If you
perform the above query often, you should optimize those queries by creating an index. For the above
query to be fast, we must create an index for the `price` column using the `@Index` annotation inside the
`@Table` annotation:

{title: "DbSalesItem.java"}
```java
@Entity
@Table(
  name = "salesitems",
  indexes = @Index(columnList = "price")
)
public class DbSalesItem {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  @Column(unique=true, nullable=false)
  private String name;

  private Integer price;
}
```

#### Entity/Table Relationships

Tables in a relational database can have relationships with other tables. There are three types of relationships:

- One-to-one
- One-to-many
- Many-to-many

##### One-To-One/Many Relationships

In this section, we focus on one-to-one and one-to-many relationships. In a one-to-one relationship, a single row in a table can
have a relationship with another row in another table. In a one-to-many relationship, a single row in a table can
have a relationship with multiple rows in another table.

Let's have an example with an *order-service* that can store orders in a database. Each order consists of one
or more order items. An order item contains information about the bought sales item.

```java
@Entity
@Table(name = "orders")
public class DbOrder {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  // Other order fields ...

  @OneToMany(mappedBy="order")
  private List<DbOrderItem> orderItems;
}

@Entity
@Table(name = "orderitems")
public class DbOrderItem {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  @OneToOne
  @JoinColumn(name = "salesitemid")
  private DbSalesItem salesItem;

  @ManyToOne
  @JoinColumn(name = "orderid", nullable = false)
  private DbOrder dbOrder;
}
```

Orders are stored in the `orders` table, and order items
are stored in the `orderitems` table, which contains a join column named `orderid`. Using this join column, we can map a particular
order item to a specific order. Each order item maps to precisely one sales item. For this reason, the `orderitems` table
also contains a join column named `salesitemid`. Using this join column, we can map an order item to a sales item.

Below is the SQL statement generated by the ORM for creating the `orderitems` table. The one-to-one and one-to-many relationships
are reflected in the foreign key constraints:

- `fksalesitem`: a `salesitemid` column value in the `orderitems` table references an `id` column value in the `salesitems` table
- `fkorder`: an `orderid` column value in the `orderitems` table references an `id` column value in the `orders` table

```sql
CREATE TABLE orderitems (
  id BIGINT GENERATED ALWAYS AS IDENTITY,
  salesitemid BIGINT,
  orderid BIGINT,
  CONSTRAINT fksalesitem FOREIGN KEY (salesitemid)
    REFERENCES salesitems(id),
  CONSTRAINT fkorder FOREIGN KEY (orderid)
    REFERENCES orders(id)
);
```

The following SQL query is executed by the ORM to fetch the order with id 123 and its order items:

```sql
SELECT o.id, s.name, ...
FROM orders o
LEFT JOIN orderitems oi ON o.id = oi.orderid
LEFT JOIN salesitems s ON s.id = oi.salesitemid
WHERE o.id = 123;
```

##### Many-To-Many Relationships

In a many-to-many relationship, one entity has a relationship with many entities of another type, and those entities have
a relationship with many entities of the first entity type. For example, a student can attend many courses, and a course can have numerous students attending it.

Suppose we have a service that stores student and course entities in a database. Each student entity contains the courses the student has
attended. Similarly, each course entity contains a list of students that have attended the course. We have a many-to-many relationship where
one student can attend multiple courses, and multiple students can attend one course. This means an additional [association/associative table](https://en.wikipedia.org/wiki/Associative_entity),
`studentcourse,` must be created.
This new table maps a particular student to a particular course.

```java
@Entity
@Table(name = "students")
class DbStudent {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  // Other Student fields...

  @JoinTable(
    name = "studentcourse",
    joinColumns = @JoinColumn(name = "studentid"),
    inverseJoinColumns = @JoinColumn(name = "courseid")
  )
  @ManyToMany
  private List<DbCourse> attendedCourses;
}

@Entity
@Table(name = "courses")
class DbCourse {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private Long id;

  // Other Course fields...

  @ManyToMany(mappedBy = "attendedCourses")
  private List<DbStudent> students;
}
```

The ORM creates the `students` and `courses` tables in addition to the `studentcourse` mapping table:

```
CREATE TABLE studentcourse (
  studentid BIGINT,
  courseid BIGINT,
  CONSTRAINT fkstudent FOREIGN KEY (studentid)
    REFERENCES students(id),
  CONSTRAINT fkorder FOREIGN KEY (courseid)
    REFERENCES courses(id)
);
```

Below is an example SQL query that the ORM executes to fetch attended courses for the user identified with id 123:

```sql
SELECT s.id, c.id, ...
FROM students s
LEFT JOIN studentcourse sc ON s.id = sc.studentid
LEFT JOIN courses c ON c.id = sc.courseid
WHERE s.id = 123;
```

Below is an example SQL query that the ORM executes to fetch students for the course identified with id 123:

```sql
SELECT c.id, s.id
FROM courses c
LEFT JOIN studentcourse sc ON c.id = sc.courseid
LEFT JOIN students s ON s.id = sc.studentid
WHERE c.id = 123;
```

In real-life scenarios, you don't necessarily have to or should implement many-to-many database relations inside a single microservice.
For example, the above service that handles students and courses is against the *single responsibility principle* on the abstraction
level of courses and students. (However, if we created a *school* microservice on a higher abstraction level, we can have students and courses tables in the same microservice)
If we created a separate microservice for students and a separate microservice for courses, then there wouldn't be
many-to-many relationships between database tables in a single microservice.

#### Sales Item Repository Example

Let's define a `SalesItemRepository` implementation using [TypeORM](https://typeorm.io/) for the *sales-item-service* API defined in the previous chapter.
TypeORM is a popular ORM that can be used with various SQL database engines, including MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, CockroachDB, SAP Hana, and even MongoDB. In the below example, we don't need database transactions because each repository operation is a single atomic operation like `save`, `update`, or `delete`.
You need a transaction if you need to perform multiple database operations to fulfill a repository operation. Consult your ORM documentation to find out
how transactions can be used. In the case of Spring JPA ORM, if your repository extends the `CrudRepository` interface, the repository methods are, by default, transactional. In TypeORM, you need to supply a callback function where you execute database operations:

```js
await myDataSource.transaction(async (transactionalEntityManager) => {
    // execute queries using 'transactionalEntityManager'
})
```

Let's start by defining the `DbSalesItem`, and `DbSalesItemImage` entities:

{title: "DbSalesItem.ts}
```ts
import { Entity, PrimaryGeneratedColumn, Column } from "typeorm"

@Entity()
export default class DbSalesItem {
    @PrimaryGeneratedColumn()
    id: number;

    @Column()
    name: string;

    @Column()
    priceInCents: number;

    @Column()
    images: DbSalesItemImage[];
}
```

{title: "DbSalesItemImage.ts}
```ts
import { Entity, PrimaryGeneratedColumn, Column } from "typeorm"

@Entity()
export default class DbSalesItemImage {
    @Column()
    id: number;

    @Column()
    salesItemId: number

    @Column()
    rank: number

    @Column()
    url: string;
}
```

Below is the implementation of the `TypeOrmSalesItemRepository`:

{title: "TypeOrmSalesItemRepository.ts"}
```ts
export default class TypeOrmSalesItemRepository implement SalesItemRepository {
  constructor(
  )
  {// create repository}


  save(salesItem: SalesItem) -> SalesItem:
    try:
            // Siirrä tämä SalesItem.from factoryyn
            salesItem.createdAtTimestampInMs = (
                time.time_ns() / 1_000_000
            )
            const dbSalesItem = DbSalesItem.from(salesItem);
            return this.repository.save(dbSalesItem);
    except SQLAlchemyError as error:
        raise DatabaseError(error)

    def findAll(self) -> list[SalesItem]:
        try:
            return this.repository.findMany();

        except SQLAlchemyError as error:
            raise DatabaseError(error)

    def find(self, id: str) -> SalesItem | None:
        try:
            return repository.findOne(id);
        except SQLAlchemyError as error:
            raise DatabaseError(error)

    def update(self, id_: str, salesItem: InputSalesItem) -> None:
        try:
                if (!find(id) {
                   raise EntityNotFoundError('Sales item', id_)
                }

                const dbSalesItem = DbSalesItem.from(salesItem);
                this.repository.update(id, dbSalesItem);
        except SQLAlchemyError as error:
            raise DatabaseError(error)

    def delete(self, id_: str) -> None:
        try:
          this.repository.delete(id);
        except SQLAlchemyError as error:
            raise DatabaseError(error)

```

### Use Parameterized SQL Statements Principle

> ***If you are not using an ORM for database access, use parameterized SQL statements to prevent potential SQL injection attacks.***

Let's use Node.js and the [mysql](https://www.npmjs.com/package//mysql) NPM library for parameterized SQL examples. First, let's insert data to the `salesitems` table:

```js
// Create a connection...

connection.query(
  `INSERT INTO salesitems (name, price)
   VALUES (?, ?)`,
  ['Sample sales item', 10]
);
```

The question marks (?) are placeholders for parameters in a parameterized SQL query. The second argument to the `query`
method contains the parameter values. When a database engine receives a parameterized query, it will replace the placeholders
with the supplied parameter values.

Next, we can update a row in the `salesitems` table. The below example changes the price of the sales item with id 123 to 20:

```js
connection.query('UPDATE salesitems SET price = ? WHERE id = ?',
                  [20, 123]);
```

Let's execute a SELECT statement to get sales items with their price over 20:

```js
connection.query(
  'SELECT id, name, price FROM salesitems WHERE price >= ?',
  [20]
);
```
</div>

In an SQL SELECT statement, you cannot use parameters everywhere. You can use them as value placeholders
in the WHERE clause. If you want to use user-supplied data in other parts of an SQL SELECT statement, you
need to use string concatenation. You should not concatenate user-supplied data without sanitation because that
would open up possibilities for SQL injection attacks. Let's say you allow the microservice client to specify a sorting column:

```js
const sortColumn = // Unvalidated data got from client
const sqlQuery =
  'SELECT id, name, price FROM salesitems ORDER BY ' +
  connection.escapeId(sortColumn);

connection.query(sqlQuery);
```

As shown above, you need to escape the `sortColumn` value so that it contains only valid characters
for a MySQL column name. If you need to get the sorting direction from the client, you should validate
that value as either `ASC` or `DESC`. In the below example, we assume that a `validateSortDirection` function
exists:

```js
const sortColumn = // Unvalidated data got from client
const sortDirection = // Unvalidated data got from client

// throws if invalid sorting direction
const validatedSortDirection =
  validateSortDirection(sortDirection);

const sqlQuery = `
  SELECT id, name, price
  FROM salesitems
  ORDER BY
  ${connection.escapeId(sortColumn)}
  ${validatedSortDirection}
`;

connection.query(sqlQuery);
```

When you get values for a MySQL query's `LIMIT` clause from a client, you must validate that those values are
integers and in a valid range. Don't allow the client to supply random, very large values. In the example below, we assume
two validation functions exist: `validateRowOffset` and `validateRowCount`. The validation functions will throw if
validation fails.

```js
const rowOffset = // Unvalidated data got from client
const rowCount = // Unvalidated data got from client

const validatedRowOffset = validateRowOffset(rowOffset);
const validatedRowCount = validateRowCount(rowCount);

const sqlQuery = `
  SELECT id, name, price
  FROM salesitems
  LIMIT ${validatedRowOffset}, ${validatedRowCount}
`;

connection.query(sqlQuery);
```

When you get a list of wanted column names from a client, you must validate that each of them is a valid column identifier:

```js
const columnNames = // Unvalidated data got from client

const escapedColumnNames =
  columnNames.map(columnName => connection.escapedId(columnName));

const sqlQuery =
  `SELECT ${escapedColumnNames.join(', ')} FROM salesitems`;

connection.query(sqlQuery);
```

#### Sales Item Repository Example

Let's implement the `SalesItemRepository` for the *sales-item-service* API from the previous chapter using parameterized SQL:

{title: "ParamSqlSalesItemRepository.ts"}
```ts
class ParamSqlSalesItemRepository(SalesItemRepository):
    def __init__(self):
        try:
            self.__conn_config = self.__try_create_conn_config()
            self.__try_create_db_tables_if_needed()
             const pool = mysql.createPool({ database: test });
        except Exception as error:
            # Log error
            raise (error)

    def save(self, input_sales_item: InputSalesItem) -> SalesItem:
        try:
           pool.getConnection(function(err, connection) {

            sql_statement = (
                'INSERT INTO salesitems'
                '(createdAtTimestampInMs, name, priceInCents)'
                ' VALUES (%s, %s, %s)'
            )

            // Move this to SalesItem.from factory method
            created_at_timestamp_in_ms = time.time_ns() / 1_000_000
            connection.beginTransaction();
            const [rows] = connection.execute(
                sql_statement,
                (
                    created_at_timestamp_in_ms,
                    input_sales_item.name,
                    input_sales_item.priceInCents,
                ),
            )

            id_ = rows.insertedId

            self.__try_insert_sales_item_images(
                id_, input_sales_item.images, cursor
            )

            connection.commit()


            return SalesItem(
                **to_entity_dict(input_sales_item),
                id=id_,
                createdAtTimestampInMs=created_at_timestamp_in_ms,
            )
        except Error as error:
            raise DatabaseError(error)
        finally:
             connection.release()

    def find_all(self) -> list[SalesItem]:
        try:
            sql_statement = (
                'SELECT s.id, s.createdAtTimestampInMs, s.name, s.priceInCents,'
                'si.id, si.rank, si.url '
                'FROM salesitems s '
                'LEFT JOIN salesitemimages si ON si.salesItemId = s.id'
            )

            const [rows] = pool.execute(sql_statement)
            return self.__get_sales_item_entities(rows)
        except Error as error:
            print(error)
            raise DatabaseError(error)

    def find(self, id_: str) -> SalesItem | None:
        if not id_.isnumeric():
            raise EntityNotFoundError('Sales item', id_)

        try:
            sql_statement = (
                'SELECT s.id, s.createdAtTimestampInMs, s.name, s.priceInCents,'
                'si.id, si.rank, si.url '
                'FROM salesitems s '
                'LEFT JOIN salesitemimages si ON si.salesItemId = s.id '
                'WHERE s.id = %s'
            )

            const [rows] = pool.execute(sql_statement, (id_,))

            sales_item_entities = self.__get_sales_item_entities(rows)
            return sales_item_entities[0] if sales_item_entities else None
        except Error as error:
            raise DatabaseError(error)

    def update(self, id_: str, sales_item_update: InputSalesItem) -> None:
        if not id_.isnumeric():
            raise EntityNotFoundError('Sales item', id_)

      pool.getConnection(function(err, connection) {
        try:
           connection.beginTransaction
            sql_statement = (
                'UPDATE salesitems SET name = %s, priceInCents = %s '
                'WHERE id = %s'
            )

            conection.execute(
                sql_statement,
                (
                    sales_item_update.name,
                    sales_item_update.priceInCents,
                    id_,
                ),
            )

            sql_statement = (
                'DELETE FROM salesitemimages WHERE salesItemId = %s'
            )

            connection.execute(sql_statement, (id_,))

            self.__try_insert_sales_item_images(
                id_, sales_item_update.images, cursor
            )

            connection.commit()
        except Error as error:
            raise DatabaseError(error)
        finally:
            if connection:
                connection.close()

    def delete(self, id_: str) -> None:
        if not id_.isnumeric():
            return

         pool.getConnection(function(err, connection) {
        try:
            connection.beginTransaction()
            sql_statement = (
                'DELETE FROM salesitemimages WHERE salesItemId = %s'
            )

            connection.execute(sql_statement, (id_,))
            sql_statement = 'DELETE FROM salesitems WHERE id = %s'
            connection.execute(sql_statement, (id_,))
            connection.commit()
        except Error as error:
            raise DatabaseError(error)
        finally:
            if connection.is_connected():
                connection.close()

    @staticmethod
    def __try_create_conn_config() -> dict[str, Any]:
        database_url = os.environ.get('DATABASE_URL')

        user_and_password = (
            database_url.split('@')[0].split('//')[1].split(':')
        )

        host_and_port = database_url.split('@')[1].split('/')[0].split(':')
        database = database_url.split('/')[3]

        return {
            'user': user_and_password[0],
            'password': user_and_password[1],
            'host': host_and_port[0],
            'port': host_and_port[1],
            'database': database,
            'pool_name': 'salesitems',
            'pool_size': 25,
        }

    def __try_create_db_tables_if_needed(self) -> None:
        connection = connect(**self.__conn_config)
        cursor = connection.cursor()

        sql_statement = (
            'CREATE TABLE IF NOT EXISTS salesitems ('
            'id BIGINT NOT NULL AUTO_INCREMENT,'
            'createdAtTimestampInMs BIGINT NOT NULL,'
            'name VARCHAR(256) NOT NULL,'
            'priceInCents INTEGER NOT NULL,'
            'PRIMARY KEY (id)'
            ')'
        )

        cursor.execute(sql_statement)

        sql_statement = (
            'CREATE TABLE IF NOT EXISTS salesitemimages ('
            'id BIGINT NOT NULL,'
            '`rank` INTEGER NOT NULL,'
            'url VARCHAR(2084) NOT NULL,'
            'salesItemId BIGINT NOT NULL,'
            'PRIMARY KEY (salesItemId, id),'
            'FOREIGN KEY (salesItemId) REFERENCES salesitems(id)'
            ')'
        )

        cursor.execute(sql_statement)
        connection.commit()
        connection.close()

    def __try_insert_sales_item_images(
        self, sales_item_id: str | int, images, cursor
    ):
        for image in images:
            sql_statement = (
                'INSERT INTO salesitemimages'
                '(id, `rank`, url, salesItemId)'
                'VALUES (%s, %s, %s, %s)'
            )

            cursor.execute(
                sql_statement,
                (image.id, image.rank, image.url, sales_item_id),
            )

    def __get_sales_item_entities(self, cursor):
        id_to_sales_item_dict = {}

        for (
            id_,
            created_at_timestamp_in_ms,
            name,
            price_in_cents,
            image_id,
            image_rank,
            image_url,
        ) in cursor:
            if id_to_sales_item_dict.get(id_) is None:
                id_to_sales_item_dict[id_] = {
                    'id': id_,
                    'createdAtTimestampInMs': created_at_timestamp_in_ms,
                    'name': name,
                    'priceInCents': price_in_cents,
                    'images': [],
                }

            if image_id is not None:
                id_to_sales_item_dict[id_]['images'].append(
                    SalesItemImage(
                        id=image_id, rank=image_rank, url=image_url
                    )
                )

        return [
            SalesItem(**sales_item_dict)
            for sales_item_dict in id_to_sales_item_dict.values()
        ]
```

### Normalization Rules

> ***Apply normalization rules to your database design.***

Below are listed the three most basic [database normalization rules](https://en.wikipedia.org/wiki/Database_normalization):

- First normal form (1NF)
- Second normal form (2NF)
- Third normal form (3NF)

A database relation is often described as "normalized" if it meets the first, second, and third normal forms.

#### First Normal Form (1NF)

The first normal form requires that a single value exists at every intersection of a row and column, never a list of values.
When considering a sales item, the first normal form states that there cannot be two different price values in
the `price` column or more than one name for the sales item in the `name` column. If you need multiple names for a sales item, you
must establish a one-to-many relationship between a `SalesItem` entity and `SalesItemName` entities. What this means in practice
is that you remove the `name` property from the `SalesItem` entity class and create a new `SalesItemName` entity class used to
store sales items' names. Then, you create a one-to-many mapping between a `SalesItem` entity and `SalesItemName` entities.

#### Second Normal Form (2NF)

The second normal form requires that each non-key column entirely depends on the primary key. Let's assume that we have the following columns in an `orderitems` table:

- `orderid` (primary key)
- `productid` (primary key)
- `orderstate`

The `orderstate` column only depends on the `orderid` column, not the entire primary key. The `orderstate` column is in the wrong table.
It should, of course, be in the `orders` table.

#### Third Normal Form (3NF)

The third normal form requires that non-key columns are independent of each other.

Let's assume that we have the following columns in a `salesitems` table:

- `id` (primary key)
- `name`
- `price`
- `category`
- `discount`

Let's assume that the discount depends on the category. This table violates the third normal form because a non-key column, `discount`,
depends on another non-key column, `category`. Column independence means that you can change any non-key column value without
affecting any other column. If you changed the category, the discount would need to be changed accordingly, thus violating the third normal form rule.

The discount column should be moved to a new `categories` table with the following columns:

- `id` (primary key)
- `name`
- `discount`

Then we should update the `salesitems` table to contain the following columns:

- `id` (primary key)
- `name`
- `price`
- `categoryid` (a foreign key that references the `id` column in the `categories` table)

## Document Databases

> ***Use a document database in cases where complete documents (e.g., JSON objects) are typically stored and retrieved as a whole.***

Document databases, like [MongoDB](https://www.mongodb.com/), are useful for storing complete documents. A document is usually a JSON object containing
information in arrays and nested objects. Documents are stored as such, and a whole document will be fetched when queried.

Let's consider a microservice for sales items. Each sales item contains an id, name, price, image URLs, and user reviews.

Below is an example sales item as a JSON object:

```json
{
  "id": "507f191e810c19729de860ea",
  "category": "Power tools",
  "name": "Sample sales item",
  "price": 10,
  "imageUrls": ["https://url-to-image-1...",
                "https://url-to-image-2..."],
  "averageRatingInStars": 5,
  "reviews": [
     {
       "reviewerName": "John Doe",
       "date": "2022-09-01",
       "ratingInStars": 5,
       "text": "Such a great product!"
     }
  ]
}
```

A document database usually has a size limit for a single document. Therefore, the above example does not store sales item images
directly inside the document but only URLs for the images. Actual images are stored in another data store more suitable for storing
images, like Amazon S3.

When creating a microservice for sales items, we can choose a document database because we usually store and access whole documents.
When sales items are created, they are created as JSON objects of the above shape with the `reviews` array being empty and `averageRatingInStars` being `null`.
When a sales item is fetched, the whole document is retrieved from the database. When a client
adds a review for a sales item, the sales item is fetched from the database. The new review is appended to the `reviews` array, a new average
rating is calculated, and finally, the document is persisted with the modifications.

Below is an example of inserting one sales item to a MongoDB collection named `salesItems`. MongoDB uses the term _collection_
instead of _table_. A MongoDB collection can store multiple documents.

```js
db.salesItems.insertOne({
  category: "Power tools",
  name: "Sample sales item",
  price: 10,
  images: ["https://url-to-image-1...",
             "https://url-to-image-2..."],
  averageRatingInStars: null,
  reviews: []
})
```

You can find sales items for the _Power tools_ category with the following query:

```js
db.salesItems.find({ category: "Power tools" })
```

If clients are usually querying sales items by category, it is wise to create an index for that field:

```js
// 1 means ascending index, -1 means descending index
db.salesItems.createIndex( { category: 1 } )
```

When a client wants to add a new review for a sales item, you first fetch the document for the sales item:

```js
db.salesItems.find({ _id: ObjectId("507f191e810c19729de860ea") })
```

Then you calculate a new value for the `averageRatingInStars` field using the existing ratings and the new rating
and add the new review to the `reviews` array and then update the document with the following command:

```js
db.salesItems.updateOne(
  { _id: ObjectId("507f191e810c19729de860ea")  },
  { $set: {averageRatingInStars: 5},
    $push: { reviews: {
      reviewerName: "John Doe",
      date: "2022-09-01",
      ratingInStars: 5,
      text: "Such a great product!"
    }}
  }
)
```

Clients may want to retrieve sales items sorted descending by the average rating. For this reason, you might want
to change the indexing to be the following:

```js
db.salesItems.createIndex( { category: 1, averageStarCount: -1 } )
```

A client can issue, for example, a request to get the best-rated sales items in the _power tools_ category.
This request can be fulfilled with the following query that utilizes the above-created index:

```js
db.salesItems
  .find({ category: "Power tools" })
  .sort({ averageStarCount: -1 })
```

### Sales Item Repository Example

Let's implement the `SalesItemRepository` for the *sales-item-service* API from the previous chapter using MongoDB:

{title: "MongoDbSalesItemRepository.ts"}
```ts
export default class MongoDbSalesItemRepository implements SalesItemRepository {
    def __init__(self):
        try:
            database_url = os.environ.get('DATABASE_URL')
            self.__client = MongoClient(database_url)
            database_name = database_url.split('/')[3]
            database = self.__client[database_name]
            self.__sales_items = database['salesitems']
        except Exception as error:
            # Log error
            raise (error)

    def save(self, input_sales_item: InputSalesItem) -> SalesItem:
        try:
            sales_item = input_sales_item.dict() | {
                'createdAtTimestampInMs': time.time_ns() / 1_000_000
            }

            self.__sales_items.insert_one(sales_item)
            return self.__create_sales_item_entity(sales_item)

        except PyMongoError as error:
            raise DatabaseError(error)

    def find_all(self) -> list[SalesItem]:
        try:
            sales_items = self.__sales_items.find()
            return [
                self.__create_sales_item_entity(sales_item)
                for sales_item in sales_items
            ]
        except PyMongoError as error:
            raise DatabaseError(error)

    def find(self, id_: str) -> SalesItem | None:
        try:
            sales_item = self.__sales_items.find_one(
                {'_id': ObjectId(id_)}
            )

            return (
                None
                if sales_item is None
                else self.__create_sales_item_entity(sales_item)
            )
        except InvalidId:
            raise EntityNotFoundError('Sales item', id_)
        except (BSONError, PyMongoError) as error:
            raise DatabaseError(error)

    def update(self, id_: str, sales_item_update: InputSalesItem) -> None:
        try:
            self.__sales_items.update_one(
                {'_id': ObjectId(id_)}, {'$set': sales_item_update.dict()}
            )
        except InvalidId:
            raise EntityNotFoundError('Sales item', id_)
        except (BSONError, PyMongoError) as error:
            raise DatabaseError(error)

    def delete(self, id_: str) -> None:
        try:
            self.__sales_items.delete_one({'_id': ObjectId(id_)})
        except InvalidId:
            pass
        except (BSONError, PyMongoError) as error:
            raise DatabaseError(error)

    def __create_sales_item_entity(sales_item: dict[str, Any]):
        id_ = sales_item['_id']
        del sales_item['_id']

        images = [
            SalesItemImage(**image) for image in sales_item['images']
        ]

        return SalesItem(
            **(sales_item | {'id': str(id_)} | {'images': images})
        )
 }
```

## Key-Value Database Principle

> ***Use a key-value database for fast real-time access to data stored by a key. Key-value stores usually store data in memory with a possibility for persistence.***

A simple use case for a key-value database is to use it as a cache for a relational database. For example, a microservice can store SQL query results
from a relational database in the cache. _Redis_ is a popular open-source key-value store. Let's have an example with JavaScript and Redis
to cache an SQL query result. In the below example, we assume that the SQL query result is available as a JavaScript object:

```js
redisClient.set(sqlQueryStatement,
                JSON.stringify(sqlQueryResult));
```

The cached SQL query result can be fetched from Redis:

```js
const sqlQueryResultJson = redisClient.get(sqlQueryStatement);
```

With Redis, you can create key-value pairs that expire automatically after a specific time.
This is a useful feature if you are using the key-value database as a cache. You may want the cached items to expire after a while.

In addition to plain strings, Redis also supports other data structures. For example, you
can store a list, queue, or hash map for a key. If you store a queue in Redis, you can
use it as a simple single-consumer message broker. Below is an example of producing a
message to a topic in the message broker:

```js
// RPUSH command (= right push) pushes a new message
// to the end of the list identified by key _topic_.
redisClient.rpush(topic, message);
```

Below is an example of consuming a message from a topic in the message broker:

```js
// LPOP command (= left pop) pops a message from
// the beginning of the list identified by key _topic_
// The LPOP command removes the value from the list
const message = redisClient.lpop(topic);
```

## Wide-Column Databases

> ***Use a wide-column database when you have a large amount of data and know what queries you need to execute, and you want these queries to be fast.***

Table structures of a wide-column database are optimized for specific queries.
With a wide-column database, storing duplicate data is okay to make the queries
faster. Wide-column databases also scale horizontally well, making them suitable for storing a large amount of data.

This section uses [Apache Cassandra](https://cassandra.apache.org/_/index.html) as an example wide-column database. Cassandra is
a scalable multi-node database engine. In Cassandra, the data of a table is divided into
partitions according to the table's [partition key](https://www.baeldung.com/cassandra-keys). A partition key is composed of one or more
columns of the table. Each partition is stored on a single Cassandra node. You can think that Cassandra is a key-value store where the key is the partition key, and the value is another
"nested" table. The rows in the "nested" table are uniquely identified by clustering columns sorted by default in ascending order. The sort order can be changed to descending if wanted.

The partition key and the clustering columns form the table's primary key. The primary key uniquely
identifies a row. The order of these components always puts the partition key first and then the clustering columns (or clustering key).
Let's have an example table that is used to store hotels near a particular point of interest (POI):

```cql
CREATE TABLE hotels_by_poi (
  poi_name text,
  hotel_distance_in_meters_from_poi int,
  hotel_id uuid,
  hotel_name text,
  hotel_address text,
  PRIMARY KEY (poi_name, hotel_distance_in_meters_from_poi, hotel_id)
);
```

In the above example, the primary key consists of three columns. The first column (`poi_name`) is always the partition key.
The partition key must be given in a query. Otherwise, the query will be slow because Cassandra must perform a full table
scan because it does not know which node data is located. When the partition key is given in a SELECT
statement's WHERE clause, Cassandra can find the appropriate node where the data for that particular partition resides. The two other primary key columns, `hotel_distance_in_meters_from_poi` and `hotel_id`, are the clustering columns. They define the order and uniqueness of the rows in the "nested" table.

![hotels_by_poi Table](resources/chapter7/images/03-01.png)

The above figure shows that when you give a partition key value (`poi_name`), you have access to the
respective "nested" table where rows are ordered first by the `hotel_distance_in_meters_from_poi` (ascending)
and second by the `hotel_id` (ascending).

Now, it is easy for a hotel room booking client to ask the server to execute a query to find hotels near a POI given
by a user. The following query will return the first 15 hotels nearest to *Piccadilly Circus* POI:

```cql
SELECT
  hotel_distance_in_meters_from_poi,
  hotel_id,
  hotel_name,
  hotel_address
FROM hotels_by_poi
WHERE poi_name = 'Piccadilly Circus'
LIMIT 15
```

When a user selects a particular hotel from the result of the above query, the client can request the execution of
another query to fetch information about the selected hotel. The user wants to see
other POIs near the selected hotel. For that query, we should create another table:

```cql
CREATE TABLE pois_by_hotel_id (
  hotel_id uuid,
  poi_distance_in_meters_from_hotel int,
  poi_id uuid,
  poi_name text,
  poi_address text,
  PRIMARY KEY (hotel_id, poi_distance_in_meters_from_hotel, poi_id)
);
```

Now, a client can request the server to execute a query to fetch the nearest 20 POIs for a selected hotel.
(hotel with id c5a49cb0-8d98-47e3-8767-c30bc075e529):

```cql
SELECT
  poi_distance_in_meters_from_hotel,
  poi_id,
  poi_name,
  poi_address
FROM pois_by_hotel_id
WHERE hotel_id = c5a49cb0-8d98-47e3-8767-c30bc075e529
LIMIT 20
```

In a real-life scenario, a user wants to search for hotels near a particular POI for a selected period. The server should respond with the nearest hotels having free rooms for the selected period.
For that kind of query, we can create an additional table for storing hotel room availability:

```cql
CREATE TABLE availability_by_hotel_id (
  hotel_id uuid,
  accommodation_date date,
  available_room_count counter,
  PRIMARY KEY (hotel_id, accommodation_date)
);
```

The above table is updated whenever a room for a specific day is booked, or a booking for a room
is canceled. The `available_room_count` column value is either decremented or incremented by one in the update procedure.

Let's say that the following query has been executed:

```cql
SELECT
  hotel_distance_in_meters_from_poi,
  hotel_id,
  hotel_name,
  hotel_address
FROM hotels_by_poi
WHERE poi_name = 'Piccadilly Circus'
LIMIT 30
```

Next, we should find hotels from the result of 30 hotels that have available rooms between the 1st of September
2023 and 3rd of September 2023. We cannot use joins in Cassandra, but we can execute the following query where we specifically list the hotel ids returned by the above query:

```cql
SELECT hotel_id, MIN(available_room_count)
FROM availability_by_hotel_id
WHERE hotel_id IN (List the 30 hotel_ids here...) AND
      accommodation_date >= '2022-09-01' AND
      accommodation_date <= '2022-09-03'
GROUP BY hotel_id
LIMIT 15
```

As a result of the above query, we have a list of a maximum of 15 hotels for which the minimum available room count is listed.
We can return a list of those maximum 15 hotels where the minimum available room count is one or more to the user.

If Cassandra's query language supported the `HAVING` clause, which it does not currently support,
we could have issued the following query to get what we wanted:

```cql
SELECT hotel_id, MIN(available_room_count)
FROM availability_by_hotel_id
WHERE hotel_id IN (List the 30 hotel_ids here...) AND
      accommodation_date >= '2022-09-01' AND
      accommodation_date <= '2022-09-03'
GROUP BY hotel_id
HAVING MIN(available_room_count) >= 1
LIMIT 15
```

A wide-column database is also useful for storing time-series data, e.g., from IoT devices and sensors. Below is a table definition
for storing measurement data in a telecom network analytics system:

```cql
CREATE TABLE measurements (
  measure_name text,
  dimension_name text,
  aggregation_period text,
  measure_timestamp timestamp,
  measure_value double,
  dimension_value text,
  PRIMARY KEY ((measure_name, dimension_name, aggregation_period),
               measure_timestamp,
               measure_value,
               dimension_value)
) WITH CLUSTERING ORDER BY (
  measure_timestamp DESC,
  measure_value DESC
  dimension_value ASC
);
```

In the above table, we have defined a *compound partition key* containing three columns: `measure_name`,
`dimension_name`, and `aggregation_period`. Columns for a compound partition key are given in parentheses because the first column of the primary key is always the partition key.

Suppose we have implemented a client that visualizes measurements. In the client, a user can first choose what
counter/KPI (= measure name) to visualize, then select a dimension and aggregation period. Let's say that the user wants
to see *dropped_call_percentage* for *cells* calculated for one minute at 2023-02-03 16:00. The following kind of
query can be executed:

```cql
SELECT measure_value, dimension_value
FROM measurements
WHERE measure_name = 'dropped_call_percentage' AND
      dimension_name = 'cell' AND
      aggregation_period = '1min' AND
      measureTimestamp = '2022-02-03T16:00+0000'
LIMIT 50;
```

The above query returns the top 50 cells with the highest dropped call percentage for the given minute.

We can create another table to hold measurements for a selected dimension value, e.g., for a particular cell id. This table can be used to
drill down to a particular dimension and see measure values in the history.

```cql
CREATE TABLE measurements_by_dimension (
  measure_name text,
  dimension_name text,
  aggregation_period text,
  dimension_value text,
  measure_timestamp timestamp,
  measure_value double,
  PRIMARY KEY ((measure_name,
                dimension_name,
                aggregation_period,
                dimension_value), measure_timestamp)
) WITH CLUSTERING ORDER BY (measureTimestamp DESC);
```

The below query will return dropped call percentage values for the last 30 minutes for the cell identified by
*cell id* 3000:

```cql
SELECT measure_value, measureTimestamp
FROM measurements_by_dimension
WHERE measure_name = 'dropped_call_percentage' AND
      dimension_name = 'cell' AND
      aggregation_period = '1min' AND
      dimension_value = '3000'
LIMIT 30;
```

## Search Engines

> ***Use a search engine if you have free-form text data that users should be able to query.***

A search engine (like [Elasticsearch](https://www.elastic.co/elasticsearch)) is useful for storing information like log entries collected
from microservices. You typically want to search the collected log data by the text in the log messages.

It is not necessary to use a search engine when you need to search for text data. Other databases, both document and relational,
have a special index type that can index free-form text data in a column. Considering the earlier example with MongoDB,
we might want a client to be able to search sales items by the text in the sales item's name. We don't need to store sales items in a search engine database. We can continue storing them in a document database
(MongoDB) and introduce a *text* type index for the `name` field. That index can be created with
the following MongoDB command:

```python
sales_items.create_index( { 'name': 'text' } )
```

