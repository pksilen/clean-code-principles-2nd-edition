# API Design Principles

This chapter presents design principles for both frontend-facing and inter-microservice APIs. First, frontend-facing API design
is discussed, and then inter-microservice API design is covered.

## Frontend Facing API Design Principles

Most frontend-facing APIs should be HTTP-based JSON-based RPC, REST, or GraphQL APIs. Use GraphQL especially
when the API handles heavily nested resources or clients want to decide what fields queries should return.
For subscription-based APIs, use Server-Sent Events (SSE) or GraphQL subscriptions, and for real-time bidirectional
communication, use WebSocket. If you transfer a lot of data or binary data between the frontend and backend, consider implementing the API using gRPC and [gRPC Web](https://github.com/grpc/grpc-web).
gRPC Web is not covered in this book. gRPC uses Protocol Buffers to binary encode data and is thus more efficient than JSON encoding.

### JSON-based RPC API Design Principle

> ***Design a JSON-based RPC API to perform a single action (procedure) for an API endpoint.***

As the name suggests, JSON-based RPC APIs are for executing remote procedure calls using JSON-encoded payloads. The remote procedure
argument is a JSON object in the HTTP request body. The remote procedure return value is a JSON object in the HTTP response body.
A client calls a remote procedure by issuing an HTTP POST request where it specifies the procedure's name in the URL path
and gives the argument for the remote procedure call in the request body in JSON.

Below is an example request for a translation service's *translate* procedure:

```http
POST /translation-service/translate HTTP/1.1
Content-Type: application/json

{
  "text": "Ich liebe dich"
  "fromLanguage": "German",
  "toLanguage": "English"
}
```

The API server shall respond with an HTTP status code and include the procedure's response in the HTTP
response body in JSON.

For the above request, you get the following response:

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "translatedText": "I love you"
}
```

{aside}
A [JSON-RPC specification](https://www.jsonrpc.org/specification) exists that defines one way to create JSON-based RPC APIs.
I do not follow that specification in the examples below because there are many ways to create a JSON-based RPC API.
But as an example, the above example rewritten using the *JSON-RPC specification* would look like the following:

```http
POST /translation-service HTTP/1.1
Content-Type: application/json

{
  "jsonrpc": "2.0",
  "method": "translate",
  "params": {
    "text": "Ich liebe dich"
    "fromLanguage": "German",
    "toLanguage": "English"
  }
  "id": 1
}
```

And the response would look like as follows:

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "jsonrpc": "2.0",
  "result": "I love you",
  "id": 1
}
```
{/aside}

Let's have another example with a *web-page-search-service*:

```http
POST /web-page-search-service/search-web-pages HTTP/1.1
Content-Type: application/json

{
  "containingText": "Software design patterns"
}
```

The response could look like as follows:

```http
HTTP/1.1 200 OK
Content-Type: application/json

[
  {
    "url": "https://...",
    "title": "...",
    "date": "...",
    "contentExcerpt": "..."
  },
  More results here ...
]
```

You can create a complete service using JSON-based RPC instead of REST or GraphQL. Below are five remote procedures
defined for a *sales-item-service*. The procedures are for basic CRUD operations.
The benefit of using JSON-based RPC instead of REST, GraphQL, or gRPC is that you don't have to learn or use conventions of any specific technology.

```http
POST /sales-item-service/create-sales-item HTTP/1.1
Content-Type: application/json

{
  "name": "Sample sales item",
  "price": 20
}
```

```http
POST /sales-item-service/get-sales-items HTTP/1.1
```

```http
POST /sales-item-service/get-sales-item-by-id HTTP/1.1
Content-Type: application/json

{
  "id": 1
}
```

```http
POST /sales-item-service/update-sales-item HTTP/1.1
Content-Type: application/json

{
  "id": 1,
  "name": "Sample sales item name modified",
  "price": 30
}
```

```http
POST /sales-item-service/delete-sales-item-by-id HTTP/1.1
Content-Type: application/json

{
  "id": 1
}
```

```http
POST /sales-item-service/delete-sales-items HTTP/1.1
```

You can easily create a controller for the above service. Below is an example of such a controller with one remote procedure defined:

{title: "SalesItemController.java"}
```java
@RestController
public class SalesItemController {
  @Autowired
  private SalesItemService salesItemService;

  @PostMapping("/create-sales-tem")
  @ResponseStatus(HttpStatus.CREATED)
  public final SalesItem createSalesItem(
    @RequestBody final InputSalesItem inputSalesItem
  ) {
    return salesItemService.createSalesItem(inputSalesItem);
  }

  // Rest of the methods ...
}
```

You can version your API by adding a version number to the URL. In the below example, the
new API version 2 allows a new procedure argument `someNewParam` to be supplied for the `search-web-pages` procedure.

```http
POST /web-page-search-service/v2/search-web-pages HTTP/1.1
Content-Type: application/json

{
  "containingText": "Software design patterns"
  "someNewParam": "..."
}
```

### REST API Design Principle

> ***Design a REST API for interaction with a resource (or resources) using CRUD (create, read, update, delete)***
> ***operations.***

Many APIs fall into the category of performing CRUD operations on resources. Let's create an example REST API called *sales-item-service*
for performing CRUD operations on sales items. You can also define non-CRUD endpoints for a REST API. For example, you can define some JSON-based RPC endpoints
if needed.

You can also remodel an RPC-style API to support CRUD operations. For example, suppose you need to create an API to start and stop some processes.
Instead of creating a JSON-based RPC API with `start-process` and `stop-process` procedures, you can create a CRUD-based REST API where you create a resource to start a process and delete a resource to stop a process, i.e., a process is a resource you can perform CRUD operations on.

#### Creating a Resource

Creating a new resource using a REST API is done by sending an HTTP POST request to the API's resource endpoint.
The API's resource endpoint should be named according to the resources it handles. The resource endpoint name should be a noun
and always given in the plural form, for example, for the *sales-item-service* handling sales items,
the resource endpoint should be *sales-items*, and for an *order-service* handling orders, the resource endpoint should be called *orders*.

You give the resource to be created in the HTTP request body in JSON. To create a new sales item, you can issue the following request:

```http
POST /sales-item-service/sales-items HTTP/1.1
Content-Type: application/json

{
  "name": "Sample sales item",
  "price": 20
}
```

The server will respond with the HTTP status code 201 *Created*. The server can add properties to the resource upon
creation. Typically, the server will add an `id` property to the created resource but can also add other
properties. The server will respond with the created resource in the HTTP response body in JSON. Below is a
response to the sales item creation request. You can notice that the server added the `id` property to the resource.
Other properties that are usually added are the creation timestamp and the version of the resource (the version
of a newly created resource should be one).

```http
HTTP/1.1 201 Created
Content-Type: application/json

{
  "id": 1,
  "name": "Sample sales item",
  "price": 20
}
```

If the supplied resource to be created is somehow invalid, the server should respond with the HTTP status code 400 *Bad Request*
and explain the error in the response body. The response body should be in JSON format containing information about the
error, like the error code and message.

To make API error responses consistent, use the same error response format throughout all the APIs in a software
system. Below is an example of an error response:

```json
{
  "statusCode": 500,
  "statusText": "Internal Server Error",
  "endpoint": "POST /sales-item-service/sales-items",
  "timestamp": "2024-03-10T13:31:40+0000",
  "errorCode": "IAMError",
  "errorMessage": "Unable to connect to the Identity and Access Management service"
  "errorDescription": "Describe the error in more detail here, if relevant/needed..."
  "stackTrace": "Call stack trace here..."
}
```

**NOTE!** In the above example, the `stackTrace` property should NOT be included in the production environment by default because
it can reveal internal implementation details to possible attackers. Use it only in development and other internal
environments, and if needed, enable it in the production environment only for a short time to conduct debugging.
The `errorCode` property is useful for updating error counter metric(s). Use it as a label for the error counter(s). There will be more
discussion about metrics in the coming *DevSecOps principles* chapter.

If the created resource is huge, there is no need to return the resource to the caller and waste network
bandwidth. You can return the added properties only. For example, if the server only adds the `id` property, it is
possible to return only the `id` in the response body as follows:

```http
HTTP/1.1 201 Created
Content-Type: application/json

{
  "id": 1
}
```

The request sender can construct the created resource by merging the sent resource object with the received
resource object.

> ***Ensure that no duplicate resources are created.***

When a client tries to create a new resource, the resource creation request may fail so that the
resource was created successfully on the server, but the client did not receive a response on time, and the request failed due to
timeout. From the server's point of view, the request was successful, but from the client's point of view, the request's status was indeterminate.
The client, of course, needs to re-issue the time-outed request, and if it succeeds,
the same resource is created twice on the server side (with two distinct IDs), which is probably unwanted in most cases.

Suppose a resource contains a unique property, like a user's email. In that case, it is impossible
to create a duplicate resource if the server is correctly implemented (= the unique property is marked as a unique column
in the database table definition). In many cases, such a unique field does not exist in the resource.
In those cases, the client can supply a universally unique identifier (UUID), like`creationUuid`.
The role of the server is to check if a resource with the same `creationUuid` was already created and to fail the creation
of a duplicate resource. As an alternative to the UUID approach, the server can ask for
verification from the client if the creation of two identical resources is intended in case the server
receives two identical resources from the same client in a short period of time.

#### Reading Resources

Reading resources with a REST API is done by sending an HTTP GET request to the API's resource endpoint.
To read all sales items, you can issue the following request:

```http
GET /sales-item-service/sales-items HTTP/1.1
```

The server will respond with the HTTP status code 200 *OK* and a JSON array of resources
in the response body or an empty array if none is found. Below is an example response to a request to get the sales items:

```http
HTTP/1.1 200 OK
Content-Type: application/json

[
  {
    "id": 1,
    "name": "Sample sales item",
    "price": 20
  }
]
```

To read a single resource by its id, add the resource's id to the request URL as follows:

```http
GET /sales-item-service/sales-items/<id> HTTP/1.1
```

The following request can be issued to read the sales item identified with id 1:

```http
GET /sales-item-service/sales-items/1 HTTP/1.1
```

The response to the above request will contain a single resource:

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": 1,
  "name": "Sample sales item",
  "price": 20
}
```

The server responds with the HTTP status code 404 *Not Found* if the requested resource is not found.

You can define parameters in the URL [query string](https://en.wikipedia.org/wiki/Query_string) to filter what resources to read.
A query string is the last part of the URL and is separated from the URL path by a question mark (?) character.
A query string can contain one or more parameters separated by ampersand (&) characters.
Each query string parameter has the following format: `<query-parameter-name>=<query-parameter-value>`.
Below is an example request with two query parameters: *name-contains* and *price-greater-than*.

```http
GET /sales-item-service/sales-items?name-contains=Sample&price-greater-than=10 HTTP/1.1
```

The above request gets sales items whose name contains the string *Sample* and whose price is greater
than 10.

To define a filter, you can specify a query parameter in the following format: `<fieldName>[-<condition>]=<value>`, for example:

- `price=10`
- `price-not-equal=10`
- `price-less-than=10`
- `price-less-than-equal=10`
- `price-greater-than=10`
- `price-greater-than-equal=10`
- `name-starts-with=Sample`
- `name-ends-with=item`
- `name-contains=Sample`
- `createdAtTimestamp-before=2022-08-02T05:18:00Z`
- `createdAtTimestamp-after=2022-08-02T05:18:00Z`
- `images.url-starts-with=https`

Remember that when implementing the server side and adding the above-given parameters to an SQL query,
you must use a parameterized SQL query to prevent SQL injection attacks because an attacker can
send malicious data in the query parameters.

Other actions like projection, sorting, and pagination for the queried resources can also be defined with
query parameters in the URL:

```http
GET /sales-item-service/sales-items?fields=id,name&sort-by=price:asc&offset=0&limit=100 HTTP/1.1
```

The above request gets sales items sorted by price (ascending). The number of fetched sales items
is limited to 100. Sales items are fetched starting from the offset 0, and the response contains only fields *id* and *name* for each sales item.

The *fields* parameter defines what resource fields (properties) are returned in the response. The wanted fields
are defined as a comma-separated list of field names. If you want to define sub-resource fields, those can be defined with
the dot notation, for example:

```
fields=id,name,images.url
```

The *sort-by* query parameter defines sorting using the following format:

```sort-by=<fieldName>:asc|desc,[<fieldName>:asc|desc]```

For example:

```
sort-by=price:asc,images.rank:asc
```

In the above example, the resources are returned as sorted first by ascending price and secondarily by image rank.

The *limit* and *offset* parameters are used for pagination. The *limit* query parameter defines the maximum
number of resources that can be returned. The *offset* query parameter specifies the offset from which resources are returned.
You can also paginate sub-resources by giving the *offset* and *limit* in the form
of `<sub-resource>:<number>`. Below is an example of using pagination query parameters:

```
offset=0&limit=50,images:5
```

The above query parameters define that the first page of 50 sales items is fetched, and each sales item contains
the first five images of the sales item. Instead of *offset* and *limit* parameters, you can use *page* and *page-size* parameters.
The *page* parameter defines the page number, and the *page-size* parameter defines the number of resources a page should contain.

Remember to validate user-supplied data to prevent SQL injection attacks when implementing the server side and adding data
from URL query parameters to an SQL query. For example, field names in
the *fields* query parameter should only contain characters allowed in an SQL column name. Similarly, the value of
the *sort-by* parameter should only contain characters allowed in an SQL column name and words *asc* and *desc*.
And finally, the values of the *offset* and *limit*  (or *page* and *page-size*) parameters must be integers.
You should also validate the *limit/page-size* parameter against the maximum allowed value because you should not allow clients
to fetch too many resources at a time.

Some HTTP servers log the URL of an HTTP GET request. For this reason, it is not recommended to put sensitive information in the URL.
Sensitive information should be included in the request body. Also, browsers can have a limit for
the maximum length of a URL. If you have a query string thousands of characters
long, you should give parameters in the request body instead. You should not put a request body to an HTTP GET request.
What you should do is issue the request using the HTTP POST method instead, for example:

```http
POST /sales-item-service/sales-items HTTP/1.1
Content-Type: application/json
X-HTTP-Method-Override: GET

{
  "fields": ["name"],
  "sortBy": "price:asc",
  "limit": 100
}
```

The server can confuse the above request with a sales item creation request because the URL and the HTTP
method are identical to a resource creation request. For this reason, a custom HTTP request header
*X-HTTP-Method-Override* has been added to the request. The server should read the custom header and treat the above
request as a GET request. The *X-HTTP-Method-Override* header tells the server to override the request method
with the method supplied in the header.

#### Updating Resources

A resource is updated with a REST API by sending an HTTP PUT or PATCH request to the API's resource endpoint.
To update the sales item identified with id 1, you can issue the following request:

```http
PUT /sales-item-service/sales-items/1 HTTP/1.1
Content-Type: application/json

{
  "name": "Sample sales item name modified",
  "price": 30
}
```

The server will respond without content:

```http
HTTP/1.1 204 No Content
```

Instead of sending no content, the server can return the updated resource in the response. This is needed if the server modifies the resource during the update process.
The server will respond with the HTTP status code 404 *Not Found* if the requested resource is not found.

If the supplied resource in the request
is invalid, the server should respond with the HTTP status code 400 *Bad Request*. The response body should contain an error object
in JSON.

HTTP PUT request will replace the existing resource with the supplied resource.
You can also modify an existing resource partially using the HTTP PATCH method:

```http
PATCH /sales-item-service/sales-items/1 HTTP/1.1
Content-Type: application/json

{
  "price": 30
}
```

The above request only modifies the price property of the sales item identified with id 1. Other properties remain intact.
You can do bulk updates by specifying a filter in the URL, for example:

```http
PATCH /sales-item-service/sales-items?price-less-than=10 HTTP/1.1
Content-Type: application/json

{
  "price": 10
}
```

The above example will update the price property of each resource where the price is currently less than ten.
On the server side, the API endpoint could use the following parameterized SQL statement to implement
the update functionality:

```sql
UPDATE salesitems SET price = %s WHERE price < %s
```

The above SQL statement will only modify the price column; other columns remain intact.

> ***Use resource versioning when needed.***

When you get a resource from the server and try to update it, someone else may have updated it after you got it but before trying to update it.
This can be okay if you don't care about other clients' updates. But sometimes, you want to ensure no one else has updated
the resource before you update it. In that case, you should use resource versioning. In the resource versioning,
there is a version field in the resource, which is incremented by one during each update. If you get a resource
with version *x* and then try to update the resource, giving back the same version *x* to the server, but someone
else has updated the resource to version *x + 1*, your update will fail because of the version mismatch (*x* != *x + 1*).
The server should respond with the HTTP status code 409 *Conflict*. After receiving the conflict response,
you can fetch the latest version of the resource from the server and, based on the resource's new state, decide
whether your update is still relevant or not, and retry the update.

The server should assign the resource version value to the HTTP response header [ETag](https://en.wikipedia.org/wiki/HTTP_ETag). A client can use the received ETag
value in a conditional HTTP GET request by assigning the received ETag value to the request header [If-None-Match](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-None-Match). The server
will return the requested resource only if it has a newer version. Otherwise, the server returns nothing with the HTTP status code 304 *Not Modified*. This brings the advantage of not re-transferring an unmodified resource from the
server to the client, which can be especially beneficial when the resource is large or the connection between the server and the client is slow.

#### Deleting Resources

Deleting a resource with a REST API is done by sending an HTTP DELETE request to the API's resource endpoint.
To delete the sales item identified with id 1, you can issue the following request:

```http
DELETE /sales-item-service/sales-items/1 HTTP/1.1
```

The server will respond without content:

```http
HTTP/1.1 204 No Content
```

If the requested resource has already been deleted, the API should still
respond with the HTTP status code 204 *No Content*, meaning a successful operation. It should not respond with the HTTP status code 404 *Not Found*.

To delete all sales items, you can issue the following request:

```http
DELETE /sales-item-service/sales-items HTTP/1.1
```

To delete sales items using a filter, you can issue the following kind of request:

```http
DELETE /sales-item-service/sales-items?price-less-than=10 HTTP/1.1
```

On the server side, the API endpoint handler can use the following parameterized SQL query to implement the deleting functionality:

```sql
DELETE FROM salesitems WHERE price < %s
```

#### Executing Non-CRUD Actions on Resources

Sometimes, you need to perform non-CRUD actions on resources. In those cases, you can issue an HTTP POST request
and put the name of the action (a verb) after the resource name in the URL. The below example will perform a *deposit*
action on an account resource:

```http
POST /account-balance-service/accounts/12345678912/deposit HTTP/1.1
Content-Type: application/json

{
  "amountInCents": 2510
}
```

Similarly, you can perform a withdrawal action:

```http
POST /account-balance-service/accounts/12345678912/withdraw HTTP/1.1
Content-Type: application/json

{
  "amountInCents": 2510
}
```

#### Resource Composition

A resource can be composed of other resources. There are two ways to implement resource composition:
Nesting resources or linking resources. Let's have an example of nesting resources first. A sales item resource can contain one or more image resources. We don't want to return all images when a client requests a sales item because images can be large and are not necessarily used by the client. What we could return is a set of small thumbnail images.
For a client to get the full images of a sales item, we could implement an API endpoint for image resources. The following API call can be issued to get images for a specific sales item:

```http
GET /sales-item-service/sales-items/<id>/images HTTP/1.1
```

You can also add a new image for a sales item:

```http
POST /sales-item-service/sales-items/<id>/images HTTP/1.1
```

Also, other CRUD operations could be made available:

```http
PUT /sales-item-service/sales-items/<salesItemId>/images/<imageId> HTTP/1.1
```

```http
DELETE /sales-item-service/sales-items/<salesItemId>/images/<imageId> HTTP/1.1
```

The problem with this approach is that the *sales-item-service* will grow in size, and if you need to add more
nested resources in the future, the size will grow even more, making the microservice too complex and being
possibly responsible for too many things.

A better alternative might be to create a separate microservice for the nested resources. This will enable the utilization of the best-suited technologies to implement the microservice.
Regarding the sales item images,
the *sales-item-image-service* could employ a cloud object storage to store images, and the *sales-item-service*
could utilize a standard relational database for storing sales items.

When having a separate microservice for sales item images, you can get the images for a sales item by issuing
the following request:

```http
GET /sales-item-image-service/sales-item-images?salesItemId=<salesItemId> HTTP/1.1
```

You can notice that the *sales-item-service* and *sales-item-image-service* are now linked by the *salesItemId*.

Note that the *sales-item-image-service* should be a service aggregated by the *sales-item-service*. The higher-level *sales-item-service* calls the lower-level *sales-item-image-service* because a sales item is a root aggregate, and sales item images are child entities that should not
be accessed directly but only via the root aggregate, according to DDD. This helps with enforcing business rules. For example, let's hypothesize that
a particular type of sales item should have at least *x* images. This kind of business rule should be enforced by the *sales-item-service*.
The *sales-item-image-service* cannot do it because it does not have (and should not have) detailed information about the sales item itself.
It only has the sales item's id.

#### HTTP Status Codes

Use the following HTTP status codes:

| HTTP Status Code       | When to Use                                                                                                                                                  |
|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 200 OK                 | Successful API operations with the GET method                                                                                                                |
 | 201 Created            | Successful API operations with the POST method                                                                                                               |
 | 202 Accepted           | The request has been accepted for processing. This can be used as the response status code for an asynchronous operation request ([Asynchronous request-reply](https://learn.microsoft.com/en-us/azure/architecture/patterns/async-request-reply)). For example, a POST request can get a response with this status code, an empty body, and a link to the resource that will eventually be created. The link is usually provided in the `Location` response header. That link will return 404 *Not Found* until the asynchronous creation is complete.
 | 204 No Content         | Successful API operations with the PUT, PATCH, or DELETE method                                                                                              |
 | 400 Bad Request        | Client error in API operations, e.g., invalid data supplied by the client                                                                                    |
 | 401 Unauthorized       | Client does not provide an authorization header in the request                                                                                               |
| 403 Forbidden          | Client provides an authorization header in the request, but the user is not authorized to perform the API operation                                          |
| 404 Not Found          | When requesting a non-existent resource with the GET, PUT, or PATCH method                                                                                   |
 | 405 Method Not Allowed | When a client tries to use the wrong method for an API endpoint                                                                                              |
 | 406 Not Acceptable     | When a client requests a response in a format that the server cannot produce, e.g., requests XML, but the server provides only JSON                          |
| 409 Conflict           | When a client is trying to update a resource that has been updated after the client got the resource                                                         |
 | 413 Payload Too Large  | When a client tries to supply a too large payload in a request. To prevent DoS attacks, do not accept arbitrarily large payloads from clients                |
 | 429 Too Many Requests  | Configure rate limiting in your API gateway to send this status code when the request rate is exceeded                                                       |
| 500 Internal Server Error | When a server error occurs, for example, an exception is thrown                                                                                              |
| 503 Service Unavailable | Server's connections to dependent services fail. This indicates that clients should retry the request after a while because this issue is usually temporary. |

#### HATEOAS and HAL

[Hypermedia as the Engine of Application State](https://en.wikipedia.org/wiki/HATEOAS) (HATEOAS) can be used to add hypermedia/metadata to a requested resource.
[Hypertext Application Language](https://en.wikipedia.org/wiki/Hypertext_Application_Language) (HAL) is a convention for defining hypermedia (metadata), such as links to external resources.
Below is an example response to a request that fetches the sales item with id 1234. The sales item is owned by the user with id 5678.
The response provides a link to the fetched resource itself and another link to fetch the user (account) that owns the sales item:

```json
{
  "_links": {
    "self": {
      "href": "https://.../sales-item-service/sales-items/1234"
    },
    "userAccount": {
      "href": "https://.../user-account-service/user-accounts/5678"
    }
  },
  "id": 1234,
  "name": "Sales item xyz"
  "userAccountId": 5678
}
```

When fetching a collection of sales items for page 3 using HAL, we can get the following kind of response:

```json
{
  "_links": {
    "self": {
      "href": "https://.../sales-items?page=3"
    },
    "first": {
      "href": "https://...sales-items"
    },
    "prev": {
      "href": "https://.../sales-items?page=2"
    },
    "next": {
      "href": "https://.../sales-items?page=4"
    },
  },
  "count": 25,
  "total": 1500,
  "_embedded": {
    "salesItems": [
      {
        "_links": {
           "self": {
             "href": "https://.../sales-items/123"
           }
        },
        "id": 123,
        "name": "Sales item 123"
      },
      {
        "_links": {
           "self": {
             "href": "https://.../sales-items/124"
           }
        },
        "id": 124,
        "name": "Sales item 124"
      },
      .
      .
      .
    ]
  }
}
```

The above response contains links to fetch sales items' first, current, previous, and last pages. It
also states that there are 1500 sales items, and a page lists 25. The `_embedded` property contains a `salesItems` property containing the 25 sales items with links to themselves and the
sales item data.

#### API Versioning

You can introduce a new version of an API using a versioning URL path segment. Below are example endpoints for API version 2:

```http
GET /sales-item-service/v2/sales-items HTTP/1.1
...
```

#### Documentation

If you need to document or provide interactive online documentation for a REST API, there are two ways:

1) Spec-first: create a specification for the API and then generate code from the specification
2) Code-first: implement the API and then generate the API specification from the code

Tools like [Swagger](https://swagger.io/) and Postman can generate both static and interactive documentation for your API based on the
API specification. You should specify APIs using the [OpenAPI specification](https://swagger.io/specification/).

When using the first alternative, you can specify your API using the OpenAPI specification language.
You can use tools like [SwaggerHub](https://swagger.io/tools/swaggerhub/) or Postman to write the API specification. [Swagger Codegen](https://swagger.io/tools/swagger-codegen/) offers code-generation tools
for multiple languages. Code generators generate code based on the OpenAPI specification. They can generate
client-side code in addition to the server-side code.

When using the second alternative, you can use a web framework-specific way to build the API spec from the API
implementation. For example, if you are using Spring Boot, you can use the [springdoc-openapi-ui](https://springdoc.org/) library, and with Nest.js, you
can use the [@nestjs/swagger](https://docs.nestjs.com/openapi/introduction) library.

I prefer to use the second approach of writing the code first. I like it better when I don't have to work with both
auto-generated and handwritten code. Many web frameworks offer automatic generation of the OpenAPI schema and
interactive documentation from the source code.

#### Implementation Example

Let's implement *sales-item-service* API endpoints for CRUD operations on sales items using FastAPI. We use the
*clean microservice design principle* introduced earlier and write the API endpoints inside a controller class:

{title: "SalesItemController.ts"}
```ts
import {
  Controller,
  Get,
  Query,
  Post,
  Body,
  Put,
  Param,
  Delete
} from '@nestjs/common';
// ...

@Controller('sales-items')
export class SalesItemController {
  constructor(private readonly salesItemService: SalesItemService) {}

  @Post()
  createSalesItem(
    @Body() inputSalesItem: InputSalesItem
  ): Promise<OutputSalesItem> {
    return this.salesItemService.createSalesItem(inputSalesItem);
  }

  @Get()
  getSalesItems(
    @Query('userAccountId') userAccountId: string,
  ): Promise<OutputSalesItem[]> {
    if (userAccountId) {
      return this.salesItemService.getSalesItemsByUserAccountId
      (
        userAccountId
      );
    } else {
      return this.salesItemService.getSalesItems();
    }
  }

  @Get('/:id')
  getSalesItem((@Param('id') id: string): Promise<OutputSalesItem> {
    return this.salesItemService.getSalesItem(id);
  }

  @Put('/:id')
  @HttpCode(204)
  updateSalesItem(
    @Param('id') id: string,
    @Body() inputSalesItemArg: InputSalesItem
  ):Promise<void> {
    return this.salesItemService.updateSalesItem(id, inputSalesItem);
  }

  @Delete('/:id')
  @HttpCode(204)
  deleteSalesItem(@Param('id') id: string): Promise<void> {
    return this.salesItemService.deleteSalesItem(id);
  }

  @Delete()
  @HttpCode(204)
  deleteSalesItems(): Promise<void> {
    return this.salesItemService.deleteSalesItems();
  }
}
```

The above controller is not production quality. The following must be added:

- Audit logging
- Observability, e.g., updating metric(s)
- Authorization

All of the above could be and probably should be implemented using custom decorators, for example:

```ts
@AllowForUserRoles(['admin'], authorizer)
@AuditLog()
@IncrementCounter(Counters.request_attempts)
@Post()
createSalesItem(
  // You need to add 'request' parameter because
  // you need to access it in your custom decorators
  // to get e.g., request URL, client's host and Authorization header
  @Req() request: Request,
  @Body() inputSalesItem: InputSalesItem
): Promise<OutputSalesItem> {
  return this.salesItemService.createSalesItem(inputSalesItem);
}
```

The implementation of the above custom decorators is not shown here, but if you are interested, similar decorators
for Python are implemented in this same chapter in my other book, Clean Code Principles And Patterns: Python Edition.
You can use the Python decorator implementations as a reference and basis for the TypeScript decorator implementations.
Notice how the above decorators are general purpose and not specific to this *sales-item-service* API. Instead of
adding the decorators to the controller class methods, you might be better off creating decorators that can be added to the service class
methods. In that case, you need to supply the needed information from the controller methods to the service methods, like the client's host
for the audit logging decorator and the JWT for the authorization decorators. You can group these two into a `ClientInfo` object passed
from the controller to the service class. The service class decorators then operate with that object.

The DTOs (objects that specify what data is transferred (input or output) between clients and the server)
are defined as shown below. For validating DTOs, we need to use the [class-validator](https://github.com/typestack/class-validator) and [class-transformer](https://github.com/typestack/class-transformer) libraries as instructed in [Nest.js
validation guide](https://docs.nestjs.com/techniques/validation).

{title: "SalesItemImage.ts"}
```ts
export default class SalesItemImage {
  @IsInt()
  @IsPositive()
  id: number;

  @IsInt()
  @IsPositive()
  rank: number;

  @IsUrl()
  url: string;
}
```

{title: "InputSalesItem.ts"}
```ts
export default class InputSalesItem {
  @MaxLength(256)
  name: string;

  // We accept negative prices for sales items that act
  // as discount items
  @IsInt()
  priceInCents: number;

  @ValidateNested()
  @ArrayMaxSize(25)
  images: SalesItemImage[];
}
```

{title: "OutputSalesItem.ts"}
```ts
export default class OutputSalesItem extends InputSalesItem {
  @MaxLength(256)
  id: string;

  @IsInt()
  @IsPositive()
  createdAtTimestampInMs: number;
}
```

Notice that we have specified validation for each attribute in all three DTO classes. This is important because of security.
For example, string and list attributes should have maximum length validators to prevent possible denial of
service attacks. Output DTOs should have validation as well. This is important because of security.
Output validation can protect against injection attacks that try to return data that has an invalid shape.
With Nest.js, the output DTOs are not validated (at the moment of writing this book). You need to implement it by yourself, e.g.,
in your application service class using the `validateOrReject` function from the *class-validator* library: `await validateOrReject(outputDto)`.

The `SalesItemService` interface looks like the following:

{title: "SalesItemService.ts"}
```ts
export default interface SalesItemService {
  createSalesItem(inputSalesItem: InputSalesItem): OutputSalesItem;
  getSalesItems(): OutputSalesItem[];
  getSalesItemsByUserAccountId(userAccountId: string): OutputSalesItem[];
  getSalesItem(id: string): OutputSalesItem;
  updateSalesItem(id: string, inputSalesItem: InputSalesItem): void;
  deleteSalesItem(id: string): void;
}
```

Next, we can implement the above protocol:

{title: "SalesItemServiceImpl.ts"}
```ts
export default class SalesItemServiceImpl implements SalesItemService {
  constructor(private readonly salesItemRepository SalesItemRepository) {
  }

  createSalesItem(inputSalesItem: InputSalesItem): OutputSalesItem {
     let salesItem = SalesItem.from(inputSalesItem);
     salesItem = this.salesItemRepository.save(salesItem);
     return OutputSalesItem.from(salesItem);
  }

  getSalesItems(): OutputSalesItem[] {
     const salesItems = this.salesItemRepository.findAll();
     return salesItems.map((salesItem) -> OutputSalesItem.from(salesItem));
  }

  getSalesItemsByUserAccountId(userAccountId: string): OutputSalesItem[] {
     const salesItems =
       this.salesItemRepository.findByUserAccountId(userAccountId);

     return salesItems.map((salesItem) -> OutputSalesItem.from(salesItem));
  }

  getSalesItem(id: string): OutputSalesItem {
    salesItem = this.salesItemRepository.find(id);

    if (!salesItem) {
      throw new EntityNotFoundError('Sales item', id);
    }

    return OutputSalesItem.from(salesItem);
  }

  updateSalesItem(id: string, inputSalesItem: InputSalesItem): void {
    if (!this.salesItemRepository.find(id)) {
      throw new EntityNotFoundError('Sales item', id);
    }

    let salesItem = SalesItem.from(inputSalesItem);
    this.salesItemRepository.update(id, salesItem);
  }

  deleteSalesItem(id: string): void {
    this.salesItemRepository.delete(id);
  }
}
```

Below is the definition of the `SalesItemRepository` protocol:

{title: "SalesItemRepository.ts"}
```ts
export default interface SalesItemRepository {
  save(salesItem: SalesItem): SalesItem;
  findAll(): SalesItem[];
  findByUserAccountId(userAccountId: string): SalesItem[];
  find(id: string): SalesItem | null;
  update(id: string, inputSalesItem: InputSalesItem): void;
  delete(id: string): void;
}
```

Various implementations for the `SalesItemRepository` are presented in the next chapter, where we focus on database
principles. The next chapter provides three different implementations for the repository: Object-Relational
Mapping (ORM), parameterized SQL queries, and MongoDB.

For error handling, we depend on the `catch` block provided by the Nest.js web framework. We could throw
errors of the Nest.js `HTTPException` type in our business logic, but then we would be coupling our web framework
with business logic, which is not desired. Remember how in the *clean microservice design principle*, the dependency goes only
from the web framework (controller) towards business logic, not vice versa. If we used web framework-specific
error classes in our business and logic, and we would like to migrate the microservice to a different web framework; we would
have to refactor the whole business logic concerning raised errors.

What we should do is introduce a base error class for our microservice and provide a custom exception filter for
Nest.js. The custom exception filter translates our business logic-specific errors into HTTP responses. The possible errors
the microservice can raise should all derive from the base error class. The `ApiError` class below is a general-purpose base error class
for any API.

{title: "ApiError.ts"}
```ts
export default class ApiError extends Error {
    constructor(
        private readonly statusCode: number,
        private readonly statusText: string,
        private readonly errorMessage: string,
        private readonly errorCode: string | undefined,
        private readonly errorDescription: string | undefined,
        private readonly cause: Error | undefined
    ) {
      timestamp = new Date();
    }

    toResponseObject(request: Request) {
      return {
        statusCode: error.statusCode,
        statusText: error.statusText,
        timestamp: new Date().toISOString(),
        endpoint: `${request.method} ${request.url}`
        errorCode: error.code,
        errorMessage: error.message,
        errorDescription: error.description,
        // getStackTrace returns stack trace only
        // when environment is not production
        // otherwise it returns 'undefined'
        stackTrace: getStackTrace(error.cause)
      }
    }
}
```

The `code` property could also be named `type`. The idea behind that property is to tell what kind
of an error is in question. This property can be used on the server side as a label for failure metrics, and on the
client side, special handling for particular error codes can be implemented.
If you want, you can even add one more property to the above class, namely `recoveryAction`. This optional property contains
information about recovery steps for an actionable error. For example, a database connection error might have a `recoveryAction` property value: *Please retry after a while. If the problem persists,
contact the technical support at &lt;email address&gt;*.

Below is the base error class for the *sales-item-service*:

{title: "SalesItemServiceError.ts"}
```ts
export default class SalesItemServiceError extends ApiError {
}
```

Let's then define one error class that is used by the API:

{title: "EntityNotFoundError"}
```ts
export default class EntityNotFoundError extends SalesItemServiceError {
  constructor(entityName: string, entityId: string) {
    super(
      404,
      'Not Found',
      `${entity_name} with id {entity_id} not found`,
      'EntityNotFound'
    )
  }
}
```

Let's implement a custom exception filter for our API. Notice how the exception filter is general purpose and
It can be used with any API with its errors derived from the `ApiError`.

{title: "SalesItemServiceErrorFilter.ts"}
```ts
@Catch(SalesItemServiceError)
export class SalesItemServiceErrorFilter implements ExceptionFilter {
  catch(error: SalesItemServiceError, host: ArgumentsHost) {
    const context = host.switchToHttp();
    const response = context.getResponse<Response>();
    const request = context.getRequest<Request>();

    // Log error.cause at least always
    // when error.status_code >= 500

    // Increment 'request_failures' counter by one
    // with three labels:
    // api_endpoint=`${request.method} ${request.url}`
    // status_code=error.statusCode
    // error_code=error.code

    response.status(error.statusCode).json(
      error.toResponseObject(request)
    });
  }
}
```

Now, if the business logic raises the following error:

```ts
throw new EntityNotFoundError('Sales item', '10')
```

The following API response should be expected in a production environment (Notice how the `stackTrace` is missing when the service is running in the production environment):

```http
HTTP/1.1 404 Not Found
Content-Type: application/json

{
  "statusCode": 404,
  "statusText": "Not Found",
  "endpoint": "GET .../sales-item-service/sales-items/1",
  "timestamp": "2024-02-26T12:32:49+0000",
  "errorCode": "EntityNotFound",
  "errorMessage": "Sales item with id 10 not found"
}
```

You should also add specific error handlers for DTO validation errors and other possible errors:

{title: "ValidationErrorFilter.ts"}
```ts
@Catch(BadRequestException)
export class ValidationErrorFilter implements ExceptionFilter {
  catch(error: BadRequestException, host: ArgumentsHost) {
    const context = host.switchToHttp();
    const response = context.getResponse<Response>();
    const request = context.getRequest<Request>();

    // Audit log

    // Increment 'request_failures' counter by one
    // with three labels:
    // api_endpoint=`${request.method} ${request.url}`
    // status_code=400
    // errorCode="RequestValidationError"

    response
      .status(400)
      .json({
        statusCode: 400,
        statusText: "Bad Request",
        timestamp: new Date().toISOString(),
        endpoint: `${request.method} ${request.url}`,
        errorCode: "RequestValidationError",
        errorMessage: 'Request validation failed',
        errorDescription: error.message
      });
  }
}
```

{title: "GenericErrorFilter.ts"}
```ts
@Catch(Error)
export class GenericErrorFilter implements ExceptionFilter {
  catch(error: Error, host: ArgumentsHost) {
    const context = host.switchToHttp();
    const response = context.getResponse<Response>();
    const request = context.getRequest<Request>();

    # Log error

    # Increment 'request_failures' counter by one
    # with labels:
    # api_endpoint=f'{request.method} {request.url}'
    # status_code=500
    # error_code='UnspecifiedError'

    response
      .status(500)
      .json({
        statusCode: 500,
        statusText: 'Internal Server Error',
        timestamp: new Date().toISOString(),
        endpoint: `${request.method} ${request.url}`,
        errorCode: 'UnspecifiedError',
        errorMessage: 'Unspecified internal error',
        errorDescription: error.message,
        stackTrace: getStackTrace(error),
      });
  }
}
```

The rest of the API service source code files look like the following:

{title: "app.ts"}
```ts
async function bootstrap() {
  const app = await NestFactory.create(AppModule);
  app.useGlobalPipes(
    new ValidationPipe(),
    new SalesItemServiceErrorFilter()
  );

  await app.listen(3000);
}

bootstrap();
}
```

### GraphQL API Design

> ***Divide API endpoints into queries and mutations. Compared to REST, REST GET requests are GraphQL queries,***
> ***and REST POST/PUT/PATCH/DELETE requests are GraphQL mutations. With GraphQL, you can name your queries and mutations with descriptive names.***

Let's create a [GraphQL schema](https://graphql.org/learn/schema/) that defines needed types and API endpoints for the *sales-item-service*.
After the example, we will discuss the details of the schema below and the schema language in general.

```graphql
type Image {
  id: Int!
  rank: Int!
  url: String!
}

type SalesItem {
  id: ID!
  createdAtTimestampInMs: String!
  name: String!
  priceInCents: Int!
  images(
    sortByField: String = "rank",
    sortDirection: SortDirection = ASC,
    offset: Int = 0,
    limit: Int = 5
  ): [Image!]!
}

input InputImage {
  id: Int!
  rank: Int!
  url: String!
}

input InputSalesItem {
  name: String!
  priceInCents: Int!
  images: [InputImage!]!
}

enum SortDirection {
  ASC
  DESC
}

type IdResponse {
  id: ID!
}

type Query {
  salesItems(
    sortByField: String = "createdAtTimestamp",
    sortDirection: SortDirection = DESC,
    offset: Int = 0,
    limit: Int = 50
  ): [SalesItem!]!

  salesItem(id: ID!): SalesItem!

  salesItemsByFilters(
    nameContains: String,
    priceGreaterThan: Float
  ): [SalesItem!]!
}

type Mutation {
  createSalesItem(salesItem: InputSalesItem!): SalesItem!

  updateSalesItem(
    id: ID!,
    salesItem: InputSalesItem
  ): IdResponse!

  deleteSalesItem(id: ID!): IdResponse!
}
```

The above GraphQL schema defines several types used in API requests and responses. A GraphQL `type` specifies an object type:
Its properties and the types of those properties. A type specified with the `input` keyword is an input-only type (input DTO type).
GraphQL defines the primitive (scalar) types: `Int` (32-bit), `Float`, `String`, `Boolean`, and `ID`.
You can define an array type with the notation: `[<Type>]`. By default, types are nullable.
If you want a non-nullable type, add an exclamation mark (!) after the type name. You can define an enumerated type
with the `enum` keyword. The `Query` and `Mutation` types are special GraphQL types used to define queries and mutations.
The above example defines three queries and four mutations that clients can execute. You can add
parameters for a type property. We have added parameters for all the queries (queries are properties of the `Query` type),
mutations (mutations are properties of the `Mutation` type), and the `images` property of the `SalesItem` type.

In the above example, I have named all the queries with names that describe the values they return, i.e., there are no
verbs in the query names. It is possible to name queries starting with a verb (like the mutations).
For example, you can add *get* to the beginning of the names of the above-defined queries if you prefer.

There are two ways to implement a GraphQL API:

- Schema first
- Code first (schema is generated from the code)

Let's first focus on the schema-first approach and implement the above-specified API using the [Apollo Server](https://www.apollographql.com/docs/apollo-server/) library.
The Apollo server below implements some GraphQL type resolvers returning static responses.

{title: "server.js"}
```js
import { ApolloServer } from '@apollo/server';
import { startStandaloneServer } from '@apollo/server/standalone';

const typeDefs = readFileSync('./schema.graphql',
                              { encoding: 'utf8' });

const resolvers = {
  Query: {
    salesItems: (_, { sortByField,
                      sortDirection,
                      offset,
                      limit }) =>
    [{
        id: 1,
        createdAtTimestampInMillis: '12345678999877',
        name: 'sales item',
        price: 10.95
    }],
    salesItem: (_, { id }) => ({
      id,
      createdAtTimestampInMillis: '12345678999877',
      name: 'sales item',
      price: 10.95
    })
  },
  Mutation: {
    createSalesItem: (_, { newSalesItem }) => {
      return {
        id: 100,
        createdAtTimestampInMillis: Date.now().toString(),
        ...newSalesItem
      };
    },
    deleteSalesItem: (_, { id }) => {
      return {
        id
      };
    }
  },
  SalesItem: {
    images: (parent) => {
      return [{
        id: 1,
        rank: 1,
        url: 'url'
      }];
    }
  }
};

const server = new ApolloServer({
  typeDefs,
  resolvers
});

startStandaloneServer(server, {
  listen: { port: 4000 }
});
```


After starting the server with the `node server.js` command, you can browse to _http://localhost:4000_ and
try to execute some of the implemented queries or mutations.
You will see the GraphiQL UI, where you can execute queries and mutations. Enter the following query in the left pane of the UI.

```graphql
query salesItems {
  salesItems(offset: 0) {
    id
    createdAtTimestampInMs
    name
    priceInCents,
    images {
      url
    }
  }
}
```

You should get the following response on the right side pane:

```json
{
  "data": {
    "salesItems": [
      {
        "id": "1",
        "createdAtTimestampInMillis": "12345678999877",
        "name": "sales item",
        "priceInCents": 1095,
        "images": [
          {
            "url": "url"
          }
        ]
      }
    ]
  }
}
```

You can also try to create a new sales item:

```graphql
mutation create {
  createSalesItem(inputSalesItem: {
    priceInCents: 4095
    name: "test sales item"
    images: []
  }) {
    id,
    createdAtTimestampInMs,
    name,
    priceInCents,
    images {
      id
    },
  }
}
```

Below is the response you would get, except for the timestamp being the current time:

```json
{
  "data": {
    "createSalesItem": {
      "id": "100",
      "createdAtTimestampInMillis": "1694798999418",
      "name": "test sales item",
      "priceInCents": 4095,
      "images": []
    }
  }
}
```

To delete a sales item, you can issue:

```graphql
mutation delete {
  deleteSalesItem(id: 1) {
   id
  }
}
```

```json
{
  "data": {
    "deleteSalesItem": {
      "id": "1"
    }
  }
}
```

Let's replace the dummy static implementations in our GraphQL controller with actual calls to the sales item service:

{title: "GraphQlSalesItemController.js"}
```js
export default class GraphQlSalesItemController {
  constructor(salesItemService) {
    this.salesItemService = salesItemService;
  }

  getSalesItems(...) {
    return this.salesItemService.getSalesItems(...);
  }

  getSalesItem({ id }) {
    return this.salesItemService.getSalesItem(id);
  }

  createSalesItem({ inputSalesItem: input }) {
    const inputSalesItem = await transformAndValidate(InputSalesItem, input);
    return this.salesItemService.createSalesItem(inputSalesItem);
  }

  updateSalesItem({ id, inputSalesItem: input }) {
    const inputSalesItem = await transformAndValidate(InputSalesItem, input);
    return this.salesItemService.createSalesItem(newSalesItem);
  }

  deleteSalesItem({ id }) {
    this.salesItemService.deleteSalesItem(id);
    return { id };
  }

  getResolvers() {
    return {
      Query: {
        salesItems: this.getSalesItems,
        salesItem: this.getSalesItem
      },
      Mutation: {
        createSalesItem: this.createSalesItem,
        deleteSalesItem: this.deleteSalesItem
      },
      SalesItem: {
        images: this.getSalesItemImages
      }
    }
  }
}
```

Notice in the above code that we must remember to validate the input for the two mutations. We can do that
by using [class-transformer-validator](https://www.npmjs.com/package/class-transformer-validator) library.

Currently our model depends on receiving validated input DTOs. There is even a better approach for validating input DTOs.
We can validate them in the entity factory. In this case, we could put the validation of `InputSalesItem` DTOs into the
`SalesItem` class's factory method, `SalesItem.from(inputSalesItem: InputSalesItem)`. This is a very natural place for
validation. Validation is now moved from the input adapter layer (controllers) to the application core/model. If the
validation logic is complex, you should create a separate class, `InputSalesItemValidator`, that can be used in the
entity factory method, `SalesItem.from`.

We should add authorization, audit logging, and metric updates to make the example more production-like. This can be done by creating decorators in a similar way we created earlier in the REST API example.
The decorators can get the request object from the context:

```js
const { url } = await startStandaloneServer(server, {
  context: async ({ request }) => ({
    request
  }),
});
```

GraphQL error handling differs from REST API error handling. A GraphQL API responses do not provide different HTTP response status codes.
A GraphQL API response is always sent with the status code *200 OK*.
When an error occurs while processing a GraphQL API request, the response body object includes an `errors` array. You should raise an error in your GraphQL type resolvers when a query or mutation fails. You can use the same `ApiError` base error class used in the earlier REST API example.
As shown below, we need to add an error formatter to handle the custom API errors. The error objects should always have a `message` field.
Additional information about the error can be supplied in an `extensions` object, which can contain any properties.

Suppose a `salesItem` query results in an `EntityNotFoundError`. Then the API response would have a `null` for the `data` property and `errors` property present, as shown below:

```json
{
  "data": null,
  "errors": [
    {
      "message": "Sales item not found with id 1",
      "extensions": {
        "statusCode": 404,
        "statusText": "Not Found",
        "errorCode": "EntityNotFound",
        "errorDescription": null
        "stackTrace": null
      }
    }
  ]
}
```

Below is the code for the *app.js* module:

{format: "app.js"}
```js
format_custom_error(
    graphql_error, debug: bool = False
) -> dict[str, Any]:
    error = unwrap_graphql_error(graphql_error)

    if isinstance(error, SalesItemServiceError):
        return {
            'message': error.message,
            'extensions': {
                'statusCode': error.status_code,
                'statusText': error.status_text,
                'errorCode': error.code,
                'errorDescription': error.description,
                'stackTrace': get_stack_trace(error.cause),
            },
        }

    if isinstance(error, ValidationError):
        return {
            'message': 'Request validation failed',
            'extensions': {
                'statusCode': 400,
                'statusText': 'Bad Request',
                'errorCode': 'RequestValidationError',
                'errorDescription': str(error),
                'stackTrace': None,
            },
        }

    if isinstance(error, Exception):
        return {
            'message': 'Unspecified internal error',
            'extensions': {
                'statusCode': 500,
                'statusText': 'Internal Server Error',
                'errorCode': 'UnspecifiedError',
                'errorDescription': str(error),
                'stackTrace': get_stack_trace(error),
            },
        }

    else:
        return format_error(graphql_error, debug)
```

I apologize for the above code containing *a chain of instanceof checks* code smell. What we should do is to
move the `formatError` code to a factory whose `create` method we give the `error` as a parameter.

As an alternative to the described error handling mechanism, it is also possible to return an error as a query/mutation return value. This can be done, e.g., by returning a union type
from a query or mutation. This approach requires a more complex GraphQL schema and more complex resolvers on the server side.
Here is an example:

```graphql
# ...

type Error {
    message: String!
    # Other possible properties
}

union SalesItemOrError = SalesItem | Error

type Mutation {
  createSalesItem(inputSalesItem: InputSalesItem!): SalesItemOrError!
}
```

In the `createSalesItem` query resolver, you must add a try-except block to handle an error situation and respond with an `Error` object in case of an error.

You can also specify multiple errors:

```graphql
# ...

type ErrorType1 {
    # ...
}

type ErrorType2 {
    # ...
}

type ErrorType3 {
    # ...
}

union SalesItemOrError = SalesItem | ErrorType1 | ErrorType2 | ErrorType3

type Mutation {
  createSalesItem(inputSalesItem: InputSalesItem!): SalesItemOrError!
}
```

The above example would require making the `createSalesItem` resolvers to catch multiple different errors and responding
with an appropriate error object as a result.

Also, the client-side code will be more complex because of the need to handle the different types of responses for a single operation (query/mutation).
For example:

```graphql
mutation {
  createSalesItem(inputSalesItem: {
    price: 200
    name: "test sales item"
    images: []
  }) {
    __typename
    ...on SalesItem {
      id,
      createdAtTimestampInMillis
    }
    ...on ErrorType1 {
      # Specify fields here
    }
    ...on ErrorType2 {
      # Specify fields here
    }
    ...on ErrorType3 {
      # Specify fields here
    }
}
```

This approach has a downside: the client must still be able to handle possible errors reported in the response's `errors` array.

In a GraphQL schema, you can add parameters for a primitive (scalar) property. That is useful for implementing conversions.
For example, we could define the `SalesItem` type with a parameterized `priceInCents` property:

```graphql
enum Currency {
  USD,
  GBP,
  EUR,
  JPY
}

type SalesItem {
  id: ID!
  createdAtTimestampInMillis: String!
  name: String!
  priceInCents(currency: Currency = USD): Int!
  images(
    sortByField: String = "rank",
    sortDirection: SortDirection = ASC,
    offset: Int = 0,
    limit: Int = 5
  ): [Image!]!
}
```

Now, clients can supply a currency parameter for the `price` property in their queries to get the price in different currencies.
The default currency is *USD* if no currency parameter is supplied.

Below are two example queries that a client could perform against the earlier defined GraphQL schema:

```graphql
{
  # gets the name, price in euros and the first 5 images
  # for the sales item with id "1"
  salesItem(id: "1") {
    name
    price(currency: EUR)
    images
  }

  # gets the next 5 images for the sales item 1
  salesItem(id: "1") {
    images(offset: 5)
  }
}
```

In real life, consider limiting the fetching of resources only to the previous or the next page (or the next page only
if you are implementing infinite scrolling on the client side). Then, clients cannot fetch random pages. This prevents
attacks where a malicious user tries to fetch a page with a huge page number (like 10,000, for example), which can
cause extra load for the server or, at the extreme, a denial of service.

Below is an example where clients can only query the first, next, or previous page. When a client requests the first page,
the page cursor can be empty, but when the client requests the previous or the next page, it must give the current page cursor
as a query parameter.

```
type PageOfSalesItems {
  # Contains the page number encrypted and
  # encoded as a Base64 value.
  pageCursor: String!

  salesItems: [SalesItem!]!
}

enum Page {
  FIRST,
  NEXT,
  PREVIOUS
}

type Query {
  pageOfSalesItems(
    page: Page = FIRST,
    pageCursor: String = ""
  ): PageOfSalesItems!
}
```

Then you can use the _type-graphql_
NPM library that allows you to write a GraphQL schema using TypeScript classes Below is the `InputSalesItem` input type from the earlier GraphQL schema represented as a TypeScript class
 The _type-graphql_ library works
with most GraphQL server implementations, like _express-graphql_ or _apollo-server_.

{title: "InputSalesItem.ts"}
```ts
import { Field, InputType } from 'type-graphql';
import InputImage from './InputImage';

@InputType()
export default class InputSalesItem {
  @Field()
  name: string;

  @Field()
  price: number;

  @Field()
  images: InputImage[];
}
```

Instead of _type-graphql_, you can use the Nest.js web framework. It also allows you to define a GraphQL schema
using TypeScript classes, too. The above and below examples
are identical, except that some decorators are imported from a different library.

{title: "InputSalesItem.ts"}
```ts
import { Field, Int, InputType } from '@nestjs/graphql';
import InputImage from './InputImage';

@InputType()
export class InputSalesItem {
  @Field()
  name: string;

  @Field()
  price: number;

  images: InputImage[];
}
```

Both with _type-graphql_ and Nest.js, you don't specify a controller for GraphQL queries and mutations. You specify
resolver classes that are used to compose the final root resolver for the GraphQL API. Below is an example Nest.js
resolver:

{title: "SalesItemResolver.ts"}
```ts
import {
  Args,
  Int,
  Parent,
  Query,
  ResolveField,
  Resolver,
} from '@nestjs/graphql';
// ...

@Resolver(of => SalesItem)
export class SalesItemResolver {
  constructor(
    private salesItemService: SalesItemService,
    private salesItemImageService: SalesItemImageService
  ) {}

  @Query(returns => SalesItem)
  async salesitem(@Args('id', { type: () => Int }) id: number) {
    return this.salesItemService.getSalesItem(id);
  }

  @ResolveField()
  async images(@Parent() salesItem: SalesItem) {
    return this.salesItemImageService
      .getSalesItemImages(salesItem.id);
  }
}
```

We must add authorization, audit logging, and metrics updates to make our resolvers more production-like. We can
implement decorators similar to those in the earlier REST API example. When the decorators need to access the request, it
can be done via the context parameter.

### Subscription-Based API Design

> ***Design a subscription-based API when you want clients to be able to subscribe to small, incremental changes to large objects***
> ***or when clients want to receive low-latency real-time updates.***

#### Server-Sent Events (SSE)

[Server-Sent Events](https://en.wikipedia.org/wiki/Server-sent_events) (SSE) is a uni-directional push technology enabling a client to receive updates from a server via an
HTTP connection.

Let's showcase the SSE capabilities with a real-life example. The below example defines a *subscribe-to-loan-app-summaries* API endpoint
for clients to subscribe to loan application summaries. A client will show loan application summaries in a list view in its UI.
Whenever a new summary for a loan application is available, the server will send a loan application summary event
to clients that will update their UIs by adding a new loan application summary.

{title: "server.js"}
```js
import express from 'express';
import bodyParser from 'body-parser';
import loanApplicationSummariesSubscriptionHandler
  from './loanApplicationSummariesSubscriptionHandler.js';

const app = express();
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({extended: false}));

app.get('/subscribe-to-loan-application-summaries',
        loanApplicationSummariesSubscriptionHandler);

app.listen(3001);
```

{title: "subscribers.js"}
```js
import { v4 as uuidv4 } from 'uuid';

export let subscribers = [];

export function addSubscriber(response) {
  const id = uuidv4();

  const subscriber = {
    id,
    response
  };

  subscribers.push(subscriber);
  return id;
}

export function removeSubscriber(id) {
  subscribers = subscribers.filter((subscriber) =>
    subscriber.id !== id);
}
```

{title: "loanApplicationSummariesSubscriptionHandler.js"}
```js
import {
  addSubscriber,
  removeSubscriber
} from './subscribers.js';

export default function
loanApplicationSummariesSubscriptionHandler(request, response) {
  // Response headers needed for SSE:
  // - Server sent events are identified with
  //   content type 'text/event-stream'
  // - The connection must be kept alive so that server
  //   can send continuously data to client
  // - Server sent events should not be cached
  const headers = {
    'Content-Type': 'text/event-stream',
    'Connection': 'keep-alive',
    'Cache-Control': 'no-cache'
    // For dev environment you can add CORS header:
    'Access-Control-Allow-Origin': '*'
  };

  response.writeHead(200, headers);

  // Server sent event must be a string beginning with 'data: '
  // and ending with two newline characters
  // First event is empty
  const data = 'data: \n\n';
  response.write(data);
  const subscriberId = addSubscriber(response);
  request.on('close', () => removeSubscriber(subscriberId));
}
```

The below `publishLoanApplicationSummary` function is called whenever the server receives a new loan application summary.
The server can receive loan application summaries as messages consumed from a message broker's topic. (This message
consumption part is not implemented here, but there is another example later in this chapter demonstrating how messages
can be consumed from a Kafka topic.)

{title: "publishLoanApplicationSummary.js"}
```js
import { subscribers } from './subscribers.js';

export default function publishLoanApplicationSummary(
  loanApplicationSummary
) {
   // Send an event to each subscriber
   // Loan application summary data is converted to JSON
   // before sending the event
   // Server sent event must be a string beginning with 'data: '
   // and ending with two newline characters
   const data = JSON.stringify(loanApplicationSummary);
   subscribers.forEach(({ response }) =>
     response.write(`data: ${data}\n\n`));
}
```

Next, we can implement the web client in JavaScript and define the following React functional component:

{title: "LoanApplicationSummaries.jsx"}
```jsx
import React, { useEffect, useState } from 'react';

export default function LoanAppSummaries() {
  const [ loanAppSummaries, setLoanAppSummaries ] = useState([]);

  // Define an effect to be executed on component mount
  useEffect(() => {
    // Create new event source
    // Hardcoded dev environment URL is used here for demonstration
    // purposes
    const eventSource =
      new EventSource('http://localhost:8000/subscribe-to-loan-app-summaries');

    // Listen to server sent events and add a new
    // loan application summary to the head of
    // loanAppSummaries array
    eventSource.addEventListener('message', (messageEvent) => {
      try {
        const loanAppSummary = JSON.parse(messageEvent.data);

        if (loanAppSummary) {
          setLoanAppSummaries([loanAppSummary, ...loanAppSummaries]);
        }
      } catch {
        // Handle error
      }
    });

    eventSource.addEventListener('error', (errorEvent) => {
      // Handle error
    });

    // Close the event source on component unmount
    return function cleanup() { eventSource.close(); }
  }, [loanAppSummaries]);

  // Render loan application summary list items
  const loanAppSummaryListItems =
    loanAppSummaries.map(({ ... }) =>
       (<li key={key here...}>render here...</li>));

  return (
    <ul>{loanAppSummaryListItems}</ul>
  );
}
```

#### GraphQL Subscriptions

Let's have an example of a GraphQL subscription. The below GraphQL schema defines one
subscription for a post's comments. It is not relevant what a post is. It can be a blog post or
social media post, for example. We want a client to be able to subscribe to a post's comments.

```graphql
type PostComment {
  id: ID!,
  text: String!
}

type Subscription {
  postComment(postId: ID!): PostComment
}
```

On the client side, we can define a subscription named `postCommentText` that subscribes to
a post's comments and returns the text property of comments:

```js
import { gql } from '@apollo/client';

const POST_COMMENT_SUBSCRIPTION = gql`
  subscription postCommentText($postId: ID!) {
    postComment(postID: $postId) {
      text
    }
  }
`;
```

If a client executes the above query for a particular post (defined with the `postId` parameter), the following kind
of response can be expected:

```json
{
  "data": {
    "postComment": {
      "text": "Nice post!"
    }
  }
}
```

To be able to use GraphQL subscriptions, you must implement support for them both on the server and client side. For the server side,
you can find instructions for the _Apollo server_ here: [https://www.apollographql.com/docs/apollo-server/data/subscriptions/#enabling-subscriptions](https://www.apollographql.com/docs/apollo-server/data/subscriptions/#enabling-subscriptions).
And for the client side, you can find instructions for the _Apollo client_ here: [https://www.apollographql.com/docs/react/data/subscriptions/#setting-up-the-transport](https://www.apollographql.com/docs/react/data/subscriptions/#setting-up-the-transport)

After the server and client-side support for subscriptions are implemented, you can use the subscription in your React component:

{title: "SubscribedPostCommentsView.jsx"}
```jsx
import { useState } from 'react';
import { gql, useSubscription } from '@apollo/client';

const POST_COMMENT_SUBSCRIPTION = gql`
  subscription subscribeToPostComment($postId: ID!) {
    postComment(postID: $postId) {
      id
      text
    }
  }
`;

export default function SubscribedPostCommentsView({ postId }) {
  const [ postComments, setPostComments ] = useState([]);

  const { data } = useSubscription(POST_COMMENT_SUBSCRIPTION,
                                   { variables: { postId } });

  if (data?.postComment) {
    setPostComments([...postComments, data.postComment]);
  }

  const postCommentListItems =
    postComments.map(( { id, text }) =>
      (<li key={id}>{text}</li>));

  return <ul>{postCommentListItems}</ul>;
}
```

### WebSocket Example

Below is a chat messaging application consisting of a WebSocket server implemented with Node.js and the [ws](https://www.npmjs.com/package/ws) NPM library and a WebSocket client implemented with React. There can be multiple instances of the server
running. These instances are stateless except for storing WebSocket connections for locally connected clients.

We implement the example using the *clean microservice design (or architecture)* principle, as shown in the picture below.

![WebSocket Example Clean Architecture](resources/chapter6/images/websocket_clean_arch.png)

On the interface adapter layer, we have multiple interface adapters:
- RedisPhoneNbrToInstanceUuidCache
- KafkaChatMsgBrokerAdminClient
- KafkaChatMsgBrokerAdminProducer
- KafkaChatMsgBrokerAdminConsumer
- ChatMsgStoreService
- WebSocketChatMsgServer
- WebSocketConnection

The above classes depend on the microservice model, which consists of `ChatMessageService` and `ChatMessage`.
The `RedisPhoneNbrToInstanceUuidCache` implements the `PhoneNbrToInstanceUuidCache` interface and is responsible
for storing the chat server instance UUID for each end-user (according to their phone number). The `KafkaChatMsgBrokerAdminProducer` implements the `ChatMsgBrokerAdminProducer` interface and is responsible for sending a chat message to Kafka to be handled
by another chat server instance. The `KafkaChatMsgBrokerAdminConsumer` implements the `ChatMsgBrokerAdminConsumer` interface
and is responsible for reading chat messages belonging to the particular chat server from the Kafka.
The `ChatMsgStoreService` is responsible for contacting a remote *chat-message-store-service* for persistent storage of
chat messages. The `WebSocketChatMsgServer` implements a chat message server using WebSocket protocol and is responsible
for creating `WebSocketConnection` instances.

First, we list the source code files for the server side.
A new Kafka client is created using the [kafkajs](https://www.npmjs.com/package/kafkajs) NPM library:

{title: kafkaClient.ts"}
```ts
import { Kafka } from 'kafkajs';

const kafkaClient = new Kafka({
  clientId: 'app-y',
  brokers: [process.env.KAFKA_BROKER],
});

export default kafkaClient;
```

A new Redis client is created using the [ioredis](https://www.npmjs.com/package/ioredis) NPM library:

{title: "redisClient.ts"}
```ts
import Redis from 'ioredis';

const redisClient = new Redis({
  port: parseInt(process.env.REDIS_PORT, 10),
  host: process.env.REDIS_HOST,
  username: process.env.REDIS_USERNAME,
  password: process.env.REDIS_PASSWORD
});

export default redisClient;
```

The below `KafkaMessageBrokerAdminClient` class implementing the `ChatMsgBrokerAdminClient` interface is used to create topics in Kafka:

{title: "WebSocketExampleError.ts"}
```ts
export default class WebSocketExampleError extends Error {
}
```

{title: "ChatMsgBrokerAdminClient.ts"}
```ts
export default class ChatMsgBrokerAdminClient {
  static class CreateTopicError = class extends WebSocketExampleError {};

  tryCreateTopic(name: string): Promise<void>;
}
```

{title: "KafkaChatMsgBrokerAdminClient.ts"}
```ts
export default class KafkaChatMsgBrokerAdminClient
                       implements ChatMsgBrokerAdminClient {
  private readonly kafkaAdminClient: AdminClient;

  constructor(kafkaClient: KafkaClient) {
    this.kafkaAdminClient = kafkaClient.admin();
  }

  async try createTopic(name: string): Promise<void> {
    try {
      await this.kafkaAdminClient.connect();

      await this.kafkaAdminClient.createTopics({
        topics: [{ name }]
      });

      await this.kafkaAdminClient.disconnect();
    } catch {
      throw new this.CreateTopicError();
    }
  }
}
```

Users of the chat messaging application are identified with phone numbers. On the server side, we store the connection for each user in the `phoneNbrToConnMap`:

{title: "phoneNbrToConnMap.ts"}
```ts
const phoneNbrToConnMap = new Map<String, Connection>();
export default phoneNbrToConnMap;
```

{title: "Connection.ts"}
```ts
export default interface Connection {
  static Error = class extends WebSocketExampleError {
  }

  trySend(message: string): Promise<void>;
}
```

{title: "WebSocketConnection.ts"}
```ts
export default WebSocketConnection implement Connection {
  constructor(private readonly webSocketConn: WebSocketConnection) {
  }

  trySend(message: string): Promise<void> {
    this.webSocketConn.send(message);
  }
}
```

The below `WebSocketChatMsgServer` class handles the construction of a WebSocket server. The server accepts connections from clients. When it receives a chat message from a client, it will first parse and validate it. If the received chat message is a special online
indication message, the server will register a new user. For an actual chat message, the server will store
the message in persistent storage (using a separate _chat-message-service_ REST API, not implemented here). The server gets the recipient's server information from a Redis cache and sends the chat message to the recipient's WebSocket connection or produces the chat message to a Kafka topic where
another server instance can consume the chat message and send it to the recipient's WebSocket connection. The Redis cache stores
a hash map where the users' phone numbers are mapped to the server instance they are currently connected. A UUID identifies a server instance.

{title: "WebSocketChatMsgServer.ts"}
```ts
import { WebSocketServer } from 'ws';
import kafkaClient from './kafkaClient.js';
import redisClient from './redisClient.js';

import phoneNbrToWsConnectionMap
  from './phoneNbrToWsConnectionMap.js';

import KafkaMessageBrokerProducer
  from './KafkaMessageBrokerProducer.js';


export default class WebSocketChatMsgServer {
  wsServer;
  messageBrokerProducer;
  wsConnectionToPhoneNbrMap = new Map();

  constructor(private readonly instanceUuid) {
    this.chatMsgBrokerProducer = new KafkaChatMsgBrokerProducer(kafkaClient);
    this.webSocketServer = new WebSocketServer({ port: 8080 });

    this.wsServer.on('connection', wsConnection => {
      phone_nbr_to_conn_map[phone_number] = connection
      self.__conn_to_phone_nbr_map[connection] = phone_number
      cache.tryStore(phoneNumber, self.__instance_uuid)

      wsConnection.on('message', async (chatMessageJson) => {
        try {
          const chatMessage = this.parse(chatMessageJson);
        } catch {
            // ...
        }

        // Validate chatMessage ...
        // Store chat message permanently using another API ...

        const recipientServerUuid =
          await this.getServerUuid(chatMessage.recipientPhoneNbr);

        this.send(chatMessage, recipientInstanceUuid);
      });

      wsConnection.on('close', () => {
        this.close(wsConnection);
      });
    });
  }

  closeServer() {
    this.wsServer.close();
    this.wsServer.clients.forEach(client => client.close());
    this.messageBrokerProducer.close();
  }

  send(chatMessage, serverUuid) {
    // Extract this method to: ChatMsgService.send(chatMessage)

    if (serverUuid === this.serverUuid) {
      // Recipient has active connection on
      // the same server instance as sender
      const recipientWsConnection =
        phoneNbrToWsConnectionMap
          .get(chatMessage.recipientPhoneNbr);

      recipientWsConnection?
        .send(JSON.stringify(chatMessage));

    } else if (serverUuid) {
      // Recipient has active connection on different
      // server instance compared to sender
      const serverTopic = serverUuid;

      this.messageBrokerProducer
        .produce(chatMessage, serverTopic);
    }
  }

  async close(wsConnection) {
    const phoneNbr =
      this.wsConnectionToPhoneNbrMap
        .get(wsConnection);

    phoneNbrToWsConnectionMap.delete(phoneNbr);
    this.wsConnectionToPhoneNbrMap.delete(wsConnection);
    cache.tryRemove()
  }
}
```

{title: "PhoneNbrToInstanceUuidCache.ts"}
```
export default interface PhoneNbrToInstanceUuidCache {
  static Error = class extends WebSocketExampleError {
  }

  retrieveInstanceUuid(phone_number: string | undefined): str | undefined;
  tryStore(phoneNumber: string, instanceUuid: string): Promise<void>;
  tryRemove(phoneNumber: string): Promise<void>;
}
```

{title: "RedisPhoneNbrToInstanceUuidCache.ts"}
```ts
export default class RedisPhoneNbrToInstanceUuidCache
                       implements PhoneNbrToInstanceUuidCache
  constructor(private readonly redisClient: RedisClient) {
  }

  retrieveInstanceUuid(phone_number: string | undefined): str | undefined {
    try {
      return
        await redisClient.hget(
          'phoneNbrToServerUuidMap',
           phoneNbr
        );
    } catch {
      return undefined;
    }
  }

  tryStore(phoneNumber: string, instanceUuid: string): Promise<void> {
    try {
      await redisClient.hset(
        'phoneNbrToServerUuidMap',
        senderPhoneNbr,
        this.serverUuid
      );
    } catch {
      // Handle error
    }
  }

  tryRemove(phoneNumber: string): Promise<void> {
    try {
      await redisClient.hdel('phoneNbrToServerUuidMap',
                             phoneNbr);
    } catch {
      // Handle error
    }
  }
```

{title: ChatMsgBrokerProducer.ts}
```ts
export default interface KafkaMessageBrokerProducer {
 static Error = class extends WebSockeExampleError {
 }

 tryProduce(chatMessage, topic): Promise<void>;
 tryClose()
    try {
      this.isTerminating = true;
      await this.kafkaProducer.disconnect();
    } catch {
    }
  }
}

{title: "KafkaChatMsgBrokerProducer.ts"}
```
export default class KafkaChatMsgBrokerProducer
                       implements ChatMsgBrokerProducer {
  private readonly kafkaProducer: KafkaProducer;

  constructor(kafkaClient: kafkaClient) {
    this.kafkaProducer = kafkaClient.producer();
  }

  async tryProduce(chatMessage, topic): Promise<void> {
    try {
      await this.kafkaProducer.connect();
      await this.kafkaProducer.send({
        topic,
        messages: [{ value: JSON.stringify(chatMessage) }],
      });
    } catch {
      // Handle error
    }
  }

  async close(): Promise<void> {
    try {
      this.isTerminating = true;
      await this.kafkaProducer.disconnect();
    } catch {
    }
  }
}
```

The `KafkaMessageBrokerConsumer` class defines a Kafka consumer that consumes chat messages from
a particular Kafka topic and sends them to the recipient's WebSocket connection:

{title: "ChatMsgBrokerConsumer.ts"}
```ts
export default interface ChatMsgBrokerConsumer {
  consumeChatMessages(topic): void;
  close(): Promise<void>;
}
```

{title: "KafkaChatMsgBrokerConsumer.ts"}
```ts
import phoneNbrToWsConnectionMap
  from './phoneNbrToWsConnectionMap.js';

export default class KafkaChatMsgBrokerConsumer
                       implements ChatMsgBrokerConsumer{
  private readonly kafkaConsumer: KafkaConsumer;

  constructor(kafkaClient: KafkaClient) {
    this.kafkaConsumer =
      kafkaClient.consumer({ groupId: 'app-y' });
  }

  async consumeChatMessages(topic): void<Promise> {
    await this.kafkaConsumer.connect();
    await this.kafkaConsumer.subscribe({
      topic,
      fromBeginning: true
    });

    this.kafkaConsumer.run({
      eachMessage: async ({ message }) => {
        try {
          // Kutsu ChatMsgService.send(chatMessage)
          // poista alla oleva koodi

          const chatMessage =
            JSON.parse(message.value.toString());

          const recipientWsConnection =
            phoneNbrToWsConnectionMap
              .get(chatMessage.recipientPhoneNbr);

          recipientWsConnection?
            .send(JSON.stringify(chatMessage));
        } catch {
          // Handle error
        }
      },
    });
  }

  async close(): void<Promise> {
    try {
      await this.kafkaConsumer.disconnect();
    } catch
    {}
  }
}
```

Finally, we put it all together in the index.js file:

{title: "index.ts"}
```ts
import { v4 as uuidv4 } from 'uuid';
import kafkaClient from './kafkaClient.js';

import KafkaMessageBrokerAdminClient
  from './KafkaMessageBrokerAdminClient.js';

import KafkaMessageBrokerConsumer
  from './KafkaMessageBrokerConsumer.js';

import WebSocketChatMessagingServer
  from './WebSocketChatMessagingServer.js';

// Generate a unique id for this particular server instance
const serverUuid = uuidv4();
const serverTopic = serverUuid;

// Create a Kafka topic for this particular microservice instance
await new KafkaMessageBrokerAdminClient(kafkaClient)
  .create(serverTopic);

// Create the chat messaging service for
// handling WebSocket connections
const chatMessagingServer =
  new WebSocketChatMessagingServer(serverUuid);

// Create and start a Kafka consumer to consume and send
// chat messages for recipients that are connected to
// this microservice instance
const messageBrokerConsumer =
  new KafkaMessageBrokerConsumer(kafkaClient);

messageBrokerConsumer.consumeChatMessages(serverTopic);

// Close the Web Socket server and Kafka consumer before exiting
function prepareExit() {
  chatMessagingServer.closeServer();
  messageBrokerConsumer.close();
}

// Handle signals and prepare for the process exit
process.once('SIGINT', prepareExit);
process.once('SIGQUIT', prepareExit);
process.once('SIGTERM', prepareExit);
```

For the web client, we have the below code. An instance of the `ChatMessagingService` class connects to
a chat messaging server via WebSocket. It listens to messages received from the server and dispatches an action upon
receiving a chat message. The class also offers a method for sending a chat message to the server.

{format: js}
![ChatMessagingService.js](resources/chapter6/code/websocket_client/ChatMessagingService.js)

{format: jsx}
![index.jsx](resources/chapter6/code/websocket_client/index.jsx)

The chat application `ChatApp` parses the user's and contact's phone numbers from the URL and then
renders a chat view between the user and the contact:

{format: jsx}
![ChatApp.jsx](resources/chapter6/code/websocket_client/ChatApp.jsx)

The `ContactChatView` component renders chat messages between a user and a contact:

{format: jsx, type: code}
![ContactChatView.jsx](resources/chapter6/code/websocket_client/ContactChatView.jsx)

{format: js}
![store.js](resources/chapter6/code/websocket_client/store.js)

{format: css}
![index.css](resources/chapter6/code/websocket_client/index.css)

![Chat Messaging Application Views for Two Users](resources/chapter6/images/Capture1.PNG)

![Chat Messaging Application Views for Two Users](resources/chapter6/images/Capture2.PNG)

## Inter-Microservice API Design Principles

Inter-microservice APIs can be divided into two categories based on the type of communication: synchronous and asynchronous.
Synchronous communication should be used when an immediate response to an issued request is expected. Asynchronous
communication can be used when no response to a request is expected or the response is not immediately required.

### Synchronous API Design Principle

> ***Use HTTP-based RPC or REST APIs with JSON data encoding, preferably with HTTP/2 or HTTP/3 transport, when requests and responses are not very large and do not contain much binary data. Suppose you have large requests or responses or a lot of binary data. In that case, you are better off encoding the data in *Avro* binary format  (Content-Type: avro/binary) instead of JSON or using a gRPC-based API. gRPC always encodes data in a binary format (Protocol Buffers).***

#### gRPC-Based API Design Example

Let's have an example of a gRPC-based API. First, we must define the needed Protocol Buffers types.
They are defined in a file named with the extension _.proto_. The syntax of _proto_ files is pretty simple. We define
the service by listing the remote procedures. A remote procedure is defined with the following syntax:
`rpc <procedure-name> (<argument-type>) returns (<return-type>) {}`. A type is defined with the below syntax:

```
message <type-name> {
  <field-type> <field-name> [= <field-index>];
  ...
}
```

{title: "salesItemService.proto"}
```proto
syntax = "proto3";

option java_multiple_files = true;
option java_package = "com.silensoft.salesitemservice";
option java_outer_classname = "SalesItemServiceProto";
option objc_class_prefix = "SIS";

package salesitemservice;

service SalesItemService {
  rpc createSalesItem (NewSalesItem) returns (SalesItem) {}
  rpc getSalesItems(Nothing) returns (SalesItems) {}
  rpc getSalesItem (Id) returns (SalesItem) {}
}

message Nothing {}

message NewSalesItem {
  string name = 1;
  float price = 2;
}

message SalesItem {
  uint64 id = 1;
  uint64 createdAtTimestampInMillis = 2;
  string name = 3;
  float price = 4;
}

message Id {
  uint64 id = 1;
}

message SalesItems {
  repeated SalesItem salesItem = 1;
}
```

Below is a partial implementation of the gRPC server. We have only implemented the `createSalesItem` procedure.

{title: "SalesItemServiceServer.java"}
```java
package com.silensoft.salesitemservice;

import io.grpc.Server;
import io.grpc.ServerBuilder;
import io.grpc.stub.StreamObserver;
import java.io.IOException;
import java.util.concurrent.TimeUnit;
import lombok.Log;

@Log
public class SalesItemServiceServer {
  private Optional<Server> maybeGrpcServer;

  private void start() throws IOException {
    maybeGrpcServer = Optional.of(ServerBuilder.forPort(50051)
      .addService(new SalesItemServiceImpl())
      .build());

    maybeGrpcServer.get().start();
    logger.info("Server started, listening on port: " + port);

    Runtime.getRuntime().addShutdownHook(new Thread() {
      @Override
      public void run() {
        try {
          stop();
        } catch (final InterruptedException exception) {
          exception.printStackTrace(System.err);
        }

        System.err.println("Server shut down");
      }
    });
  }

  private void stop() throws InterruptedException {
    maybeGrpcServer
      .ifPresent(grpcServer ->
        grpcServer
          .shutdown()
          .awaitTermination(30, TimeUnit.SECONDS));
  }

  private void waitUntilTerminated() throws InterruptedException {
    maybeGrpcServer.ifPresent(Server::awaitTermination);
  }

  public static void main(
    final String[] args
  ) throws IOException, InterruptedException {
    final var server = new SalesItemServiceServer();
    server.start();
    server.waitUntilTerminated();
  }

  static class SalesItemServiceImpl
                 extends SalesItemServiceGrpc.ImplBase {
    @Override
    public void createSalesItem(
      final NewSalesItem salesItem,
      final StreamObserver<SalesItem> responseObserver
    ) {
      // Set createdAtTimestamp value on salesItem to be now
      // Insert sales item to database and return 'id'

      salesItem.id = id;
      responseObserver.onNext(salesItem);
      responseObserver.onCompleted();
    }
  }
}
```

Below is the gRPC client implementation for the above gRPC server:

{title: "SalesItemServiceClient.java"}
```java
package com.silensoft.salesitemservice;

import io.grpc.Channel;
import io.grpc.ManagedChannel;
import io.grpc.ManagedChannelBuilder;
import io.grpc.StatusRuntimeException;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;
import java.util.logging.Logger;
import lombok.Log;

@Log
public class SalesItemServiceClient {
  private final SalesItemServiceGrpc.SalesItemServiceBlockingStub salesItemService;

  public SalesItemServiceClient(final Channel channel) {
    salesItemService =
      SalesItemServiceGrpc.newBlockingStub(channel);
  }

  public SalesItem createSalesItem(final NewSalesItem salesItem) {
    try {
      return salesItemService.createSalesItem(salesItem);
    } catch (final StatusRuntimeException exception) {
       logger.log(Level.ERROR,
                  "CreateSalesItem failed: {0}",
                  exception.getStatus());
    }
  }

  public static void main(final String[] args) throws Exception {
    final var channel = ManagedChannelBuilder
                          .forTarget("localhost:50051")
                          .usePlaintext()
                          .build();

    try {
      SalesItemServiceClient client =
        new SalesItemServiceClient(channel);

      client.createSalesItem(...);
    } finally {
      channel.shutdownNow().awaitTermination(5, TimeUnit.SECONDS);
    }
  }
}
```

### Asynchronous API Design Principle

> ***Use asynchronous APIs when requests are request-only (fire-and-forget, i.e., no response is expected) or when the response***
> ***is not immediately expected.***

#### Request-Only Asynchronous API Design

In request-only asynchronous APIs, the request sender does not expect a response. Such APIs are typically
implemented using a message broker. The request sender will send a JSON or other format request to a topic in the message broker,
where the request recipient consumes the request asynchronously.

Different API endpoints can be specified in a request using a `procedure` property, for example.
You can name the `procedure` property as you wish, e.g., `action`, `method`, `operation`, `apiEndpoint`, etc.
Parameters for the procedure can be supplied in a `parameters` property.
Below is an example request in JSON:

```json
{
  "procedure": "<procedure name>",
  "parameters": {
    "<parameterName1>": "parameter value 1",
    "<parameterName2>": "parameter value 2",
    // ...
  }
}
```

Let's have an example with an email-sending microservice that implements a request-only asynchronous API
and handles the sending of emails. We start by defining a message broker topic for the microservice. The topic should
be named after the microservice, for example, *email-sending-service*.

In the *email-sending-service*, we define the following request schema for an API endpoint that
sends an email:

```json
{
  "procedure": "sendEmailMessage",
  "parameters": {
    "fromEmailAddress": "...",
    "toEmailAddresses": ["...", "...", ...],
    "subject": "...",
    "message": "..."
  }
}
```

Below is an example request that some other microservice can produce to the *email-sending-service* topic in the message broker to be handled by the *email-sending-service*:

```json
{
  "procedure": "sendEmailMessage",
  "parameters": {
    "fromEmailAddress": "sender@domain.com",
    "toEmailAddresses": ["receiver@domain.com"],
    "subject": "Status update",
    "message": "Hi, Here is my status update ..."
  }
}
```

#### Request-Response Asynchronous API Design

A request-response asynchronous API microservice receives requests from other microservices and then produces
responses asynchronously. Request-response asynchronous APIs are typically implemented
using a message broker. The request sender will send a request to a topic where the request recipient consumes the request
asynchronously and then produces a response or responses to a message broker topic or topics.
Each participating microservice should have a topic named after the microservice in the message broker.

The request format is the same as defined earlier, but
the response has a `response` or `result` property instead of the `parameters` property, meaning that responses have the following format:

```json
{
   "procedure": "<procedure name>",
   "response": {
     "propertyName1": "property value 1",
     "propertyName2": "property value 2",
     // ...
   }
}
```

Below is an example where a *loan-application-service* requests a *loan-eligibility-assessment-service*
to assess loan eligibility. The *loan-application-service* sends the following JSON-format request to
the message broker's *loan-eligibility-assessment-service* topic:

```json
{
  "procedure": "assessLoanEligibility",
  "parameters": {
    "userId": 123456789012,
    "loanApplicationId": 5888482223,
    // Other parameters...
  }
}
```

The *loan-eligibility-assessment-service* responds to the above request by sending the following JSON-format response to
the message broker's *loan-application-service* topic:

```json
{
  "procedure": "assessLoanEligibility",
  "response": {
     "loanApplicationId": 5888482223,
     "isEligible": true,
     "amountInDollars": 10000,
     "interestRate": 9.75,
     "termInMonths": 120
  }
}
```

Below is an example response when the loan application is rejected:

```json
{
  "procedure": "assessLoanEligibility",
  "response": {
    "loanApplicationId": 5888482223,
    "isEligible": false
  }
}
```

Alternatively, request and response messages can be treated as events with some data. When we send events between
microservices, we call it an [event-driven architecture](https://en.wikipedia.org/wiki/Event-driven_architecture).
For event-driven architecture, we must decide if we have a single or multiple topics
for the software system in the message broker. If all the microservices share a single topic in the software system,
then each microservice will consume each message from the message broker and decide if they should act on it. This approach is suitable except when large events are produced to the message broker. When large events are produced, each microservice must consume those large events even if they don't need to react to them. This will unnecessarily consume a lot of network bandwidth if the number of microservices is also high. The other
extreme is to create a topic for each microservice in the message broker. This approach causes extra network bandwidth consumption if a large event must be produced to multiple topics to be handled by multiple microservices. You can also create a hybrid model with a broadcast topic or topics and individual topics for specific microservices.

To solve the problems described above, you can use the [claim check pattern](https://learn.microsoft.com/enus/azure/architecture/patterns/claim-check).
In that pattern, you split a large message into a claim check and the actual payload of the message. You only send the claim check
to a message queue and store the payload elsewhere. This protects other microservices from needing to read large messages from the message queue that they don't have to react to.

Below are the earlier request and response messages written as events:

```json
{
  "event": "AssessLoanEligibility",
  "data": {
    "userId": 123456789012,
    "loanApplicationId": 5888482223,
    // ...
  }
}
```

```json
{
  "event": "LoanApproved",
  "data": {
     "loanApplicationId": 5888482223,
     "isEligible": true,
     "amountInDollars": 10000,
     "interestRate": 9.75,
     "termInMonths": 120
  }
}
```

```json
{
  "procedure": "LoanRejected",
  "response": {
    "loanApplicationId": 5888482223,
    "isEligible": false
  }
}
```

#### Asynchronous API Documentation

[AsyncAPI](https://www.asyncapi.com/) provides tools for building and documenting event-driven architectures.
Below is an example where two events are defined for the *sales-service*:

```yaml
asyncapi: 3.0.0
info:
  title: Sales Item Service
  version: 1.0.0
channels:
  salesItemService:
    address: sales-item-service
    messages:
      createSalesItem:
        description: Creates a sales item.
        payload:
          type: object
          properties:
            name:
              type: string
            price:
              type: integer
  notifications:
      address: notifications
      messages:
        salesItemCreated:
          description: A Sales item was created.
          payload:
            type: object
            properties:
              id:
                type: string
              name:
                type: string
              price:
                type: integer
operations:
  createSalesItem:
    action: receive
    channel:
      $ref: '#/channels/salesItemService'
  salesItemCreated:
      action: send
      channel:
        $ref: '#/channels/notifications'
```

The service receives `createSalesItem` events on channel `salesItemService` and sends `salesItemCreated` events
on the `notifications` channel. The `createSalesItem` event contains the following properties: `name` and `price`. And
the `salesItemCreated` event contains an additional `id` property.

## API Design Example

Let's have a concrete example of designing an API for a trip booking service.
The first feature, as presented by product management, is for a user to be able to *book a trip*. We do not concern ourselves with frontend development here; we only focus on the backend (API) side.

The team uses domain-driven design and starts with an event-storming session, which results in the following output.

![Event Storming Result](resources/chapter6/images/api_design_example.png)

From the above picture, we can infer our user stories for the backend API:

- As a user I want flight(s) to be reserved for my trip
- As a user I want hotel room(s) to be reserved for my trip
- As a user I want rental car(s) to be reserved for my trip
- As a user I want my trip to be persisted

From the above picture, we can infer our classes and put them in the following directory layout:

```
trip-booking-service
 src
     trip
         model
            dtos
               InputTrip.py
               InputFlightReservation.py
               InputHotelReservation.py
               InputRentalCarReservation.py
               OutputTrip.py
               OutputFlightReservation.py
               OutputHotelReservation.py
               OutputRentalCarReservation.py
            entities
               FlightReservation.py
               HotelReservation.py
               RentalCarReservation.py
               Trip.py
            errors
               TripBookingServiceError.py
               ...
            repositories
               TripRepository.py
            services
               FlightReservationService.py
               HotelReservationService.py
               RentalCarReservationService.py
            usecases
                TripBookingUseCases.py
                TripBookingUseCasesImpl.py
         ifadapters
             controllers
                RestTripBookingController.py
             repositories
                MongoDbTripRepository.py
             services
                 GalileoFlightReservationService.py
                 AmadeusHotelReservationService.py
                 HertzRentalCarReservationService.py
```

Next, we should use BDD and ATDD to define acceptance tests for the trip booking feature. We will skip that step
here because it was already well covered in the testing principles chapter.

After we have implemented our acceptance tests, we need to start implementing our API microservice to get those
acceptance tests passed. For the implementation, we should use either Detroit/Chicago or London-style TDD. We choose the London
style and start from the outer layer, i.e., from the controller. I am not presenting the TDD steps here; I am only presenting the implementation. We have already covered the TDD in several examples.
We should use the bounded context-specific ubiquitous language in our code. For example, instead of speaking about creating a trip, we
use the term "book a trip".

{aside}
Source code for the below example is available [here](https://github.com/pksilen/clean-code-principles-python-code/tree/main/chapter6/apidesign).
{/aside}

The controller method for booking a trip should be simple and delegate to a business use case.

{title: "RestTripBookingController"}
```python
class RestTripBookingController:
    __trip_booking_use_cases: TripUseCases = Provide['trip_use_cases']

    def __init__(self):
        self.__router = APIRouter()

        self.__router.add_api_route(
            '/trips/',
            self.book_trip,
            methods=['POST'],
            status_code=201,
            response_model=OutputTrip,
        )

    @property
    def router(self):
        return self.__router

    def book_trip(self, input_trip: InputTrip) -> OutputTrip:
        return self.__trip_booking_use_cases.book_trip(input_trip)
```

Notice below how we put behavior into domain entities, and our use case class is not crowded
with business logic code but delegate to entity class and repository to achieve a business use case.

{title: "TripBookingUseCasesImpl"}
```python
class TripUseCasesImpl(TripUseCases):
    __trip_repository: TripRepository = Provide['trip_repository']

    def book_trip(self, input_trip: InputTrip) -> OutputTrip:
        # Below factory method creates a validated domain entity
        trip = Trip.create_from(input_trip)

        # Distributed transaction starts
        trip.make_reservations()

        try:
            self.__trip_repository.save(trip)
        except self.__trip_repository.Error as error:
           # Compensating action
           trip.cancel_reservations()
           raise error

       # Distributed transaction ends

       return OutputTrip.model_validate(trip)
```

{title: "TripRepository"}
```python
class TripRepository(Protocol):
    class Error(TripBookingServiceError):
        pass

    def save(self, trip: Trip) -> None:
        pass
```

{title: "MongoDbTripRepository"}
```python
class MongoDbTripRepository(TripRepository):
    def save(self, trip: Trip) -> None:
        # ...
```

Below is the code for the domain entities:

{title: "Trip.py"}
```python
class Trip:
    def __init__(self, reservations: list[Reservation], ...):
        self.__reservations = reservations

    @staticmethod
    def create_from(input_trip: InputTrip) -> 'Trip':
        reservations = []

        for flight_reservation in input_trip.flight_reservations:
            reservations.append(FlightReservation(...))

        for hotel_reservation in input_trip.hotel_reservations:
            reservations.append(HotelReservation(...))

        for rental_car_reservation in input_trip.rental_car_reservations:
            reservations.append(RentalCarReservation(...))

        return Trip(reservations, ...)

    def make_reservations(self) -> None:
        try:
            for reservation in self.__reservations:
                reservation.make()
        except Reservation.MakeError as error:
            # We are inside a distributed transaction
            # Compensating actions
            self.cancel_reservations()
            raise error

    def cancel_reservations(self) -> None:
        # In production code, this loop cannot be forever but should be
        # replaced with more robust and complex error handling as described
        # earlier in first chapter when discussing distributed transactions
        while self.__reservations:
            try:
                for reservation in self.__reservations:
                    reservation.cancel()
                    self.__reservations.remove(reservation)
                    break
            except Reservation.CancelError:
                pass
```

{title: "Reservation.py"}
```python
class Reservation(Protocol):
    class MakeError(TripBookingServiceError):
        pass

   class AlreadyReservedError(MakeError):
           pass

    def make(self) -> None:
        pass

    class CancelError(TripBookingServiceError):
        pass

    def cancel(self) -> None:
        pass
```

{title: "AbstractReservation.py"}
```python
class AbstractReservation(Reservation):
    def __init__(self, id_: str):
        self.__id = id_

    @property
    def id(self) -> str:
        return self.__id

    @id.setter
    def id(self, id_: str) -> None:
        self.__id = id_

    def _assert_is_not_reserved(self) -> None:
        if self.__id is not None:
            raise self.AlreadyReservedError()

    def _cancel_using(self, reservation_service: ReservationService) -> None:
        if self.__id is None:
            return

        try:
            reservation_service.cancel_reservation(self.__id)
            self.__id = None
        except reservation_service.CancelReservationError as error:
            raise self.CancelError(error)
```

{title: "FlightReservation.py"}
```python
class FlightReservation(AbstractReservation):
    __flight_reservation_service: FlightReservationService = Provide['flight_reservation_service']

    def __init__(self, ...):
        # Set flight reservation related attributes ...

    def make(self) -> None:
        self._assert_is_not_reserved()

        try:
            self.id = self.__flight_reservation_service.reserve_flight(...)
        except self.__flight_reservation_service.ReserveFlightError as error:
            raise self.MakeError(error)

    def cancel(self) -> None:
        self._cancel_using(self.__flight_reservation_service)
```

{title: "HotelReservation.py"}
```python
class HotelReservation(AbstractReservation):
    __hotel_reservation_service: HotelReservationService = Provide['hotel_reservation_service']

    def __init__(self, ...):
        # Set hotel reservation related attributes ...

    def make(self) -> None:
        self._assert_is_not_reserved()

        try:
            self.id = self.__hotel_reservation_service.reserve_hotel(...)
        except self.__hotel_reservation_service.ReserveHotelError as error:
            raise self.MakeError(error)

    def cancel(self) -> None:
        self._cancel_using(self.__hotel_reservation_service)
```

{title: "RentalCarReservation.py"}
```python
class RentalCarReservation(AbstractReservation):
    __rental_car_reservation_service: RentalCarReservationService = Provide['rental_car_reservation_service']

     def __init__(self, ...):
         # Set rental car reservation related attributes ...

    def make(self) -> None:
        self._assert_is_not_reserved()

        try:
            self.id = self.__rental_car_reservation_service.reserve_car(...)
        except self.__rental_car_reservation_service.ReserveCarError as error:
            raise self.MakeError(error)

    def cancel(self) -> None:
        self._cancel_using(self.__rental_car_reservation_service)
```

{title: ReservationService.py}
```python
class ReservationService(Protocol):
    class CancelReservationError(TripBookingServiceError):
        pass

    def cancel_reservation(self, id_: str) -> None:
        pass
```

{title: FlightReservationService.py}
```python
class FlightReservationService(ReservationService):
    class ReserveFlightError(TripBookingServiceError):
        pass

    def reserve_flight(self, ...) -> None:
        pass
```

{title: GalileoFlightReservationService.py}
```python
class GalileoFlightReservationService(FlightReservationService):
    def reserve_flight(self, ...) -> None:
        # ...

    def cancel_reservation(self, id_: str) -> None:
        # ...
```

{title: HotelReservationService.py}
```python
class HotelReservationService(ReservationService):
    class ReserveHotelError(TripBookingServiceError):
        pass

    def reserve_hotel(self, ...) -> None:
        pass
```

{title: AmadeusHotelReservationService.py}
```python
class AmadeusHotelReservationService(HotelReservationService):
    def reserve_hotel(self, ...) -> None:
        # ...

    def cancel_reservation(self, id_: str) -> None:
        # ...
```

{title: RentalCarReservationService.py}
```python
class RentalCarReservationService(ReservationService):
    class ReserveCarError(TripBookingServiceError):
        pass

    def reserve_car(self, ...) -> None:
        pass
```

{title: HertzRentalCarReservationService.py}
```python
class HertzRentalCarReservationService(RentalCarReservationService):
    def reserve_car(self, ...) -> None:
        # ...

    def cancel_reservation(self, id_: str) -> None:
        # ...
```

{title: "DiContainer.py"}
```python
class DiContainer(containers.DeclarativeContainer):
    wiring_config = containers.WiringConfiguration(
        modules=[
            # ...
        ]
    )

    trip_booking_use_cases = providers.Singleton(TripUseCasesImpl)
    trip_repository = providers.Singleton(MongoDbTripRepository)
    flight_reservation_service = providers.Singleton(GalileoFlightReservationService)
    hotel_reservation_service = providers.Singleton(AmadeusHotelReservationService)
    rental_car_reservation_service = providers.Singleton(HertzRentalCarReservationService)
```

Let's see how we can further develop the trip booking service. Let's assume that product management requests us
to allow users to reserve tours and activities during their trip. We can implement this feature by mostly using the *open-closed
principle*. For tour and activities reservations, we should introduce input and output DTO classes, an entity class derived
from the `Reservation` class, and a service class for performing the actual reservations. Then, we only need to modify the `Trip` class factory method to create instances of
the newly created tour and activities reservation entity class.

After booking a trip, product management wants users to be able to modify their reservations, like adding, replacing, and
removing reservations. Let's have an example of a feature for adding a rental car reservation to an existing trip.

{title: "RestTripBookingController"}
```python
class RestTripBookingController:
    __trip_booking_use_cases: TripUseCases = Provide['trip_booking_use_cases']

    def __init__(self):
       self.__router = APIRouter()

       # ...

       self.__router.add_api_route(
            '/trips/{trip_id}/rental-car-reservations',
            self.add_rental_car_reservation,
            methods=['POST'],
            status_code=201,
            response_model=OutputRentalCarReservation,
        )

    # ...

    def add_rental_car_reservation(
        self, trip_id: str, input_rental_car_reservation: InputRentalCarReservation
    ) -> OutputRentalCarReservation:
        return self.__trip_booking_use_cases.add_rental_car_reservation(
            trip_id,
            input_rental_car_reservation
        )
```

{title: "TripBookingUseCasesImpl"}
```python
class TripBookingUseCasesImpl(TripBookingUseCases):
    # ...

    def add_rental_car_reservation(
        self,
        trip_id: str,
        input_rental_car_reservation: InputRentalCarReservation
    ) -> OutputRentalCarReservation:
        # Get existing trip domain entity
        trip = self.__trip_repository.find(trip_id)

        if trip is None:
            raise EntityNotFoundError('Trip', trip_id)

        # Below factory method creates a validated domain entity
        rental_car_reservation = RentalCarReservation.create_from(input_rental_car_reservation)

        # Distributed transaction begins
        trip.add(rental_car_reservation)

        try:
            self.__trip_repository.update(trip)
        except self.__trip_repository.Error as error:
           # Compensating action
           trip.remove(rental_car_reservation)
           raise error

        # Distributed transaction ends

       return OutputRentalCarReservation.model_validate(rental_car_reservation)
```

{title: "TripRepository"}
```python
class TripRepository(Protocol):
    # ...

    def update(self, trip: Trip) -> None:
        pass
```

{title: "MongoDbTripRepository"}
```python
class MongoDbTripRepository(TripRepository):
    # ...

    def update(self, trip: Trip) -> None:
        # ...
```

{title: "Trip.py"}
```python
class Trip:
    # ...

    def add(self, reservation: Reservation) -> None:
        reservation.make()
        self.__reservations.append(reservation)

    def remove(self, reservation: Reservation) -> None:
        while True:
           try:
                reservation.cancel()
                break
           except reservation.CancelError:
                pass

        self.__reservations.remove(reservation)
```

In the above examples, we did not use the convention of adding a *try*-prefix to a method that can raise an error.
However, it could have been beneficial in this case due to distributed transactions. *Try*-prefixed methods would have clarified where our distributed transactions can fail and execution of, e.g., compensating actions, is required.